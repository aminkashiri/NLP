{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Required Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahur4/anaconda3/envs/data_env/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from transformers import pipeline, BertTokenizer, BertForMaskedLM, AlbertTokenizer, AlbertForMaskedLM, RobertaTokenizer, RobertaModel\n",
    "from transformers.pipelines.fill_mask import FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "from spacy.tokens.token import Token\n",
    "from spacy.tokens.doc import Doc\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en bert Model Loaded ...\n"
     ]
    }
   ],
   "source": [
    "# torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch_device = 'cpu'\n",
    "print(f\"Torch Device: {torch_device}\")\n",
    "\n",
    "language = 'en'\n",
    "model_type = 'bert'\n",
    "\n",
    "# EN\n",
    "model_name = \"bert-large-uncased\" # Bert large\n",
    "# model_name = \"bert-base-uncased\" # Bert base\n",
    "# model_name = \"roberta-large\"  # Roberta\n",
    "\n",
    "# FA\n",
    "# model_name = \"HooshvareLab/albert-fa-zwnj-base-v2\" # Albert\n",
    "# model_name = \"HooshvareLab/bert-fa-base-uncased\" # BERT V2\n",
    "# model_name = \"HooshvareLab/bert-fa-zwnj-base\" # BERT V3\n",
    "\n",
    "if model_type == 'bert':\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else BertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'albert':\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "    model = AlbertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else AlbertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'roberta':\n",
    "    MASK = \"<mask>\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "    unmasker = pipeline('fill-mask', model='roberta-large')\n",
    "\n",
    "else:\n",
    "    print(f\"{model_type} not found.\")\n",
    "\n",
    "vocab: set = set(tokenizer.get_vocab().keys())\n",
    "\n",
    "if model_type == 'roberta':\n",
    "    vocab = set(map(lambda s: s[1:], vocab))\n",
    "\n",
    "print(f\"{language} {model_type} Model Loaded ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stanza\n",
    "\n",
    "spaCy's tokenization is non-destructive, so it always represents the original input text and never adds or deletes anything. This is kind of a core principle of the Doc object: you should always be able to reconstruct and reproduce the original input text.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import spacy\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if language == 'fa':\n",
    "    stanza.install_corenlp()\n",
    "    stanza.download('fa')\n",
    "    nlp = spacy_stanza.load_pipeline(\"fa\")\n",
    "\n",
    "elif language == 'en':\n",
    "    spacy.prefer_gpu()\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"{language} not supported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Lexico Typo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def lexico_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index, current_token in enumerate(doc):\n",
    "            current_token: Token\n",
    "            start_char_index: int = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            if current_token.text not in vocab:\n",
    "                masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "                predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "                ### Select Token From Predicts\n",
    "                predicts = pd.DataFrame(predicts)\n",
    "\n",
    "                predicts['token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "                predicts['edit_distance'] = predicts['token_str'].apply(lambda tk: editdistance.eval(current_token.text, tk))\n",
    "\n",
    "                predicts['edit_distance_to_len_ratio'] = predicts['edit_distance'] / len(current_token.text)\n",
    "\n",
    "                selected_predicts = predicts[(predicts['edit_distance_to_len_ratio'] <= max_edit_distance_to_length_ratio) &\n",
    "                                             (predicts['edit_distance'] <= max_edit_distance) & (predicts['score'] >= min_score)]\n",
    "\n",
    "                try:\n",
    "                    selected_predict = selected_predicts['token_str'].iloc[0]\n",
    "                except:\n",
    "                    selected_predict = current_token.text\n",
    "                    if selected_predict not in vocab:\n",
    "                        vocab.add(selected_predict)\n",
    "\n",
    "                if selected_predict != current_token.text:\n",
    "                    some_token_corrected = True\n",
    "                    result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                    text = result_text\n",
    "\n",
    "                if verbose:\n",
    "\n",
    "                    # print(\"*\" * 50)\n",
    "                    # print(f\"Token: {current_token.text}\")\n",
    "                    #\n",
    "                    # print(\"Predicts: \\n\")\n",
    "                    # print(predicts[['token_str', 'score']])\n",
    "                    #\n",
    "                    # print(\"Filtered Predicts: \\n\")\n",
    "                    # print(selected_predicts[['token_str', 'score']])\n",
    "                    # print(f\"{current_token.text} -> {selected_predict}\")\n",
    "\n",
    "                    typo_correction_details = {\n",
    "                        \"raw\": current_token.text,\n",
    "                        \"corrected\": selected_predict,\n",
    "                        \"span\": f\"[{start_char_index}, {end_char_index}]\",\n",
    "                        \"type\": \"lexical\"\n",
    "                    }\n",
    "\n",
    "                    print(typo_correction_details)\n",
    "\n",
    "                if some_token_corrected:\n",
    "                    break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Contextual Typo\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def contextual_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index in range(len(doc)):\n",
    "            current_token: Token = doc[index]\n",
    "\n",
    "            start_char_index = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "            predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "            ### Select Token From Predicts\n",
    "            predicts = pd.DataFrame(predicts)\n",
    "\n",
    "            predicts['token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "            predicts['edit_distance'] = predicts['token_str'].apply(\n",
    "                lambda tk: editdistance.eval(current_token.text, tk))\n",
    "            predicts['edit_distance_to_len_ratio'] = predicts['edit_distance'] / len(current_token.text)\n",
    "\n",
    "            try:\n",
    "                if current_token.text in string.punctuation:\n",
    "                    selected_predict = predicts['token_str'].iloc[0]\n",
    "\n",
    "                elif current_token.text.isdigit():\n",
    "                    selected_predict = current_token.text\n",
    "\n",
    "                else:\n",
    "                    selected_predicts = predicts[\n",
    "                        (predicts['edit_distance_to_len_ratio'] <= max_edit_distance_to_length_ratio) &\n",
    "                        (predicts['edit_distance'] <= max_edit_distance) &\n",
    "                        (predicts['score'] >= min_score)]\n",
    "\n",
    "                    selected_predict = selected_predicts.sort_values('score')['token_str'].iloc[0]\n",
    "\n",
    "                    current_token_text_score = selected_predicts['score'][selected_predicts['token_str'] == current_token.text]\n",
    "                    selected_token_text_score = selected_predicts.sort_values('score')['score'].iloc[0]\n",
    "\n",
    "                    if current_token.text != selected_predict:\n",
    "\n",
    "                        if current_token.text in selected_predicts['token_str'].values:\n",
    "                            print(\"\\n\")\n",
    "                            print(f\"current_token_text_score: {current_token_text_score}, selected_token_text_score: {selected_token_text_score}\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "                            if selected_token_text_score / current_token_text_score > 50:\n",
    "                                selected_predict = selected_predicts.sort_values('edit_distance_to_len_ratio')['token_str'].iloc[0]\n",
    "\n",
    "                            else:\n",
    "                                selected_predict = current_token.text\n",
    "\n",
    "                        else:\n",
    "                            selected_predict = selected_predicts.sort_values('edit_distance_to_len_ratio')['token_str'].iloc[0]\n",
    "\n",
    "            except:\n",
    "                selected_predict = current_token.text\n",
    "\n",
    "            if selected_predict != current_token.text:\n",
    "                some_token_corrected = True\n",
    "                result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                text = result_text\n",
    "\n",
    "            if verbose:\n",
    "                print(\"*\" * 50)\n",
    "                print(f\"Token: {current_token.text}\")\n",
    "\n",
    "                print(\"Predicts: \\n\")\n",
    "                print(predicts[['token_str', 'score']])\n",
    "\n",
    "                print(\"Filtered Predicts: \\n\")\n",
    "                print(selected_predicts[['token_str', 'score', 'edit_distance_to_len_ratio']])\n",
    "                print(f\"{current_token.text} -> {selected_predict}\")\n",
    "\n",
    "                if current_token.text != selected_predict:\n",
    "                    typo_correction_details = {\n",
    "                        \"raw\": current_token.text,\n",
    "                        \"corrected\": selected_predict,\n",
    "                        \"span\": f\"[{start_char_index}, {end_char_index}]\",\n",
    "                        \"type\": \"contextual\"\n",
    "                    }\n",
    "\n",
    "                    print(typo_correction_details)\n",
    "\n",
    "            if some_token_corrected:\n",
    "                break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correction Pipeline Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class SpellCorrector:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_edit_distance_to_length_ratio=0.45,\n",
    "            max_edit_distance=2,\n",
    "            min_score=1e-7,\n",
    "            verbose=False,\n",
    "            top_k=50\n",
    "    ):\n",
    "        self.max_edit_distance_to_length_ratio = max_edit_distance_to_length_ratio\n",
    "        self.max_edit_distance = max_edit_distance\n",
    "        self.min_score = min_score\n",
    "        self.verbose = verbose\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def _lexico_typo_correction(self, text):\n",
    "        return lexico_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                      self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def _contextual_typo_correction(self, text):\n",
    "        return contextual_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                          self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def correction_pipeline(self, text):\n",
    "\n",
    "        print(f\"raw       : {text}\")\n",
    "        # print(\"Lexico Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._lexico_typo_correction(text)\n",
    "\n",
    "        # print(\"Contextual Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._contextual_typo_correction(corrected_text)\n",
    "\n",
    "        print(f\"corrected : {corrected_text}\")\n",
    "        return corrected_text\n",
    "\n",
    "    def __call__(self, text, *args, **kwargs):\n",
    "        return self.correction_pipeline(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test On Sample Texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell Correction for text sentences:\n",
      "raw       : cars have very sweet features. it has two beautifull eye, adorably tiny paws, sharp claws, and two perky ear which are very sensitive to sounds. it has a tiny body covered with smoot fur and it has a furry tail as well. cats have an adorable face with a tiny nose, a big mouth and a few whiskers under its nose.\n",
      "{'raw': 'smoot', 'corrected': 'soft', 'span': '[177, 182]', 'type': 'lexical'}\n",
      "**************************************************\n",
      "Token: cars\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        cats  0.733804\n",
      "1        they  0.194963\n",
      "2        dogs  0.010025\n",
      "3      humans  0.005630\n",
      "4          it  0.005564\n",
      "..        ...       ...\n",
      "245     bulls  0.000009\n",
      "246      must  0.000009\n",
      "247  biscuits  0.000009\n",
      "248    models  0.000009\n",
      "249    fruits  0.000009\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       cats  0.733804                        0.25\n",
      "60      cars  0.000120                        0.00\n",
      "cars -> cars\n",
      "**************************************************\n",
      "Token: have\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         have  0.851532\n",
      "1          has  0.137819\n",
      "2          are  0.001647\n",
      "3      possess  0.001346\n",
      "4          had  0.001079\n",
      "..         ...       ...\n",
      "245   manifest  0.000002\n",
      "246     unique  0.000002\n",
      "247  describes  0.000002\n",
      "248       that  0.000002\n",
      "249     appear  0.000002\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      have  0.851532                         0.0\n",
      "have -> have\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         very  0.333895\n",
      "1         many  0.064019\n",
      "2         some  0.056303\n",
      "3       really  0.039823\n",
      "4         nice  0.027663\n",
      "..         ...       ...\n",
      "245       uber  0.000129\n",
      "246  genuinely  0.000129\n",
      "247      round  0.000128\n",
      "248     famous  0.000128\n",
      "249   peculiar  0.000127\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      very  0.333895                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: sweet\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0     similar  0.154371\n",
      "1     unusual  0.059991\n",
      "2     special  0.057704\n",
      "3        cute  0.057267\n",
      "4       funny  0.046098\n",
      "..        ...       ...\n",
      "245    mobile  0.000184\n",
      "246      mild  0.000180\n",
      "247     alien  0.000177\n",
      "248     quick  0.000177\n",
      "249   several  0.000174\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "54     sweet  0.001688                         0.0\n",
      "sweet -> sweet\n",
      "**************************************************\n",
      "Token: features\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0            fur  0.211673\n",
      "1           ears  0.135094\n",
      "2          smell  0.069273\n",
      "3          taste  0.039930\n",
      "4           skin  0.038087\n",
      "..           ...       ...\n",
      "245        sides  0.000162\n",
      "246    abilities  0.000161\n",
      "247        moans  0.000160\n",
      "248  expressions  0.000157\n",
      "249       digits  0.000157\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "     token_str     score  edit_distance_to_len_ratio\n",
      "71    features  0.001561                        0.00\n",
      "137  creatures  0.000426                        0.25\n",
      "features -> features\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0               .  7.522441e-01\n",
      "1               :  5.886701e-02\n",
      "2               ,  5.752305e-02\n",
      "3               ;  3.961290e-02\n",
      "4             and  3.427293e-02\n",
      "..            ...           ...\n",
      "245  respectively  6.728072e-07\n",
      "246        second  6.699937e-07\n",
      "247          ##es  6.691674e-07\n",
      "248            me  6.665763e-07\n",
      "249        became  6.658909e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "     token_str     score  edit_distance_to_len_ratio\n",
      "71    features  0.001561                        0.00\n",
      "137  creatures  0.000426                        0.25\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0           it  0.974362\n",
      "1          she  0.003967\n",
      "2          cat  0.002941\n",
      "3          one  0.002634\n",
      "4         each  0.001387\n",
      "..         ...       ...\n",
      "245      oscar  0.000007\n",
      "246    peacock  0.000007\n",
      "247   godzilla  0.000007\n",
      "248     silver  0.000007\n",
      "249  everybody  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.974362                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          has  9.796064e-01\n",
      "1         have  1.623373e-02\n",
      "2          had  7.658841e-04\n",
      "3    possesses  5.518724e-04\n",
      "4        bears  5.341871e-04\n",
      "..         ...           ...\n",
      "245   averages  3.094376e-07\n",
      "246       hugs  3.064006e-07\n",
      "247        add  3.053243e-07\n",
      "248   reflects  3.035709e-07\n",
      "249   commands  3.017344e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.979606                    0.000000\n",
      "2       had  0.000766                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           a  9.497755e-01\n",
      "1         one  4.276532e-02\n",
      "2          an  2.173155e-03\n",
      "3         the  2.157749e-03\n",
      "4        very  5.338201e-04\n",
      "..        ...           ...\n",
      "245    normal  9.124297e-07\n",
      "246      pale  9.090961e-07\n",
      "247     apple  8.975439e-07\n",
      "248       are  8.950633e-07\n",
      "249        ho  8.847924e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: beautifull\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0        round  0.148541\n",
      "1        brown  0.082408\n",
      "2        black  0.069239\n",
      "3        green  0.039812\n",
      "4        large  0.037479\n",
      "..         ...       ...\n",
      "245   flicking  0.000271\n",
      "246  ##ceptive  0.000270\n",
      "247     clever  0.000269\n",
      "248      angry  0.000268\n",
      "249     secret  0.000268\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "63  beautiful  0.001823                         0.1\n",
      "beautifull -> beautiful\n",
      "{'raw': 'beautifull', 'corrected': 'beautiful', 'span': '[42, 52]', 'type': 'contextual'}\n",
      "**************************************************\n",
      "Token: cars\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          cats  0.730647\n",
      "1          they  0.216030\n",
      "2            it  0.005759\n",
      "3          dogs  0.005017\n",
      "4        humans  0.003801\n",
      "..          ...       ...\n",
      "245         who  0.000008\n",
      "246        baby  0.000008\n",
      "247  everything  0.000008\n",
      "248    vehicles  0.000008\n",
      "249    diamonds  0.000008\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      cats  0.730647                        0.25\n",
      "cars -> cats\n",
      "{'raw': 'cars', 'corrected': 'cats', 'span': '[0, 4]', 'type': 'contextual'}\n",
      "**************************************************\n",
      "Token: cats\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          cats  0.730647\n",
      "1          they  0.216030\n",
      "2            it  0.005759\n",
      "3          dogs  0.005017\n",
      "4        humans  0.003801\n",
      "..          ...       ...\n",
      "245         who  0.000008\n",
      "246        baby  0.000008\n",
      "247  everything  0.000008\n",
      "248    vehicles  0.000008\n",
      "249    diamonds  0.000008\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       cats  0.730647                        0.00\n",
      "6        cat  0.002942                        0.25\n",
      "32      rats  0.000238                        0.25\n",
      "33      bats  0.000230                        0.25\n",
      "cats -> cats\n",
      "**************************************************\n",
      "Token: have\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        have  9.915218e-01\n",
      "1         are  1.631465e-03\n",
      "2     possess  1.611670e-03\n",
      "3         has  1.394418e-03\n",
      "4        show  4.405547e-04\n",
      "..        ...           ...\n",
      "245   suggest  5.871368e-07\n",
      "246     breed  5.809515e-07\n",
      "247  produces  5.788731e-07\n",
      "248      draw  5.758173e-07\n",
      "249  develops  5.731278e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      have  0.991522                         0.0\n",
      "have -> have\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          very  0.498812\n",
      "1          many  0.089064\n",
      "2          some  0.031186\n",
      "3        really  0.020070\n",
      "4          such  0.019526\n",
      "..          ...       ...\n",
      "245         has  0.000081\n",
      "246      having  0.000081\n",
      "247      beauty  0.000080\n",
      "248   aesthetic  0.000080\n",
      "249  definitely  0.000079\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      very  0.498812                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: sweet\n",
      "Predicts: \n",
      "\n",
      "          token_str     score\n",
      "0        attractive  0.114004\n",
      "1         beautiful  0.100591\n",
      "2              cute  0.086600\n",
      "3            unique  0.047575\n",
      "4           special  0.046831\n",
      "..              ...       ...\n",
      "245           mixed  0.000115\n",
      "246         slender  0.000114\n",
      "247      intriguing  0.000113\n",
      "248  distinguishing  0.000113\n",
      "249            best  0.000112\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "43     sweet  0.002451                         0.0\n",
      "sweet -> sweet\n",
      "**************************************************\n",
      "Token: features\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0             ears  0.174290\n",
      "1             pets  0.086584\n",
      "2              fur  0.078622\n",
      "3    personalities  0.038857\n",
      "4            taste  0.036810\n",
      "..             ...       ...\n",
      "245    accessories  0.000170\n",
      "246      childhood  0.000167\n",
      "247           tits  0.000167\n",
      "248     perception  0.000166\n",
      "249        touches  0.000166\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "45   features  0.003815                        0.00\n",
      "62  creatures  0.002445                        0.25\n",
      "features -> features\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0             .  7.703379e-01\n",
      "1             :  6.338237e-02\n",
      "2             ,  4.723988e-02\n",
      "3             ;  3.989726e-02\n",
      "4           and  3.233065e-02\n",
      "..          ...           ...\n",
      "245        many  5.716093e-07\n",
      "246  consisting  5.698812e-07\n",
      "247    suddenly  5.691523e-07\n",
      "248           1  5.665615e-07\n",
      "249         did  5.648432e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "45   features  0.003815                        0.00\n",
      "62  creatures  0.002445                        0.25\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0          it  0.933854\n",
      "1         one  0.018278\n",
      "2         cat  0.017062\n",
      "3        cats  0.005900\n",
      "4        each  0.005158\n",
      "..        ...       ...\n",
      "245      tick  0.000007\n",
      "246         .  0.000007\n",
      "247     goats  0.000007\n",
      "248     rover  0.000007\n",
      "249        to  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.933854                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          has  9.910017e-01\n",
      "1         have  5.901625e-03\n",
      "2    possesses  5.861947e-04\n",
      "3          had  5.115345e-04\n",
      "4        bears  3.895882e-04\n",
      "..         ...           ...\n",
      "245       owes  1.490854e-07\n",
      "246     ##arts  1.485201e-07\n",
      "247   produced  1.468330e-07\n",
      "248     plants  1.456113e-07\n",
      "249      seeks  1.450744e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.991002                    0.000000\n",
      "3       had  0.000512                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           a  9.711115e-01\n",
      "1         one  2.769010e-02\n",
      "2         the  4.289299e-04\n",
      "3          an  3.009702e-04\n",
      "4        very  1.128861e-04\n",
      "..        ...           ...\n",
      "245      they  8.560556e-08\n",
      "246     thick  8.252132e-08\n",
      "247        ou  8.223724e-08\n",
      "248         0  8.214818e-08\n",
      "249      left  8.187991e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: beautiful\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       round  0.149555\n",
      "1       brown  0.083190\n",
      "2       black  0.066572\n",
      "3       large  0.037893\n",
      "4        good  0.036975\n",
      "..        ...       ...\n",
      "245     poked  0.000270\n",
      "246   rolling  0.000268\n",
      "247     angry  0.000268\n",
      "248  laughing  0.000268\n",
      "249   reddish  0.000263\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str    score  edit_distance_to_len_ratio\n",
      "68  beautiful  0.00165                         0.0\n",
      "beautiful -> beautiful\n",
      "**************************************************\n",
      "Token: eye\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         eyes  0.591590\n",
      "1         ears  0.104622\n",
      "2         legs  0.087865\n",
      "3        faces  0.042724\n",
      "4        heads  0.033132\n",
      "..         ...       ...\n",
      "245       blue  0.000014\n",
      "246   bedrooms  0.000014\n",
      "247      belly  0.000014\n",
      "248      souls  0.000014\n",
      "249  qualities  0.000013\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.591590                    0.333333\n",
      "76       eye  0.000106                    0.000000\n",
      "eye -> eye\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           ,  0.967388\n",
      "1         and  0.023625\n",
      "2     ##balls  0.002909\n",
      "3       ##lid  0.000675\n",
      "4        with  0.000645\n",
      "..        ...       ...\n",
      "245    ##felt  0.000001\n",
      "246       had  0.000001\n",
      "247     shine  0.000001\n",
      "248    ##tops  0.000001\n",
      "249      gaze  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.591590                    0.333333\n",
      "76       eye  0.000106                    0.000000\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: adorably\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0           two  0.669660\n",
      "1         three  0.116771\n",
      "2          four  0.104936\n",
      "3          five  0.025887\n",
      "4           six  0.017305\n",
      "..          ...       ...\n",
      "245      simple  0.000014\n",
      "246  attractive  0.000014\n",
      "247       fours  0.000014\n",
      "248      petite  0.000013\n",
      "249          as  0.000013\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "adorably -> adorably\n",
      "**************************************************\n",
      "Token: tiny\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0           soft  0.156512\n",
      "1           cute  0.089967\n",
      "2          large  0.076037\n",
      "3          small  0.068978\n",
      "4            big  0.064751\n",
      "..           ...       ...\n",
      "245         many  0.000131\n",
      "246         dull  0.000129\n",
      "247  fascinating  0.000129\n",
      "248         tame  0.000128\n",
      "249         loud  0.000128\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "6        tiny  0.043006                        0.00\n",
      "229      tidy  0.000141                        0.25\n",
      "tiny -> tiny\n",
      "**************************************************\n",
      "Token: paws\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        nose  0.452259\n",
      "1        ears  0.104111\n",
      "2       teeth  0.078387\n",
      "3        feet  0.058718\n",
      "4       mouth  0.048883\n",
      "..        ...       ...\n",
      "245   numbers  0.000012\n",
      "246      cute  0.000012\n",
      "247    ##foot  0.000011\n",
      "248      pink  0.000011\n",
      "249    radius  0.000011\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "12      paws  0.009522                        0.00\n",
      "17       paw  0.005642                        0.25\n",
      "27      jaws  0.001654                        0.25\n",
      "paws -> paws\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        with  7.431141e-01\n",
      "1           ,  2.251920e-01\n",
      "2         and  2.200083e-02\n",
      "3     without  1.998577e-03\n",
      "4        like  8.078933e-04\n",
      "..        ...           ...\n",
      "245    owning  9.386274e-07\n",
      "246       off  9.370666e-07\n",
      "247    flying  9.347461e-07\n",
      "248       one  9.338576e-07\n",
      "249  slightly  9.304352e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "12      paws  0.009522                        0.00\n",
      "17       paw  0.005642                        0.25\n",
      "27      jaws  0.001654                        0.25\n",
      ", -> with\n",
      "{'raw': ',', 'corrected': 'with', 'span': '[75, 76]', 'type': 'contextual'}\n",
      "**************************************************\n",
      "Token: cats\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         cats  0.712699\n",
      "1         they  0.233161\n",
      "2           it  0.006552\n",
      "3         dogs  0.004525\n",
      "4       humans  0.003796\n",
      "..         ...       ...\n",
      "245  sometimes  0.000008\n",
      "246     ravens  0.000008\n",
      "247   diamonds  0.000008\n",
      "248    giggles  0.000008\n",
      "249      doors  0.000008\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       cats  0.712699                        0.00\n",
      "7        cat  0.002740                        0.25\n",
      "31      rats  0.000265                        0.25\n",
      "36      bats  0.000222                        0.25\n",
      "cats -> cats\n",
      "**************************************************\n",
      "Token: have\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        have  9.908742e-01\n",
      "1         are  1.787634e-03\n",
      "2     possess  1.657947e-03\n",
      "3         has  1.455844e-03\n",
      "4        show  4.878830e-04\n",
      "..        ...           ...\n",
      "245    really  6.561168e-07\n",
      "246     human  6.551970e-07\n",
      "247  develops  6.533656e-07\n",
      "248  produces  6.500405e-07\n",
      "249  comprise  6.484895e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      have  0.990874                         0.0\n",
      "have -> have\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          very  0.494156\n",
      "1          many  0.083181\n",
      "2          some  0.029380\n",
      "3        really  0.019651\n",
      "4        pretty  0.018605\n",
      "..          ...       ...\n",
      "245  surprising  0.000085\n",
      "246   marvelous  0.000083\n",
      "247   aesthetic  0.000082\n",
      "248     elegant  0.000082\n",
      "249    handsome  0.000082\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      very  0.494156                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: sweet\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0    attractive  0.112511\n",
      "1     beautiful  0.090318\n",
      "2          cute  0.083491\n",
      "3       similar  0.053114\n",
      "4      delicate  0.049123\n",
      "..          ...       ...\n",
      "245      detail  0.000126\n",
      "246   offensive  0.000126\n",
      "247  noteworthy  0.000123\n",
      "248        mild  0.000122\n",
      "249  delightful  0.000122\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "46     sweet  0.002346                         0.0\n",
      "sweet -> sweet\n",
      "**************************************************\n",
      "Token: features\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0             ears  0.178810\n",
      "1              fur  0.092002\n",
      "2             pets  0.078623\n",
      "3    personalities  0.040925\n",
      "4            taste  0.036333\n",
      "..             ...       ...\n",
      "245          bells  0.000171\n",
      "246         shapes  0.000171\n",
      "247          belly  0.000170\n",
      "248       tempered  0.000170\n",
      "249         kitten  0.000168\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "45   features  0.003918                        0.00\n",
      "66  creatures  0.002170                        0.25\n",
      "features -> features\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           .  7.392534e-01\n",
      "1           :  7.527990e-02\n",
      "2           ,  5.496104e-02\n",
      "3           ;  4.442289e-02\n",
      "4         and  3.179400e-02\n",
      "..        ...           ...\n",
      "245        no  6.564961e-07\n",
      "246  suddenly  6.489690e-07\n",
      "247     found  6.483435e-07\n",
      "248      many  6.477675e-07\n",
      "249       can  6.436626e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "45   features  0.003918                        0.00\n",
      "66  creatures  0.002170                        0.25\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0          it  0.938017\n",
      "1         one  0.018050\n",
      "2         cat  0.012919\n",
      "3        each  0.005556\n",
      "4        cats  0.004871\n",
      "..        ...       ...\n",
      "245     rover  0.000007\n",
      "246     paper  0.000007\n",
      "247      cara  0.000007\n",
      "248   species  0.000007\n",
      "249   hissing  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.938017                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          has  9.900554e-01\n",
      "1         have  6.638397e-03\n",
      "2          had  5.709118e-04\n",
      "3    possesses  5.662647e-04\n",
      "4        bears  4.378551e-04\n",
      "..         ...           ...\n",
      "245      bites  1.727651e-07\n",
      "246     scores  1.699341e-07\n",
      "247     plants  1.696544e-07\n",
      "248          a  1.686514e-07\n",
      "249          \"  1.679843e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.990055                    0.000000\n",
      "2       had  0.000571                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           a  9.597966e-01\n",
      "1         one  3.881061e-02\n",
      "2         the  4.930736e-04\n",
      "3          an  3.631299e-04\n",
      "4        very  1.042452e-04\n",
      "..        ...           ...\n",
      "245     shiny  9.788803e-08\n",
      "246       are  9.741307e-08\n",
      "247    wicked  9.717665e-08\n",
      "248     truly  9.711977e-08\n",
      "249         7  9.704533e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: beautiful\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       round  0.158927\n",
      "1       brown  0.081744\n",
      "2       black  0.064118\n",
      "3       large  0.039004\n",
      "4        good  0.034976\n",
      "..        ...       ...\n",
      "245      disc  0.000271\n",
      "246   serious  0.000270\n",
      "247         +  0.000267\n",
      "248    unique  0.000265\n",
      "249      type  0.000264\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "65  beautiful  0.001766                         0.0\n",
      "beautiful -> beautiful\n",
      "**************************************************\n",
      "Token: eye\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        eyes  0.577927\n",
      "1        ears  0.110175\n",
      "2        legs  0.089038\n",
      "3       faces  0.039913\n",
      "4       heads  0.037213\n",
      "..        ...       ...\n",
      "245  coloring  0.000014\n",
      "246  coloured  0.000014\n",
      "247     nasal  0.000014\n",
      "248     smell  0.000014\n",
      "249    tigers  0.000014\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.577927                    0.333333\n",
      "72       eye  0.000126                    0.000000\n",
      "eye -> eye\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0            ,  0.977217\n",
      "1          and  0.014600\n",
      "2      ##balls  0.002552\n",
      "3         with  0.000633\n",
      "4        ##lid  0.000500\n",
      "..         ...       ...\n",
      "245      candy  0.000001\n",
      "246      types  0.000001\n",
      "247  creatures  0.000001\n",
      "248     socket  0.000001\n",
      "249    however  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.577927                    0.333333\n",
      "72       eye  0.000126                    0.000000\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: adorably\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0         two  0.815623\n",
      "1       three  0.070463\n",
      "2        four  0.058922\n",
      "3        five  0.011865\n",
      "4         six  0.009683\n",
      "..        ...       ...\n",
      "245     thick  0.000005\n",
      "246      slim  0.000005\n",
      "247     first  0.000005\n",
      "248     often  0.000005\n",
      "249     thumb  0.000005\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "adorably -> adorably\n",
      "**************************************************\n",
      "Token: tiny\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          cute  0.171242\n",
      "1         small  0.072999\n",
      "2          tiny  0.065215\n",
      "3          soft  0.062338\n",
      "4         large  0.061621\n",
      "..          ...       ...\n",
      "245        lazy  0.000158\n",
      "246     refined  0.000157\n",
      "247  immaculate  0.000155\n",
      "248     muscled  0.000154\n",
      "249   dangerous  0.000154\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "2        tiny  0.065215                        0.00\n",
      "229      tidy  0.000170                        0.25\n",
      "tiny -> tiny\n",
      "**************************************************\n",
      "Token: pawswith\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           ,  0.429067\n",
      "1         but  0.220979\n",
      "2         and  0.157880\n",
      "3        very  0.021210\n",
      "4        long  0.015062\n",
      "..        ...       ...\n",
      "245  sporting  0.000069\n",
      "246     while  0.000069\n",
      "247     touch  0.000069\n",
      "248   painful  0.000068\n",
      "249    almost  0.000068\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "pawswith -> pawswith\n",
      "**************************************************\n",
      "Token: sharp\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0      little  0.166271\n",
      "1        tiny  0.141268\n",
      "2          no  0.079940\n",
      "3       sharp  0.066645\n",
      "4       small  0.057455\n",
      "..        ...       ...\n",
      "245       its  0.000190\n",
      "246  metallic  0.000190\n",
      "247   walking  0.000190\n",
      "248    glossy  0.000189\n",
      "249     magic  0.000189\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "3       sharp  0.066645                         0.0\n",
      "9       short  0.017606                         0.4\n",
      "81       hard  0.000801                         0.4\n",
      "155     scary  0.000361                         0.4\n",
      "sharp -> sharp\n",
      "**************************************************\n",
      "Token: claws\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       claws  0.712735\n",
      "1       nails  0.134536\n",
      "2       teeth  0.062087\n",
      "3        toes  0.022931\n",
      "4      hooves  0.014571\n",
      "..        ...       ...\n",
      "245    enamel  0.000004\n",
      "246      spit  0.000004\n",
      "247    breath  0.000004\n",
      "248      spur  0.000004\n",
      "249  memories  0.000004\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0      claws  0.712735                         0.0\n",
      "9       paws  0.004029                         0.4\n",
      "22      claw  0.000303                         0.2\n",
      "29      jaws  0.000175                         0.4\n",
      "claws -> claws\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           ,  9.967991e-01\n",
      "1           ;  8.876361e-04\n",
      "2           .  7.439798e-04\n",
      "3         and  1.529756e-04\n",
      "4         ...  1.080073e-04\n",
      "..        ...           ...\n",
      "245    fitted  6.621647e-07\n",
      "246   feather  6.586284e-07\n",
      "247     birds  6.464939e-07\n",
      "248   capable  6.450485e-07\n",
      "249  matching  6.405972e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0      claws  0.712735                         0.0\n",
      "9       paws  0.004029                         0.4\n",
      "22      claw  0.000303                         0.2\n",
      "29      jaws  0.000175                         0.4\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: and\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0         and  9.973839e-01\n",
      "1         but  4.135603e-04\n",
      "2        with  3.443704e-04\n",
      "3        plus  2.543816e-04\n",
      "4          or  2.000680e-04\n",
      "..        ...           ...\n",
      "245       new  3.321879e-07\n",
      "246      dark  3.318402e-07\n",
      "247   showing  3.317064e-07\n",
      "248   perhaps  3.313842e-07\n",
      "249       put  3.304986e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       and  0.997384                         0.0\n",
      "and -> and\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0            a  0.974591\n",
      "1          one  0.016451\n",
      "2         very  0.001345\n",
      "3        small  0.001238\n",
      "4          the  0.000602\n",
      "..         ...       ...\n",
      "245  brilliant  0.000001\n",
      "246       semi  0.000001\n",
      "247      curly  0.000001\n",
      "248   possibly  0.000001\n",
      "249   multiple  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "8       two  0.000324                         0.0\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: perky\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0    beautiful  0.176262\n",
      "1         tiny  0.150592\n",
      "2        small  0.124252\n",
      "3        large  0.067858\n",
      "4       lovely  0.035139\n",
      "..         ...       ...\n",
      "245     purple  0.000212\n",
      "246      split  0.000210\n",
      "247    healthy  0.000208\n",
      "248          -  0.000205\n",
      "249   external  0.000203\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "124      very  0.000565                         0.4\n",
      "perky -> very\n",
      "{'raw': 'perky', 'corrected': 'very', 'span': '[101, 106]', 'type': 'contextual'}\n",
      "**************************************************\n",
      "Token: cats\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         cats  0.713912\n",
      "1         they  0.233402\n",
      "2           it  0.010978\n",
      "3          cat  0.003828\n",
      "4      animals  0.002747\n",
      "..         ...       ...\n",
      "245      users  0.000007\n",
      "246    minutes  0.000007\n",
      "247     fruits  0.000007\n",
      "248     angels  0.000007\n",
      "249  guardians  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       cats  0.713912                        0.00\n",
      "3        cat  0.003828                        0.25\n",
      "43      bats  0.000160                        0.25\n",
      "44      rats  0.000158                        0.25\n",
      "cats -> cats\n",
      "**************************************************\n",
      "Token: have\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        have  0.986798\n",
      "1         are  0.002572\n",
      "2         has  0.002230\n",
      "3     possess  0.002091\n",
      "4        show  0.000704\n",
      "..        ...       ...\n",
      "245   promote  0.000001\n",
      "246   harbour  0.000001\n",
      "247        to  0.000001\n",
      "248      draw  0.000001\n",
      "249        on  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      have  0.986798                         0.0\n",
      "have -> have\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          very  0.469609\n",
      "1          many  0.082010\n",
      "2          some  0.027787\n",
      "3          such  0.021791\n",
      "4        pretty  0.019761\n",
      "..          ...       ...\n",
      "245   identical  0.000098\n",
      "246    fabulous  0.000097\n",
      "247  definitely  0.000097\n",
      "248  expressive  0.000097\n",
      "249  additional  0.000097\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      very  0.469609                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: sweet\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0        beautiful  0.122067\n",
      "1       attractive  0.100929\n",
      "2             cute  0.065573\n",
      "3         delicate  0.054503\n",
      "4           unique  0.049823\n",
      "..             ...       ...\n",
      "245     vulnerable  0.000131\n",
      "246       abstract  0.000131\n",
      "247        plastic  0.000131\n",
      "248        organic  0.000129\n",
      "249  distinguished  0.000128\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str    score  edit_distance_to_len_ratio\n",
      "56     sweet  0.00189                         0.0\n",
      "sweet -> sweet\n",
      "**************************************************\n",
      "Token: features\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         ears  0.136493\n",
      "1          fur  0.076316\n",
      "2         pets  0.056128\n",
      "3        taste  0.051402\n",
      "4        smell  0.036100\n",
      "..         ...       ...\n",
      "245     shapes  0.000201\n",
      "246    giggles  0.000198\n",
      "247   habitats  0.000197\n",
      "248  intuition  0.000196\n",
      "249    mothers  0.000195\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "54   features  0.003209                        0.00\n",
      "74  creatures  0.002012                        0.25\n",
      "features -> features\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0            .  7.211725e-01\n",
      "1            :  7.529560e-02\n",
      "2            ,  6.994314e-02\n",
      "3            ;  3.902196e-02\n",
      "4          and  3.800625e-02\n",
      "..         ...           ...\n",
      "245  believing  8.031706e-07\n",
      "246  worldwide  7.977650e-07\n",
      "247        did  7.842345e-07\n",
      "248  involving  7.837694e-07\n",
      "249    somehow  7.804659e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "54   features  0.003209                        0.00\n",
      "74  creatures  0.002012                        0.25\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0           it  0.944469\n",
      "1          one  0.015191\n",
      "2          cat  0.012466\n",
      "3         cats  0.005131\n",
      "4         each  0.004291\n",
      "..         ...       ...\n",
      "245     hunter  0.000006\n",
      "246       both  0.000006\n",
      "247  curiosity  0.000006\n",
      "248       pony  0.000006\n",
      "249      every  0.000006\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.944469                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0            has  9.855988e-01\n",
      "1           have  1.008721e-02\n",
      "2            had  9.325345e-04\n",
      "3      possesses  6.876419e-04\n",
      "4          bears  5.077592e-04\n",
      "..           ...           ...\n",
      "245           in  2.490769e-07\n",
      "246          put  2.478150e-07\n",
      "247       awards  2.476572e-07\n",
      "248  proportions  2.473062e-07\n",
      "249       writes  2.464810e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.985599                    0.000000\n",
      "2       had  0.000933                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           a  9.558343e-01\n",
      "1         one  4.201113e-02\n",
      "2         the  8.625567e-04\n",
      "3          an  4.001343e-04\n",
      "4        very  2.173159e-04\n",
      "..        ...           ...\n",
      "245      from  1.746525e-07\n",
      "246      hair  1.745088e-07\n",
      "247     brand  1.741846e-07\n",
      "248    double  1.726821e-07\n",
      "249    deeply  1.724691e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: beautiful\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           -  0.251968\n",
      "1       large  0.065007\n",
      "2        good  0.061856\n",
      "3       round  0.044803\n",
      "4         big  0.042874\n",
      "..        ...       ...\n",
      "245         )  0.000204\n",
      "246      long  0.000200\n",
      "247        on  0.000198\n",
      "248         =  0.000198\n",
      "249      disc  0.000198\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "54  beautiful  0.001639                         0.0\n",
      "beautiful -> beautiful\n",
      "**************************************************\n",
      "Token: eye\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         eyes  0.453038\n",
      "1         ears  0.249296\n",
      "2         legs  0.059659\n",
      "3        heads  0.056068\n",
      "4        faces  0.038650\n",
      "..         ...       ...\n",
      "245     joints  0.000014\n",
      "246      skull  0.000014\n",
      "247   forehead  0.000014\n",
      "248      mates  0.000014\n",
      "249  hindwings  0.000014\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.453038                    0.333333\n",
      "82       eye  0.000102                    0.000000\n",
      "eye -> eye\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           ,  0.951365\n",
      "1         and  0.032824\n",
      "2     ##balls  0.003097\n",
      "3        with  0.002663\n",
      "4           -  0.000927\n",
      "..        ...       ...\n",
      "245    leaves  0.000003\n",
      "246       big  0.000003\n",
      "247    ##fish  0.000003\n",
      "248   ##glass  0.000003\n",
      "249    points  0.000003\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       eyes  0.453038                    0.333333\n",
      "82       eye  0.000102                    0.000000\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: adorably\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0           two  0.769462\n",
      "1         three  0.092984\n",
      "2          four  0.068412\n",
      "3          five  0.015767\n",
      "4           six  0.013073\n",
      "..          ...       ...\n",
      "245  individual  0.000005\n",
      "246        into  0.000005\n",
      "247   including  0.000005\n",
      "248      unique  0.000005\n",
      "249        dual  0.000005\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "adorably -> adorably\n",
      "**************************************************\n",
      "Token: tiny\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         cute  0.106161\n",
      "1    beautiful  0.086216\n",
      "2        small  0.069074\n",
      "3         soft  0.067457\n",
      "4        large  0.067375\n",
      "..         ...       ...\n",
      "245     edible  0.000202\n",
      "246      brave  0.000199\n",
      "247  ferocious  0.000195\n",
      "248        toy  0.000189\n",
      "249     deadly  0.000188\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "5      tiny  0.047522                         0.0\n",
      "tiny -> tiny\n",
      "**************************************************\n",
      "Token: pawswith\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           ,  0.349752\n",
      "1         and  0.223849\n",
      "2         but  0.186418\n",
      "3        very  0.041675\n",
      "4        long  0.017974\n",
      "..        ...       ...\n",
      "245      snow  0.000078\n",
      "246      cold  0.000078\n",
      "247      huge  0.000078\n",
      "248       ear  0.000077\n",
      "249     which  0.000076\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "pawswith -> pawswith\n",
      "**************************************************\n",
      "Token: sharp\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0       little  0.150969\n",
      "1         tiny  0.121167\n",
      "2           no  0.076919\n",
      "3        sharp  0.067411\n",
      "4        small  0.066338\n",
      "..         ...       ...\n",
      "245     bright  0.000208\n",
      "246  expensive  0.000206\n",
      "247      clean  0.000203\n",
      "248    glowing  0.000202\n",
      "249    feather  0.000201\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "3       sharp  0.067411                         0.0\n",
      "10      short  0.015026                         0.4\n",
      "87       hard  0.000775                         0.4\n",
      "161     scary  0.000357                         0.4\n",
      "sharp -> sharp\n",
      "**************************************************\n",
      "Token: claws\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0         claws  0.705040\n",
      "1         nails  0.111470\n",
      "2         teeth  0.088074\n",
      "3          toes  0.017717\n",
      "4        hooves  0.015101\n",
      "..          ...       ...\n",
      "245      curled  0.000006\n",
      "246     feather  0.000006\n",
      "247       posts  0.000006\n",
      "248        tops  0.000006\n",
      "249  complaints  0.000006\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0      claws  0.705040                         0.0\n",
      "9       paws  0.003583                         0.4\n",
      "23      claw  0.000370                         0.2\n",
      "31      jaws  0.000202                         0.4\n",
      "claws -> claws\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0             ,  0.992227\n",
      "1             ;  0.002291\n",
      "2             .  0.001996\n",
      "3           and  0.000335\n",
      "4           ...  0.000267\n",
      "..          ...       ...\n",
      "245        near  0.000001\n",
      "246   elongated  0.000001\n",
      "247         big  0.000001\n",
      "248     handles  0.000001\n",
      "249  constantly  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0      claws  0.705040                         0.0\n",
      "9       paws  0.003583                         0.4\n",
      "23      claw  0.000370                         0.2\n",
      "31      jaws  0.000202                         0.4\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: and\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0           and  0.985792\n",
      "1           the  0.001906\n",
      "2          with  0.001251\n",
      "3           but  0.000988\n",
      "4          even  0.000766\n",
      "..          ...       ...\n",
      "245        nice  0.000002\n",
      "246     located  0.000002\n",
      "247  originally  0.000002\n",
      "248   typically  0.000002\n",
      "249        full  0.000002\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0        and  0.985792                    0.000000\n",
      "20        an  0.000104                    0.333333\n",
      "and -> and\n",
      "**************************************************\n",
      "Token: two\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0               a  0.584517\n",
      "1             one  0.219584\n",
      "2             the  0.095325\n",
      "3             its  0.054828\n",
      "4           their  0.005449\n",
      "..            ...       ...\n",
      "245           fat  0.000013\n",
      "246            11  0.000013\n",
      "247  surprisingly  0.000013\n",
      "248        closed  0.000013\n",
      "249        behind  0.000013\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "6        two  0.002838                    0.000000\n",
      "20        to  0.000434                    0.333333\n",
      "two -> two\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0    beautiful  0.176262\n",
      "1         tiny  0.150592\n",
      "2        small  0.124252\n",
      "3        large  0.067858\n",
      "4       lovely  0.035139\n",
      "..         ...       ...\n",
      "245     purple  0.000212\n",
      "246      split  0.000210\n",
      "247    healthy  0.000208\n",
      "248          -  0.000205\n",
      "249   external  0.000203\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "124      very  0.000565                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: ear\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        ears  0.972465\n",
      "1        eyes  0.005085\n",
      "2        toes  0.004776\n",
      "3        feet  0.003507\n",
      "4        legs  0.002351\n",
      "..        ...       ...\n",
      "245   cousins  0.000001\n",
      "246     brain  0.000001\n",
      "247      bits  0.000001\n",
      "248   screams  0.000001\n",
      "249    eagles  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       ears  0.972465                    0.333333\n",
      "19       ear  0.000187                    0.000000\n",
      "ear -> ear\n",
      "**************************************************\n",
      "Token: which\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        that  0.326383\n",
      "1      ##less  0.109779\n",
      "2       which  0.095449\n",
      "3        ##ed  0.067071\n",
      "4        ears  0.049112\n",
      "..        ...       ...\n",
      "245     boxes  0.000100\n",
      "246     ##mes  0.000099\n",
      "247      worn  0.000099\n",
      "248    scales  0.000098\n",
      "249      cubs  0.000098\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "2       which  0.095449                         0.0\n",
      "194     white  0.000140                         0.4\n",
      "which -> which\n",
      "**************************************************\n",
      "Token: are\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0           are  0.869858\n",
      "1            is  0.120949\n",
      "2          were  0.001326\n",
      "3        become  0.001244\n",
      "4           get  0.000666\n",
      "..          ...       ...\n",
      "245        kind  0.000001\n",
      "246       touch  0.000001\n",
      "247     already  0.000001\n",
      "248  expression  0.000001\n",
      "249          we  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       are  0.869858                         0.0\n",
      "are -> are\n",
      "**************************************************\n",
      "Token: very\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0           very  0.807857\n",
      "1      extremely  0.094406\n",
      "2         highly  0.017786\n",
      "3          quite  0.013971\n",
      "4     especially  0.006059\n",
      "..           ...       ...\n",
      "245   themselves  0.000010\n",
      "246     sexually  0.000010\n",
      "247  necessarily  0.000010\n",
      "248        madly  0.000010\n",
      "249          but  0.000009\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      very  0.807857                         0.0\n",
      "very -> very\n",
      "**************************************************\n",
      "Token: sensitive\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0      sensitive  0.967452\n",
      "1     responsive  0.017900\n",
      "2          alert  0.004806\n",
      "3    sensitivity  0.002107\n",
      "4      attracted  0.001684\n",
      "..           ...       ...\n",
      "245     directed  0.000001\n",
      "246         akin  0.000001\n",
      "247       silent  0.000001\n",
      "248   supportive  0.000001\n",
      "249  destructive  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0  sensitive  0.967452                         0.0\n",
      "sensitive -> sensitive\n",
      "**************************************************\n",
      "Token: to\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          to  9.728771e-01\n",
      "1         for  1.778181e-02\n",
      "2     towards  4.550613e-03\n",
      "3        with  5.773687e-04\n",
      "4     against  5.129644e-04\n",
      "..        ...           ...\n",
      "245        mo  4.162648e-07\n",
      "246   attract  4.156380e-07\n",
      "247      your  4.144316e-07\n",
      "248   leaving  4.114830e-07\n",
      "249    nearby  4.088084e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        to  0.972877                         0.0\n",
      "to -> to\n",
      "**************************************************\n",
      "Token: sounds\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0         touch  0.529693\n",
      "1         light  0.108610\n",
      "2          cold  0.054378\n",
      "3          heat  0.045953\n",
      "4      sunlight  0.035801\n",
      "..          ...       ...\n",
      "245  everything  0.000076\n",
      "246        wood  0.000075\n",
      "247  percussion  0.000075\n",
      "248     rodents  0.000073\n",
      "249      colors  0.000073\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "14      sound  0.005067                    0.166667\n",
      "43     sounds  0.000885                    0.000000\n",
      "123      suns  0.000202                    0.333333\n",
      "145    wounds  0.000160                    0.166667\n",
      "sounds -> sounds\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0            .  9.991720e-01\n",
      "1            ;  3.299965e-04\n",
      "2            ,  2.326727e-04\n",
      "3            !  1.349540e-04\n",
      "4          ...  5.638042e-05\n",
      "..         ...           ...\n",
      "245       ##as  4.946645e-09\n",
      "246  initially  4.902022e-09\n",
      "247          ~  4.783502e-09\n",
      "248     called  4.758349e-09\n",
      "249          }  4.752263e-09\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "14      sound  0.005067                    0.166667\n",
      "43     sounds  0.000885                    0.000000\n",
      "123      suns  0.000202                    0.333333\n",
      "145    wounds  0.000160                    0.166667\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0          it  0.983747\n",
      "1         cat  0.006442\n",
      "2        cats  0.002137\n",
      "3         she  0.001016\n",
      "4        this  0.001013\n",
      "..        ...       ...\n",
      "245    pigeon  0.000002\n",
      "246        we  0.000002\n",
      "247     [UNK]  0.000002\n",
      "248    horses  0.000002\n",
      "249    mammal  0.000002\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.983747                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0         has  9.964850e-01\n",
      "1        have  1.798051e-03\n",
      "2         had  4.669453e-04\n",
      "3          is  4.547022e-04\n",
      "4    features  1.109094e-04\n",
      "..        ...           ...\n",
      "245    allows  1.380067e-07\n",
      "246   species  1.366843e-07\n",
      "247     hairy  1.361665e-07\n",
      "248      show  1.358518e-07\n",
      "249    create  1.353711e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.996485                    0.000000\n",
      "2       had  0.000467                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "          token_str         score\n",
      "0                 a  9.982993e-01\n",
      "1               one  3.851682e-04\n",
      "2               the  2.449282e-04\n",
      "3                an  2.195664e-04\n",
      "4              very  1.987109e-04\n",
      "..              ...           ...\n",
      "245            warm  2.263720e-07\n",
      "246           often  2.247978e-07\n",
      "247  characteristic  2.245073e-07\n",
      "248            easy  2.240849e-07\n",
      "249             ...  2.231095e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.998299                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: tiny\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0         furry  0.093788\n",
      "1          soft  0.077222\n",
      "2         small  0.060382\n",
      "3         hairy  0.051135\n",
      "4          long  0.048372\n",
      "..          ...       ...\n",
      "245     similar  0.000139\n",
      "246        neat  0.000134\n",
      "247        cold  0.000134\n",
      "248  vulnerable  0.000134\n",
      "249      sparse  0.000133\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "9      tiny  0.035079                         0.0\n",
      "tiny -> tiny\n",
      "**************************************************\n",
      "Token: body\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        body  0.361727\n",
      "1        head  0.320613\n",
      "2        face  0.109006\n",
      "3        tail  0.042561\n",
      "4       chest  0.019519\n",
      "..        ...       ...\n",
      "245    spider  0.000009\n",
      "246       web  0.000009\n",
      "247      bald  0.000009\n",
      "248       rib  0.000009\n",
      "249    ##foot  0.000009\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      body  0.361727                         0.0\n",
      "body -> body\n",
      "**************************************************\n",
      "Token: covered\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0     covered  0.879686\n",
      "1           ,  0.050208\n",
      "2        coat  0.007945\n",
      "3       along  0.006147\n",
      "4    complete  0.004730\n",
      "..        ...       ...\n",
      "245    played  0.000019\n",
      "246      sack  0.000019\n",
      "247   mixture  0.000018\n",
      "248   smeared  0.000018\n",
      "249      rich  0.000018\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0    covered  0.879686                    0.000000\n",
      "15     cover  0.000722                    0.285714\n",
      "17   colored  0.000700                    0.285714\n",
      "covered -> covered\n",
      "**************************************************\n",
      "Token: with\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          in  6.028815e-01\n",
      "1        with  3.578788e-01\n",
      "2          by  3.782479e-02\n",
      "3          on  1.858519e-04\n",
      "4          of  9.801366e-05\n",
      "..        ...           ...\n",
      "245     total  2.472201e-07\n",
      "246      than  2.441224e-07\n",
      "247        wi  2.426575e-07\n",
      "248      deep  2.414557e-07\n",
      "249  opposite  2.411531e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1      with  0.357879                         0.0\n",
      "with -> with\n",
      "**************************************************\n",
      "Token: soft\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        soft  0.163895\n",
      "1       brown  0.078459\n",
      "2       silky  0.077652\n",
      "3       white  0.071513\n",
      "4       thick  0.055312\n",
      "..        ...       ...\n",
      "245     right  0.000098\n",
      "246      coat  0.000097\n",
      "247     rusty  0.000096\n",
      "248       jet  0.000095\n",
      "249       pup  0.000095\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      soft  0.163895                         0.0\n",
      "soft -> soft\n",
      "**************************************************\n",
      "Token: fur\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0            fur  0.898746\n",
      "1          hairs  0.034876\n",
      "2           hair  0.013769\n",
      "3       feathers  0.012214\n",
      "4           skin  0.008646\n",
      "..           ...       ...\n",
      "245        fiber  0.000008\n",
      "246      brushes  0.000008\n",
      "247        scale  0.000008\n",
      "248  furnishings  0.000008\n",
      "249       tracks  0.000008\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       fur  0.898746                         0.0\n",
      "fur -> fur\n",
      "**************************************************\n",
      "Token: and\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0               .  6.174911e-01\n",
      "1             and  3.093906e-01\n",
      "2               ,  3.450322e-02\n",
      "3             but  1.535204e-02\n",
      "4               ;  1.407511e-02\n",
      "..            ...           ...\n",
      "245        mainly  3.427795e-07\n",
      "246      opposite  3.370747e-07\n",
      "247        lastly  3.328275e-07\n",
      "248          note  3.224700e-07\n",
      "249  consequently  3.218835e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1       and  0.309391                         0.0\n",
      "and -> and\n",
      "**************************************************\n",
      "Token: it\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0             it  0.908937\n",
      "1      sometimes  0.020275\n",
      "2        usually  0.015942\n",
      "3          often  0.013406\n",
      "4           also  0.009003\n",
      "..           ...       ...\n",
      "245         over  0.000004\n",
      "246   thankfully  0.000004\n",
      "247    curiously  0.000004\n",
      "248  importantly  0.000004\n",
      "249     together  0.000004\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        it  0.908937                         0.0\n",
      "it -> it\n",
      "**************************************************\n",
      "Token: has\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          has  9.947656e-01\n",
      "1         have  7.786116e-04\n",
      "2          had  6.166431e-04\n",
      "3         gets  5.592118e-04\n",
      "4        grows  4.170327e-04\n",
      "..         ...           ...\n",
      "245      works  4.919297e-07\n",
      "246       acts  4.918575e-07\n",
      "247  surrounds  4.897997e-07\n",
      "248    dresses  4.890343e-07\n",
      "249        get  4.804966e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       has  0.994766                    0.000000\n",
      "2       had  0.000617                    0.333333\n",
      "has -> has\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0            a  0.991327\n",
      "1          one  0.001958\n",
      "2        short  0.001087\n",
      "3        small  0.000775\n",
      "4           no  0.000654\n",
      "..         ...       ...\n",
      "245    similar  0.000001\n",
      "246   multiple  0.000001\n",
      "247    pointed  0.000001\n",
      "248       wild  0.000001\n",
      "249  shortened  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.991327                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: furry\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       short  0.256986\n",
      "1        tiny  0.202110\n",
      "2       small  0.146051\n",
      "3        long  0.107644\n",
      "4      little  0.062457\n",
      "..        ...       ...\n",
      "245      much  0.000081\n",
      "246    female  0.000081\n",
      "247      whip  0.000080\n",
      "248      pure  0.000080\n",
      "249     ##ppy  0.000079\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "14      curly  0.004161                         0.4\n",
      "28      fuzzy  0.001363                         0.4\n",
      "31      furry  0.001269                         0.0\n",
      "68      funny  0.000464                         0.4\n",
      "109     fairy  0.000235                         0.4\n",
      "furry -> furry\n",
      "**************************************************\n",
      "Token: tail\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         tail  0.709906\n",
      "1         head  0.119952\n",
      "2         nose  0.020833\n",
      "3        belly  0.018405\n",
      "4         face  0.016041\n",
      "..         ...       ...\n",
      "245      ##fur  0.000030\n",
      "246       fang  0.000030\n",
      "247  eyelashes  0.000030\n",
      "248       iris  0.000030\n",
      "249       claw  0.000030\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       tail  0.709906                        0.00\n",
      "80     tails  0.000168                        0.25\n",
      "tail -> tail\n",
      "**************************************************\n",
      "Token: as\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            as  9.994199e-01\n",
      "1          very  7.283308e-05\n",
      "2          like  3.074075e-05\n",
      "3         quite  2.086056e-05\n",
      "4           and  1.791593e-05\n",
      "..          ...           ...\n",
      "245     humming  2.531012e-07\n",
      "246  surprising  2.524450e-07\n",
      "247      inside  2.513208e-07\n",
      "248           ?  2.504511e-07\n",
      "249       grows  2.500974e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str    score  edit_distance_to_len_ratio\n",
      "0        as  0.99942                         0.0\n",
      "as -> as\n",
      "**************************************************\n",
      "Token: well\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0         well  9.971693e-01\n",
      "1         tail  1.033212e-03\n",
      "2        usual  2.936721e-04\n",
      "3          fur  9.497331e-05\n",
      "4         hair  8.205306e-05\n",
      "..         ...           ...\n",
      "245   features  6.517175e-07\n",
      "246  livestock  6.500198e-07\n",
      "247  curiosity  6.489464e-07\n",
      "248      input  6.479070e-07\n",
      "249        hat  6.458520e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      well  0.997169                         0.0\n",
      "well -> well\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           .  9.969339e-01\n",
      "1           ,  7.210547e-04\n",
      "2         the  5.754959e-04\n",
      "3         ...  4.966960e-04\n",
      "4           ;  1.928328e-04\n",
      "..        ...           ...\n",
      "245        no  1.495153e-07\n",
      "246    people  1.478975e-07\n",
      "247         6  1.475398e-07\n",
      "248     horse  1.474817e-07\n",
      "249     seven  1.467975e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      well  0.997169                         0.0\n",
      ". -> .\n",
      "**************************************************\n",
      "Token: cats\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0         cats  0.446176\n",
      "1         they  0.364261\n",
      "2           it  0.118664\n",
      "3          cat  0.006384\n",
      "4          you  0.004506\n",
      "..         ...       ...\n",
      "245       here  0.000015\n",
      "246        two  0.000014\n",
      "247   products  0.000014\n",
      "248  buildings  0.000014\n",
      "249      danes  0.000014\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       cats  0.446176                        0.00\n",
      "3        cat  0.006384                        0.25\n",
      "50      rats  0.000220                        0.25\n",
      "68      cars  0.000125                        0.25\n",
      "71      bats  0.000112                        0.25\n",
      "cats -> cats\n",
      "**************************************************\n",
      "Token: have\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        have  9.911267e-01\n",
      "1         has  2.573028e-03\n",
      "2        make  1.063767e-03\n",
      "3         get  6.350349e-04\n",
      "4         are  5.237362e-04\n",
      "..        ...           ...\n",
      "245      come  7.687144e-07\n",
      "246     great  7.643881e-07\n",
      "247     which  7.608549e-07\n",
      "248    formed  7.603754e-07\n",
      "249     speak  7.603537e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      have  0.991127                         0.0\n",
      "have -> have\n",
      "**************************************************\n",
      "Token: an\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          an  9.934681e-01\n",
      "1           a  1.601580e-03\n",
      "2        very  1.529690e-03\n",
      "3        this  7.407861e-04\n",
      "4         the  6.618400e-04\n",
      "..        ...           ...\n",
      "245      made  5.502831e-07\n",
      "246     [UNK]  5.443661e-07\n",
      "247    looked  5.409087e-07\n",
      "248      part  5.325151e-07\n",
      "249      fine  5.319943e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        an  0.993468                         0.0\n",
      "an -> an\n",
      "**************************************************\n",
      "Token: adorable\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          oval  0.216882\n",
      "1    attractive  0.180885\n",
      "2          ugly  0.159564\n",
      "3      adorable  0.154114\n",
      "4       average  0.052725\n",
      "..          ...       ...\n",
      "245   resembled  0.000051\n",
      "246     exposed  0.000051\n",
      "247      abused  0.000051\n",
      "248     ##erine  0.000051\n",
      "249   ##imating  0.000050\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "3  adorable  0.154114                         0.0\n",
      "adorable -> adorable\n",
      "**************************************************\n",
      "Token: face\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          face  0.769413\n",
      "1    appearance  0.080249\n",
      "2          nose  0.038917\n",
      "3          look  0.026668\n",
      "4          head  0.021236\n",
      "..          ...       ...\n",
      "245       frame  0.000013\n",
      "246        ugly  0.000013\n",
      "247     eyebrow  0.000013\n",
      "248         bit  0.000013\n",
      "249       grace  0.000013\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0       face  0.769413                        0.00\n",
      "18     faces  0.001052                        0.25\n",
      "face -> face\n",
      "**************************************************\n",
      "Token: with\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          with  0.718882\n",
      "1             ,  0.247738\n",
      "2           and  0.011116\n",
      "3        having  0.005819\n",
      "4     including  0.002338\n",
      "..          ...       ...\n",
      "245        very  0.000001\n",
      "246  projecting  0.000001\n",
      "247          an  0.000001\n",
      "248      little  0.000001\n",
      "249        more  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      with  0.718882                         0.0\n",
      "with -> with\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           a  9.951947e-01\n",
      "1         one  9.743941e-04\n",
      "2         its  7.386006e-04\n",
      "3         the  4.948413e-04\n",
      "4          an  3.143588e-04\n",
      "..        ...           ...\n",
      "245    though  7.177133e-07\n",
      "246    proper  7.090487e-07\n",
      "247   strange  7.079831e-07\n",
      "248     dirty  7.050522e-07\n",
      "249     young  7.031063e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.995195                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: tiny\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       small  0.217932\n",
      "1         big  0.195101\n",
      "2        cute  0.178672\n",
      "3       large  0.066528\n",
      "4        tiny  0.042372\n",
      "..        ...       ...\n",
      "245   swollen  0.000061\n",
      "246   biggest  0.000061\n",
      "247     puppy  0.000061\n",
      "248  pointing  0.000061\n",
      "249      puff  0.000061\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "4      tiny  0.042372                         0.0\n",
      "tiny -> tiny\n",
      "**************************************************\n",
      "Token: nose\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        nose  0.771236\n",
      "1         eye  0.049235\n",
      "2        chin  0.048437\n",
      "3        eyes  0.019770\n",
      "4    forehead  0.016812\n",
      "..        ...       ...\n",
      "245      ring  0.000007\n",
      "246      form  0.000007\n",
      "247       box  0.000007\n",
      "248     horns  0.000007\n",
      "249    stance  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      nose  0.771236                         0.0\n",
      "nose -> nose\n",
      "**************************************************\n",
      "Token: ,\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0            ,  9.105527e-01\n",
      "1          and  6.493215e-02\n",
      "2         with  1.799562e-02\n",
      "3          but  1.941474e-03\n",
      "4           or  4.848657e-04\n",
      "..         ...           ...\n",
      "245   orbiting  5.943630e-07\n",
      "246      hence  5.913241e-07\n",
      "247       very  5.892407e-07\n",
      "248    whereas  5.887110e-07\n",
      "249  depicting  5.798366e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      nose  0.771236                         0.0\n",
      ", -> ,\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           a  0.974509\n",
      "1        very  0.013411\n",
      "2       small  0.001131\n",
      "3         one  0.000929\n",
      "4         and  0.000907\n",
      "..        ...       ...\n",
      "245   however  0.000003\n",
      "246   classic  0.000003\n",
      "247       ...  0.000003\n",
      "248      have  0.000003\n",
      "249      pale  0.000003\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.974509                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: big\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       small  0.354651\n",
      "1        tiny  0.198064\n",
      "2         big  0.099964\n",
      "3        cute  0.079333\n",
      "4       large  0.053153\n",
      "..        ...       ...\n",
      "245  kindness  0.000071\n",
      "246      pale  0.000070\n",
      "247     curly  0.000070\n",
      "248     poked  0.000070\n",
      "249  horrible  0.000070\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "2       big  0.099964                         0.0\n",
      "big -> big\n",
      "**************************************************\n",
      "Token: mouth\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       mouth  0.338745\n",
      "1    forehead  0.165435\n",
      "2        ears  0.089687\n",
      "3        chin  0.061006\n",
      "4       cheek  0.036409\n",
      "..        ...       ...\n",
      "245    camera  0.000034\n",
      "246     jewel  0.000034\n",
      "247   chuckle  0.000034\n",
      "248  mouthful  0.000034\n",
      "249     ##hat  0.000034\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "0      mouth  0.338745                         0.0\n",
      "40     pouch  0.000756                         0.4\n",
      "61     tooth  0.000400                         0.4\n",
      "95   ##mouth  0.000159                         0.4\n",
      "mouth -> mouth\n",
      "**************************************************\n",
      "Token: and\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0         and  9.869562e-01\n",
      "1           ,  8.265255e-03\n",
      "2        with  2.914283e-03\n",
      "3          or  9.383378e-04\n",
      "4           &  2.000504e-04\n",
      "..        ...           ...\n",
      "245   housing  1.447127e-07\n",
      "246      held  1.440781e-07\n",
      "247     their  1.439223e-07\n",
      "248     ##ing  1.423726e-07\n",
      "249  presents  1.415323e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       and  0.986956                         0.0\n",
      "and -> and\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0            a  9.968337e-01\n",
      "1         very  2.282242e-03\n",
      "2          the  1.760452e-04\n",
      "3         just  6.990383e-05\n",
      "4         with  5.010664e-05\n",
      "..         ...           ...\n",
      "245        red  1.704804e-07\n",
      "246       well  1.696372e-07\n",
      "247   handsome  1.694295e-07\n",
      "248    however  1.682635e-07\n",
      "249  literally  1.680932e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.996834                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: few\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0            few  0.640548\n",
      "1         little  0.207772\n",
      "2          small  0.021151\n",
      "3            big  0.012970\n",
      "4           tiny  0.009967\n",
      "..           ...       ...\n",
      "245         just  0.000042\n",
      "246     wrinkled  0.000041\n",
      "247  microscopic  0.000041\n",
      "248         hare  0.000041\n",
      "249    sensitive  0.000040\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       few  0.640548                         0.0\n",
      "few -> few\n",
      "**************************************************\n",
      "Token: whiskers\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       teeth  0.176672\n",
      "1       hairs  0.130656\n",
      "2       spots  0.042064\n",
      "3       rings  0.033785\n",
      "4      glands  0.033153\n",
      "..        ...       ...\n",
      "245     heads  0.000164\n",
      "246    mouths  0.000163\n",
      "247     ##gly  0.000162\n",
      "248     furry  0.000161\n",
      "249   objects  0.000160\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "whiskers -> whiskers\n",
      "**************************************************\n",
      "Token: under\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0          on  0.827040\n",
      "1       along  0.037059\n",
      "2          in  0.025208\n",
      "3      across  0.021968\n",
      "4       under  0.015536\n",
      "..        ...       ...\n",
      "245  orbiting  0.000006\n",
      "246   stained  0.000005\n",
      "247   reading  0.000005\n",
      "248   curving  0.000005\n",
      "249    circle  0.000005\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "4     under  0.015536                         0.0\n",
      "under -> under\n",
      "**************************************************\n",
      "Token: its\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          the  9.081793e-01\n",
      "1          its  7.346959e-02\n",
      "2        their  9.950437e-03\n",
      "3         each  2.733660e-03\n",
      "4          his  1.101502e-03\n",
      "..         ...           ...\n",
      "245       were  3.183093e-07\n",
      "246    maximum  3.135412e-07\n",
      "247    rounded  3.093716e-07\n",
      "248  prominent  3.089090e-07\n",
      "249      along  3.086098e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1       its  0.073470                    0.000000\n",
      "9        it  0.000407                    0.333333\n",
      "its -> its\n",
      "**************************************************\n",
      "Token: nose\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0        eyes  0.307272\n",
      "1        chin  0.239111\n",
      "2        ears  0.202388\n",
      "3         eye  0.091011\n",
      "4        nose  0.025329\n",
      "..        ...       ...\n",
      "245      band  0.000007\n",
      "246    growth  0.000007\n",
      "247    layers  0.000007\n",
      "248     light  0.000007\n",
      "249      suit  0.000007\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "4      nose  0.025329                         0.0\n",
      "nose -> nose\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           .  9.988227e-01\n",
      "1           ;  1.047786e-03\n",
      "2           !  1.175286e-04\n",
      "3           ?  6.114633e-06\n",
      "4         ...  3.800321e-06\n",
      "..        ...           ...\n",
      "245      well  3.503260e-10\n",
      "246      away  3.500355e-10\n",
      "247     stock  3.476628e-10\n",
      "248       ago  3.476243e-10\n",
      "249      2014  3.473009e-10\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "4      nose  0.025329                         0.0\n",
      ". -> .\n",
      "corrected : cats have very sweet features. it has two beautiful eye, adorably tiny pawswith sharp claws, and two very ear which are very sensitive to sounds. it has a tiny body covered with soft fur and it has a furry tail as well. cats have an adorable face with a tiny nose, a big mouth and a few whiskers under its nose.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'cats have very sweet features. it has two beautiful eye, adorably tiny pawswith sharp claws, and two very ear which are very sensitive to sounds. it has a tiny body covered with soft fur and it has a furry tail as well. cats have an adorable face with a tiny nose, a big mouth and a few whiskers under its nose.'"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EDIT_DISTANCE_TO_LEN_RATIO = 0.4\n",
    "MAX_EDIT_DISTANCE = 2\n",
    "MIN_SCORE = 0.0001\n",
    "TOP_K = 250\n",
    "VERBOSE = True\n",
    "\n",
    "if language == 'en':\n",
    "    # input_text = \"The capitan of Iran is tehran.\"\n",
    "    # input_text = \"i am speeking english very wall.\"\n",
    "    # input_text = \"He was stadying english for the finall exam.\"\n",
    "    # text = \"I'm studying [MASK] learning in my computer class.\"\n",
    "    # text = \"I'm a very [MASK] player in football.\"\n",
    "    # input_text = \"He drove a cat.\"\n",
    "    # text = \"do you want to watch tv.\"\n",
    "    # text = \"I love playing [MASK].\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The quantity thoery of money also assume that the quantity of money in an economy has a large influense on its level of economic activity. So, a change in the money supply results in either a change in the price levels or a change in the sopply of gods and services, or both. In addition, the theory assumes that changes in the money supply are the primary reason for changes in spending.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Does it privent Iran from getting nuclear weapens. Many exports say that if all parties adhered to their pledges, the deal almost certainly could have achieved that goal for longer than a dekade!\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The Federal Reserve monitor risks to the financal system and works to help ensure the system supports a haelthy economy for U.S. households, communities, and busineses.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Bitcoin is a decentrallized digital curency that can be transfered on the peer-to-peer bitcoin network. Bitcoin transactions are veryfied by network nodes throgh cryptography and recorded in a public distributed ledger called a blockchain. The criptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto. The curency began use in 2009 when its implemntation was released as open-source software.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The 2022 FILA World Cup is scheduled to be the 22nd running of the FILA World Cup competition, the quadrennial international men's football championship contested by the national teams of the member associations of FIFA. It is scheduled to take place in Qatar from 21 Novamber to 18 Decamber 2022.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        President Daneld Trump annonced on Tuesday he will withdraw the United States from the Iran nuclear deal and restore far-reaching sanktions aimed at severing Iran from the global finansial system.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Cars have very sweet features. It has two beautifull eye, adorably tiny paws, sharp claws, and two perky ear which are very sensitive to sounds. It has a tiny body covered with smoot fur and it has a furry tail as well. Cats have an adorable face with a tiny nose, a big mouth and a few whiskers under its nose.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if model_type != 'roberta':\n",
    "        input_text = input_text.lower()\n",
    "\n",
    "if language == 'fa':\n",
    "    input_text = \"امروز در استادیوم آزادی تیم ملی ایران و روسیه مسایقه می‌دهند.\"\n",
    "    input_text = \"پس از سال‌ها تلاش رازی موفق به کسف الکل شد. این دانشمند تیرانی باعث افتخار در تاریخ کور است.\"\n",
    "    input_text = \"هفته آینده احتمالا توافق بسته‌ای امضا می‌شود.\"\n",
    "    input_text = \"اهل کدام کشور هستی.\"\n",
    "    input_text = \"سن شما چقدر است.\"\n",
    "    input_text = \"وقتی قیمت گوست قرمز یا صفید در کشورهای دیگر بیشتر شده است، ممکن است در جیران هم گرا شود.\"\n",
    "    input_text = \"در هفته گذشته قیمت تلا تغییر چندانی نداشت، و در همان محدوده 1850 دلاری کار خود را به پایان رساند. \"\n",
    "    input_text = \"هدف از زندگانی چیست!\"\n",
    "    input_text = \"همه رأس ساعت 3 در جلسه حاضر باشند.\"\n",
    "\n",
    "    input_text = \"بر اساس مسوبه سران قوا، معاملات فردایی طلا همانند معاملات فردایی ارض، ممنوع و غیرقانونی شناخته شد و فعالان این بازار به جرم اخلال اقتصادی، تحت پیگرد قرار خواهند گرفت. در نتیجه تانک مرکزی در بازار فردایی مداخله نخواهد کرد\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        با نزدیک شدن قیمت دار غیر رسمی به سفف خود در روز قبل، تحلیلگران در بازار برای هفته بعد هشدار میدادند که باید احطیاط کرد و اقدامات امنیتی در بازار افزایش خواهد یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "    با تولانی شدن جنگ روسیه و اوکراین و سهم قابل توجهی که این دو کشور در تأمین کندم جهان داشتند، بازار کندم با نوسانات زیادی مواجه شد و قیمت محصولاتی که مواد اولیه‌شان کندم بود، در همه جای جهان افزایش یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        علت واقعی تعویق در مزاکرات وین چیست.\n",
    "    \"\"\"\n",
    "\n",
    "input_text = input_text.strip()\n",
    "\n",
    "spell_corrector = SpellCorrector(MAX_EDIT_DISTANCE_TO_LEN_RATIO, MAX_EDIT_DISTANCE, MIN_SCORE, VERBOSE, TOP_K)\n",
    "\n",
    "doc = nlp(input_text)\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "# displacy.render(doc, style=\"dep\")\n",
    "\n",
    "print(\"Spell Correction for text sentences:\")\n",
    "result = spell_corrector(input_text)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"severing\" == \"severing\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34daa296ffe99e8a66e159d01b1dfeb9a87967b5cca691fda43c054f03617153"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}