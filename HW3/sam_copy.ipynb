{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Required Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahur4/anaconda3/envs/data_env/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from transformers import pipeline, BertTokenizer, BertForMaskedLM, AlbertTokenizer, AlbertForMaskedLM, RobertaTokenizer, RobertaModel\n",
    "from transformers.pipelines.fill_mask import FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "from spacy.tokens.token import Token\n",
    "from spacy.tokens.doc import Doc\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cpu\n",
      "en roberta Model Loaded ...\n"
     ]
    }
   ],
   "source": [
    "# torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch_device = 'cpu'\n",
    "print(f\"Torch Device: {torch_device}\")\n",
    "\n",
    "language = 'en'\n",
    "model_type = 'roberta'\n",
    "\n",
    "# EN\n",
    "\n",
    "if model_type == 'bert':\n",
    "    model_name = \"bert-large-uncased\"  # Bert large\n",
    "    # model_name = \"bert-base-uncased\" # Bert base\n",
    "\n",
    "if model_type == 'roberta':\n",
    "    model_name = \"roberta-large\"  # Roberta\n",
    "\n",
    "# FA\n",
    "# model_name = \"HooshvareLab/albert-fa-zwnj-base-v2\" # Albert\n",
    "# model_name = \"HooshvareLab/bert-fa-base-uncased\" # BERT V2\n",
    "# model_name = \"HooshvareLab/bert-fa-zwnj-base\" # BERT V3\n",
    "\n",
    "if model_type == 'bert':\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else BertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'albert':\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "    model = AlbertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else AlbertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'roberta':\n",
    "    MASK = \"<mask>\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "    unmasker = pipeline('fill-mask', model='roberta-large')\n",
    "\n",
    "else:\n",
    "    print(f\"{model_type} not found.\")\n",
    "\n",
    "vocab: set = set(tokenizer.get_vocab().keys())\n",
    "\n",
    "if model_type == 'roberta':\n",
    "    vocab = set(map(lambda s: s[1:], vocab))\n",
    "\n",
    "print(f\"{language} {model_type} Model Loaded ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "39620"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stanza\n",
    "\n",
    "spaCy's tokenization is non-destructive, so it always represents the original input text and never adds or deletes anything. This is kind of a core principle of the Doc object: you should always be able to reconstruct and reproduce the original input text.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import spacy\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if language == 'fa':\n",
    "    stanza.install_corenlp()\n",
    "    stanza.download('fa')\n",
    "    nlp = spacy_stanza.load_pipeline(\"fa\")\n",
    "\n",
    "elif language == 'en':\n",
    "    spacy.prefer_gpu()\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"{language} not supported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "alpha = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Lexico Typo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def lexico_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index, current_token in enumerate(doc):\n",
    "            current_token: Token\n",
    "            start_char_index: int = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            if current_token.text not in vocab:\n",
    "                masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "                predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "                # Select token from predicts\n",
    "                predicts = pd.DataFrame(predicts)\n",
    "\n",
    "                predicts.loc[:, 'token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "                predicts.loc[:, 'edit_distance'] = predicts['token_str'].apply(lambda tk: editdistance.eval(current_token.text, tk))\n",
    "\n",
    "                # Filter tokens with at most 3 edit distance\n",
    "                filtered_predicts = predicts.loc[predicts['edit_distance'] <= 3, :].copy()\n",
    "\n",
    "                # Apply total score function\n",
    "                # e: edit distance + 1\n",
    "                # l: token length\n",
    "                filtered_predicts.loc[:, 'e_to_l'] = (filtered_predicts.loc[:, 'edit_distance'] + 1) / len(current_token.text)\n",
    "\n",
    "                filtered_predicts.loc[:, 'total_score'] = filtered_predicts.loc[:, 'score'] / filtered_predicts.loc[:, 'e_to_l'] * alpha\n",
    "\n",
    "                filtered_predicts = filtered_predicts.sort_values('total_score', ascending=False)\n",
    "\n",
    "                try:\n",
    "                    selected_predict_row = filtered_predicts.iloc[0, :]\n",
    "                    selected_predict = selected_predict_row['token_str']\n",
    "                except:\n",
    "                    print(f\"\\n ** filtered tokens size is 0. ** \\n\")\n",
    "\n",
    "                    from spellchecker import SpellChecker\n",
    "                    spell = SpellChecker()\n",
    "                    selected_predict = spell.correction(current_token.text)\n",
    "\n",
    "                if selected_predict != current_token.text:\n",
    "                    some_token_corrected = True\n",
    "                    result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                    text = result_text\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"*\" * 50)\n",
    "                    print(f\"Token: {current_token.text}\")\n",
    "\n",
    "                    print(\"Filtered Predicts: \\n\")\n",
    "                    print(filtered_predicts[['token_str', 'score', 'total_score']])\n",
    "\n",
    "                    print(f\"{current_token.text} -> {selected_predict} : lexical\")\n",
    "\n",
    "\n",
    "                    typo_correction_details = {\n",
    "                        \"raw\": current_token.text,\n",
    "                        \"corrected\": selected_predict,\n",
    "                        \"span\": f\"[{start_char_index}, {end_char_index}]\",\n",
    "                        \"type\": \"lexical\"\n",
    "                    }\n",
    "\n",
    "                    # print(typo_correction_details)\n",
    "\n",
    "                if some_token_corrected:\n",
    "                    break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Contextual Typo\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def contextual_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index in range(len(doc)):\n",
    "            current_token: Token = doc[index]\n",
    "\n",
    "            start_char_index = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "            predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "            try:\n",
    "                if current_token.text in string.punctuation:\n",
    "                    selected_predict = predicts['token_str'].iloc[0]\n",
    "\n",
    "                elif current_token.text.isdigit():\n",
    "                    selected_predict = current_token.text\n",
    "\n",
    "                else:\n",
    "                    ### Select Token From Predicts\n",
    "                    predicts = pd.DataFrame(predicts)\n",
    "\n",
    "                    predicts.loc[:, 'token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "                    predicts.loc[:, 'edit_distance'] = predicts['token_str'].apply(lambda tk: editdistance.eval(current_token.text, tk))\n",
    "\n",
    "                    # Filter tokens with at most 3 edit distance\n",
    "                    filtered_predicts = predicts.loc[predicts['edit_distance'] <= 3, :].copy()\n",
    "\n",
    "                    # Apply total score function\n",
    "                    # e: edit distance + 1\n",
    "                    # l: token length\n",
    "                    filtered_predicts.loc[:, 'e_to_l'] = (filtered_predicts.loc[:, 'edit_distance'] + 1) / len(current_token.text)\n",
    "\n",
    "                    filtered_predicts.loc[:, 'total_score'] = filtered_predicts.loc[:, 'score'] / filtered_predicts.loc[:, 'e_to_l'] * alpha\n",
    "\n",
    "                    filtered_predicts = filtered_predicts.sort_values('total_score', ascending=False)\n",
    "                    selected_predict_row = filtered_predicts.iloc[0, :]\n",
    "\n",
    "                    selected_predict = selected_predict_row['token_str']\n",
    "\n",
    "                    current_token_text_tot_score = filtered_predicts.loc[filtered_predicts['token_str'] == current_token.text, 'total_score']\n",
    "                    selected_token_text_tot_score = selected_predict['total_score']\n",
    "\n",
    "                    print(f\"current_token_text_total_score: {current_token_text_tot_score}, selected_token_total_score: {selected_token_text_tot_score}\")\n",
    "\n",
    "            except:\n",
    "                selected_predict = current_token.text\n",
    "\n",
    "            if selected_predict != current_token.text:\n",
    "                some_token_corrected = True\n",
    "                result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                text = result_text\n",
    "\n",
    "            if verbose:\n",
    "                print(\"*\" * 50)\n",
    "                print(f\"Token: {current_token.text}\")\n",
    "\n",
    "                print(\"Filtered Predicts: \\n\")\n",
    "                print(filtered_predicts[['token_str', 'score', 'total_score']])\n",
    "\n",
    "                print(f\"{current_token.text} -> {selected_predict} : contextual\")\n",
    "\n",
    "                if current_token.text != selected_predict:\n",
    "                    typo_correction_details = {\n",
    "                        \"raw\": current_token.text,\n",
    "                        \"corrected\": selected_predict,\n",
    "                        \"span\": f\"[{start_char_index}, {end_char_index}]\",\n",
    "                        \"type\": \"contextual\"\n",
    "                    }\n",
    "\n",
    "                    # print(typo_correction_details)\n",
    "\n",
    "            if some_token_corrected:\n",
    "                break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correction Pipeline Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class SpellCorrector:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_edit_distance_to_length_ratio=0.45,\n",
    "            max_edit_distance=2,\n",
    "            min_score=1e-7,\n",
    "            verbose=False,\n",
    "            top_k=50\n",
    "    ):\n",
    "        self.max_edit_distance_to_length_ratio = max_edit_distance_to_length_ratio\n",
    "        self.max_edit_distance = max_edit_distance\n",
    "        self.min_score = min_score\n",
    "        self.verbose = verbose\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def _lexico_typo_correction(self, text):\n",
    "        return lexico_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                      self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def _contextual_typo_correction(self, text):\n",
    "        return contextual_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                          self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def correction_pipeline(self, text):\n",
    "        print(f\"raw       : {text}\")\n",
    "        # print(\"Lexico Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._lexico_typo_correction(text)\n",
    "\n",
    "        # print(\"Contextual Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._contextual_typo_correction(corrected_text)\n",
    "\n",
    "        print(f\"corrected : {corrected_text}\")\n",
    "        return corrected_text\n",
    "\n",
    "    def __call__(self, text, *args, **kwargs):\n",
    "        return self.correction_pipeline(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test On Sample Texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell Correction for text sentences:\n",
      "raw       : I am going to stadiom.\n",
      "\n",
      " ** filtered tokens size is 0. ** \n",
      "\n",
      "**************************************************\n",
      "Token: stadiom\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, total_score]\n",
      "Index: []\n",
      "stadiom -> stadium : lexical\n",
      "**************************************************\n",
      "Token: I\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  total_score\n",
      "0           I  0.990719     9.907195\n",
      "1           i  0.000929     0.004646\n",
      "4           I  0.000367     0.003665\n",
      "2          He  0.000475     0.001584\n",
      "3         You  0.000432     0.001081\n",
      "..        ...       ...          ...\n",
      "220       Mom  0.000004     0.000011\n",
      "226       Two  0.000004     0.000011\n",
      "231       Ash  0.000004     0.000010\n",
      "242       now  0.000004     0.000010\n",
      "249       Max  0.000004     0.000010\n",
      "\n",
      "[120 rows x 3 columns]\n",
      "I -> I : contextual\n",
      "**************************************************\n",
      "Token: am\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  total_score\n",
      "1          am  0.295750     5.915001\n",
      "0          'm  0.538394     5.383937\n",
      "2         was  0.103079     0.687190\n",
      "8          is  0.002038     0.013588\n",
      "6        hate  0.002684     0.013420\n",
      "..        ...       ...          ...\n",
      "229       the  0.000019     0.000096\n",
      "235       don  0.000019     0.000093\n",
      "239       you  0.000018     0.000089\n",
      "244      aven  0.000017     0.000086\n",
      "248      make  0.000017     0.000085\n",
      "\n",
      "[84 rows x 3 columns]\n",
      "am -> am : contextual\n",
      "**************************************************\n",
      "Token: going\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  total_score\n",
      "0       going  0.426484    21.324202\n",
      "6      coming  0.028801     0.480025\n",
      "9      moving  0.017117     0.285279\n",
      "17     flying  0.005205     0.065065\n",
      "21    getting  0.004831     0.060385\n",
      "30    looking  0.002759     0.034491\n",
      "33     trying  0.002484     0.031049\n",
      "44         on  0.001685     0.021056\n",
      "46         in  0.001443     0.018032\n",
      "48       down  0.001353     0.016910\n",
      "69       gone  0.000855     0.014250\n",
      "61     racing  0.000962     0.012029\n",
      "84     losing  0.000629     0.010490\n",
      "75       born  0.000763     0.009537\n",
      "78     taking  0.000740     0.009249\n",
      "92      using  0.000554     0.009227\n",
      "100     dying  0.000473     0.007889\n",
      "86       good  0.000616     0.007699\n",
      "87      bound  0.000597     0.007462\n",
      "152     Going  0.000293     0.007316\n",
      "103    riding  0.000456     0.005696\n",
      "121      soon  0.000399     0.004988\n",
      "140    biking  0.000337     0.004217\n",
      "176    hoping  0.000231     0.003851\n",
      "161        go  0.000258     0.003226\n",
      "172       one  0.000239     0.002987\n",
      "193    waving  0.000201     0.002517\n",
      "201    saying  0.000192     0.002402\n",
      "202    adding  0.000191     0.002389\n",
      "211    having  0.000182     0.002269\n",
      "238    living  0.000157     0.001967\n",
      "going -> going : contextual\n",
      "**************************************************\n",
      "Token: to\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  total_score\n",
      "0          to  0.632180    12.643608\n",
      "1         the  0.127892     0.852610\n",
      "2        into  0.051653     0.344353\n",
      "3           a  0.009259     0.061725\n",
      "5         for  0.005157     0.034378\n",
      "..        ...       ...          ...\n",
      "220       mad  0.000089     0.000443\n",
      "221      post  0.000089     0.000443\n",
      "226       NBA  0.000086     0.000429\n",
      "227       ...  0.000086     0.000429\n",
      "229       UFC  0.000085     0.000427\n",
      "\n",
      "[77 rows x 3 columns]\n",
      "to -> to : contextual\n",
      "**************************************************\n",
      "Token: stadium\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, total_score]\n",
      "Index: []\n",
      "stadium -> stadium : contextual\n",
      "**************************************************\n",
      "Token: .\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, total_score]\n",
      "Index: []\n",
      ". -> . : contextual\n",
      "corrected : I am going to stadium.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'I am going to stadium.'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EDIT_DISTANCE_TO_LEN_RATIO = 0.4\n",
    "MAX_EDIT_DISTANCE = 3\n",
    "MIN_SCORE = 0.0\n",
    "TOP_K = 250\n",
    "VERBOSE = True\n",
    "\n",
    "if language == 'en':\n",
    "    # input_text = \"The capitan of Iran is tehran.\"\n",
    "    # input_text = \"i am speeking english very wall.\"\n",
    "    # input_text = \"He was stadying english for the finall exam.\"\n",
    "    # text = \"I'm studying [MASK] learning in my computer class.\"\n",
    "    # text = \"I'm a very [MASK] player in football.\"\n",
    "    # input_text = \"He drove a cat.\"\n",
    "    # text = \"do you want to watch tv.\"\n",
    "    # text = \"I love playing [MASK].\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The quantity thoery of money also assume that the quantity of money in an economy has a large influense on its level of economic activity. So, a change in the money supply results in either a change in the price levels or a change in the sopply of gods and services, or both. In addition, the theory assumes that changes in the money supply are the primary reason for changes in spending.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Does it privent Iran from getting nuclear weapens. Many exports say that if all parties adhered to their pledges, the deal almost certainly could have achieved that goal for longer than a dekade!\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The Federal Reserve monitor risks to the financal system and works to help ensure the system supports a haelthy economy for U.S. households, communities, and busineses.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Bitcoin is a decentrallized digital curency that can be transfered on the peer-to-peer bitcoin network. Bitcoin transactions are veryfied by network nodes throgh cryptography and recorded in a public distributed ledger called a blockchain. The criptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto. The curency began use in 2009 when its implemntation was released as open-source software.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The 2022 FILA World Cup is scheduled to be the 22nd running of the FILA World Cup competition, the quadrennial international men's football championship contested by the national teams of the member associations of FIFA. It is scheduled to take place in Qatar from 21 Novamber to 18 Decamber 2022.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        President Daneld Trump annonced on Tuesday he will withdraw the United States from the Iran nuclear deal and restore far-reaching sanktions aimed at withdrawal Iran from the global finansial system.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Cars have very sweet features. It has two beautifull eye, adorable tiny paws, sharp claws, and two perky ear which are very sensitive to sounds. It has a tiny body covered with smoot fur and it has a furry tail as well. Cats have an adorable face with a tiny nose, a big mouth and a few whiskers under its nose.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        I am going to stadiom.\n",
    "    \"\"\"\n",
    "\n",
    "    if model_type != 'roberta':\n",
    "        input_text = input_text.lower()\n",
    "\n",
    "if language == 'fa':\n",
    "    input_text = \"امروز در استادیوم آزادی تیم ملی ایران و روسیه مسایقه می‌دهند.\"\n",
    "    input_text = \"پس از سال‌ها تلاش رازی موفق به کسف الکل شد. این دانشمند تیرانی باعث افتخار در تاریخ کور است.\"\n",
    "    input_text = \"هفته آینده احتمالا توافق بسته‌ای امضا می‌شود.\"\n",
    "    input_text = \"اهل کدام کشور هستی.\"\n",
    "    input_text = \"سن شما چقدر است.\"\n",
    "    input_text = \"وقتی قیمت گوست قرمز یا صفید در کشورهای دیگر بیشتر شده است، ممکن است در جیران هم گرا شود.\"\n",
    "    input_text = \"در هفته گذشته قیمت تلا تغییر چندانی نداشت، و در همان محدوده 1850 دلاری کار خود را به پایان رساند. \"\n",
    "    input_text = \"هدف از زندگانی چیست!\"\n",
    "    input_text = \"همه رأس ساعت 3 در جلسه حاضر باشند.\"\n",
    "\n",
    "    input_text = \"بر اساس مسوبه سران قوا، معاملات فردایی طلا همانند معاملات فردایی ارض، ممنوع و غیرقانونی شناخته شد و فعالان این بازار به جرم اخلال اقتصادی، تحت پیگرد قرار خواهند گرفت. در نتیجه تانک مرکزی در بازار فردایی مداخله نخواهد کرد\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        با نزدیک شدن قیمت دار غیر رسمی به سفف خود در روز قبل، تحلیلگران در بازار برای هفته بعد هشدار میدادند که باید احطیاط کرد و اقدامات امنیتی در بازار افزایش خواهد یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "    با تولانی شدن جنگ روسیه و اوکراین و سهم قابل توجهی که این دو کشور در تأمین کندم جهان داشتند، بازار کندم با نوسانات زیادی مواجه شد و قیمت محصولاتی که مواد اولیه‌شان کندم بود، در همه جای جهان افزایش یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        علت واقعی تعویق در مزاکرات وین چیست.\n",
    "    \"\"\"\n",
    "\n",
    "input_text = input_text.strip()\n",
    "\n",
    "spell_corrector = SpellCorrector(MAX_EDIT_DISTANCE_TO_LEN_RATIO, MAX_EDIT_DISTANCE, MIN_SCORE, VERBOSE, TOP_K)\n",
    "from spacy import displacy\n",
    "# displacy.render(doc, style=\"dep\")\n",
    "\n",
    "print(\"Spell Correction for text sentences:\")\n",
    "result = spell_corrector(input_text)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"stadium\" in vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34daa296ffe99e8a66e159d01b1dfeb9a87967b5cca691fda43c054f03617153"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}