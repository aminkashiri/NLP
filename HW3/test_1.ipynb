{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertForMaskedLM\n",
    "import torch \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "text = \"The capital of Iran is [MASK].\"\n",
    "text = \"Yesterday, I played [MASK] in the stadium\"\n",
    "text = \"Yesterday, I played [MASK] in the [MASK].\"\n",
    "text = \"I'm studying [MASK] learning in my computer class.\"\n",
    "text = \"I'm a very [MASK] player in football.\"\n",
    "text = \"He drived a [MASK].\"\n",
    "text = \"I love playing [MASK].\"\n",
    "text = \"I am [MASK] english.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "print(tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  True, False, False, False]])\n",
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# retrieve index of [MASK]\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "print(inputs.input_ids == tokenizer.mask_token_id)\n",
    "print(mask_token_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_id</th>\n",
       "      <th>scores</th>\n",
       "      <th>word</th>\n",
       "      <th>edit_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>11.230057</td>\n",
       "      <td>not</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4092</td>\n",
       "      <td>11.103004</td>\n",
       "      <td>speaking</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1999</td>\n",
       "      <td>10.102517</td>\n",
       "      <td>in</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4083</td>\n",
       "      <td>7.643354</td>\n",
       "      <td>learning</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2053</td>\n",
       "      <td>7.444749</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>7.016780</td>\n",
       "      <td>an</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19376</td>\n",
       "      <td>6.977960</td>\n",
       "      <td>fluent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2200</td>\n",
       "      <td>6.632783</td>\n",
       "      <td>very</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4252</td>\n",
       "      <td>6.566546</td>\n",
       "      <td>teaching</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2069</td>\n",
       "      <td>6.517703</td>\n",
       "      <td>only</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4036</td>\n",
       "      <td>6.285468</td>\n",
       "      <td>taught</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>6.195779</td>\n",
       "      <td>from</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3713</td>\n",
       "      <td>6.168704</td>\n",
       "      <td>speak</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5702</td>\n",
       "      <td>6.135529</td>\n",
       "      <td>studying</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6669</td>\n",
       "      <td>5.953689</td>\n",
       "      <td>perfectly</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5760</td>\n",
       "      <td>5.824117</td>\n",
       "      <td>pure</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037</td>\n",
       "      <td>5.771194</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2074</td>\n",
       "      <td>5.769257</td>\n",
       "      <td>just</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>5.727654</td>\n",
       "      <td>of</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026</td>\n",
       "      <td>5.641541</td>\n",
       "      <td>my</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    token_id     scores       word  edit_distance\n",
       "5       2025  11.230057        not              4\n",
       "13      4092  11.103004   speaking              6\n",
       "14      1999  10.102517         in              3\n",
       "11      4083   7.643354   learning              6\n",
       "17      2053   7.444749         no              3\n",
       "6       2019   7.016780         an              3\n",
       "9      19376   6.977960     fluent              5\n",
       "15      2200   6.632783       very              5\n",
       "12      4252   6.566546   teaching              6\n",
       "8       2069   6.517703       only              5\n",
       "19      4036   6.285468     taught              6\n",
       "10      2013   6.195779       from              5\n",
       "7       3713   6.168704      speak              5\n",
       "18      5702   6.135529   studying              6\n",
       "16      6669   5.953689  perfectly              9\n",
       "4       5760   5.824117       pure              5\n",
       "1       1037   5.771194          a              4\n",
       "2       2074   5.769257       just              5\n",
       "3       1997   5.727654         of              5\n",
       "0       2026   5.641541         my              5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "\n",
    "N = 20\n",
    "word = 'diano'\n",
    "token_ids = np.argpartition(logits[0, mask_token_index], -N, axis=-1)[0,-N:]\n",
    "scores = logits[0, mask_token_index][0, token_ids]\n",
    "df = pd.DataFrame({'token_id':token_ids, 'scores':scores})\n",
    "df['word'] = df['token_id'].apply(lambda row: tokenizer.decode([row]))\n",
    "df['edit_distance'] = df['word'].apply(lambda row: editdistance.eval(word,row))\n",
    "df.sort_values(by = 'scores', ascending=False)\n",
    "# display(df)\n",
    "# print(df['edit_distance'].idxmin())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd029c74b3931211e259a6407e9cb636f4133dd1d46c169023899434202d8e33"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('nlp_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}