{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFbu_4MbSbuR",
        "outputId": "9cec8048-43d6-496e-9366-cf1b1d907a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tG7J5v1Qud6",
        "outputId": "a94cdcde-1870-4dd8-df99-3aabf327367c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfI3HXXGRvap",
        "outputId": "a2e31401-2943-41d2-c3d6-0b212f31c1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  models_4.pickle\tsample_data  test.txt  tokens_4.pickle\tvocab_4.pickle\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/Colab\\ Notebooks/NLP/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn9hxaEqSGQ8",
        "outputId": "38e37ef9-2f58-4e56-f90f-4306aa5587ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open sports.zip, sports.zip.zip or sports.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip sports.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pbar(x):\n",
        "  return tqdm(x, position=0, leave=True)"
      ],
      "metadata": {
        "id": "qg0WT5B63Iie"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "from tqdm import tqdm\n",
        "# lines = [x for x in tqdm(codecs.open('./test.txt','rU','utf-8').readlines())]\n",
        "# lines = [x for x in pbar(codecs.open('/content/drive/MyDrive/Colab Notebooks/NLP/sports.txt','rU','utf-8').readlines())]\n",
        "lines = [x for i, x in pbar(enumerate(codecs.open('/content/drive/MyDrive/Colab Notebooks/NLP/sports.txt','rU','utf-8').readlines())) if i<200000]\n",
        "paragraphs = []\n",
        "paragraph = ''\n",
        "for line in pbar(lines):\n",
        "    if line == '\\n':\n",
        "        paragraphs.append(paragraph)\n",
        "        paragraph = ''\n",
        "    else:\n",
        "        paragraph += line\n",
        "else:\n",
        "    paragraphs.append(paragraph)\n",
        "\n",
        "\n",
        "# print(paragraphs[0])\n",
        "# print(paragraphs[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOl78t9mwfEw",
        "outputId": "67d1bdba-4629-4d02-eb36-8c177f048d56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1833371it [00:01, 1302153.97it/s]\n",
            "100%|██████████| 200000/200000 [00:00<00:00, 1053187.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5OfD9CegjMJ",
        "outputId": "e408c5aa-b17e-4a68-fc69-7902579cdbfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24307"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "xnrWRVu1hBru",
        "outputId": "0853ff85-848e-4125-ed60-8f4a9ace1edc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'شاید کمتر\\u200cکسی تصور می\\u200cکرد روزی رابطه ایران با جمهوری آذربایجان از لحاظ دیپلماتیک شکرآب شود؛ اگرچه هنوز چنین موضوعی به\\u200cصورت قطعی رخ نداده ولی نشانه\\u200cهایی در میان است که به نظر می\\u200cرسد رفته\\u200cرفته چنین شود. شروعش فعلا از سوی رئیس\\u200cجمهور آذربایجان بوده است؛ الهام علی\\u200cاف، اخیرا در گفت\\u200cوگو با یک رسانه ترکیه\\u200cای درباره ادعای ورود ۶۰ کامیون ایرانی به منطقه قره\\u200cباغ در تابستان امسال گفته است که «این اولین باری نیست که کامیون\\u200cهای ایرانی به\\u200cصورت غیرقانونی به منطقه قره\\u200cباغ سفر می\\u200cکنند. این چیزی است که به\\u200cطور مداوم در جریان دوران اشغال [قره\\u200cباغ توسط ارمنستان] رخ می\\u200cداده است». او گفته است: «ما اطلاعاتی داشتیم اما قطعا مثل زمان حال، اطلاعاتمان واضح نبود. با توجه به این موضوع، ما از کانال\\u200cهای مختلف نارضایتی خود را از عبور غیرقانونی ابراز داشتیم اما این رویه ادامه داشت». علی\\u200cاف همچنین گفت در\\u200cصورتی\\u200cکه ورود کامیون\\u200cهای ایران به قره\\u200cباغ ادامه پیدا کند، باید مالیات پرداخت کنند. علی\\u200cاف همچنین درباره رزمایش\\u200c نظامی ایران در مرز جمهوری آذربایجان اظهارنظر کرد و گفت: «این یک رویداد بسیار تعجب\\u200cآور است. هر کشوری می\\u200cتواند هرگونه رزمایش نظامی را در قلمرو خود انجام دهد. این حق حاکمیتی آنها\\u200cست اما چرا حالا و چرا در مرز ما؟ چرا زمانی که ارامنه در جبرائیل، فضولی و زنگلان بودند، چنین رزمایش\\u200cهایی در کار نبود؟ چرا پس از آزادسازی این زمین\\u200cها پس از 30 سال اشغال برگزار می\\u200cشود؟». این اظهارات با واکنش مقام\\u200cهای ایرانی روبه\\u200cرو شده است. سعید خطیب\\u200cزاده، سخنگوی وزارت امور خارجه در واکنش به اظهارات الهام علی\\u200cاف\\u200c گفته است:در\\u200cحالی\\u200cکه روابط خوب و محترمانه\\u200c\\u200cای میان دو کشور وجود دارد و مسیرهای معمول ارتباطات میان دو طرف در بالاترین سطح وجود دارد، بیان آن به این شیوه مایه تعجب است. او افزوده است: در این زمینه و موضوعات دیگر مرتبط با آن، در دیدار دو وزیر امور خارجه در حاشیه نشست اخیر مجمع عمومی سازمان ملل متحد در نیویورک، رایزنی\\u200cهای جدی و دقیقی صورت گرفت و توافق شد در یک بستر مناسب این گفت\\u200cوگو\\u200cها ادامه پیدا کند. او گفت: جمهوری اسلامی ایران همواره مخالفت خود را با هرگونه اشغال سرزمینی اعلام داشته و بر لزوم احترام به تمامیت ارضی کشورها و مرزهای شناخته\\u200cشده بین\\u200cالمللی تأکید کرده است. ضمن آنکه رعایت حسن همسایگی و همجواری از مهم\\u200cترین موضوعاتی است که انتظار می\\u200cرود از سوی همه همسایگان مورد توجه قرار گیرد. خطیب\\u200cزاده افزود: مانور انجام\\u200cشده از سوی کشورمان در مناطق مرزی شمال\\u200c غرب یک موضوع حاکمیتی است و برای آرامش و ثبات کل منطقه انجام می\\u200cشود. البته روشن است که جمهوری اسلامی ایران، حضور هرچند نمایشی رژیم صهیونیستی در نزدیکی مرزهای خود را تحمل نخواهد کرد و در این رابطه هر اقدامی را که برای امنیت ملی خود لازم بداند، انجام خواهد داد.\\nاگرچه ایران به اتهامات علی\\u200cاف پاسخ داده و اظهارات رئیس\\u200cجمهور آذربایجان را بی\\u200cاساس توصیف کرده ولی با فرمانی که الهام در پیش گرفته، ممکن است شرایط از وضع موجود کمی حادتر هم بشود. اگر چنین شود، آن\\u200cوقت روابط دو کشور در تمامی حوزه\\u200cها تحت تأثیر قرار می\\u200cگیرد و اینجاست که پای ورزشکاران بی\\u200cشماری که از ایران راهی جمهوری آذربایجان شده\\u200cاند هم به میان می\\u200cآید. قبل از وارد\\u200cشدن به جزئیات و اسامی این ورزشکاران، باید گفت \\u200cجمهوری آذربایجان در یک دهه گذشته مقصد بسیاری از ورزشکاران ایرانی بوده که عمدتا هم تابعیت این کشور را به دست آورده و زیر پرچم جمهوری آذربایجان مبارزه و مسابقه داده\\u200cاند. با\\u200cاین\\u200cحال، آنها تا\\u200cبه\\u200cحال منعی برای تردد بین دو کشور نداشته\\u200cاند. این موضوع در حالی است که عده\\u200cای دیگر از ورزشکاران ایرانی هم بدون اینکه تبعیت آذربایجان را بپذیرند، به لیگ\\u200cهای این کشور رفته\\u200cاند. پس، سؤال اصلی اینجاست که تکلیف این ورزشکاران چه می\\u200cشود و الهام علی\\u200cاف با ورزشکاران بی\\u200cشمار ایرانی در آذربایجان چه می\\u200cکند؟ آیا از این به بعد ورود و خروج ورزشکاران دو کشور محدود می\\u200cشود؟ یا شاید شبیه به اتفاقی که سال\\u200cها در امارات رخ داد، آیا حضور در لیگ\\u200cهای آذربایجان هم قرار است دستخوش تغییر و تحول قرار بگیرد؟ اینها مواردی است که ورزشکاران را نگران می\\u200cکند و هیچ\\u200cکدام علاقه\\u200cای به تیره\\u200cشدن روابط دیپلماتیک دو کشور ندارند.\\nفهرست ورزشکاران ایرانی که زیر پرچم جمهوری آذربایجان مسابقه می\\u200cدهند هم چندان کم نیست؛ علی قربانی و حجت حق\\u200cوردی دو فوتبالیست مشهور ایرانی هستند که برای تیم ملی فوتبال جمهوری آذربایجان مسابقه می\\u200cدهند. چهار فوتسالیست ایرانی هم پیش\\u200cتر در ترکیب تیم ملی فوتسال جمهوری آذربایجان دیده شده\\u200cاند: وحید شفیعی، بازیکن سابق تیم ملی ایران و تیم\\u200cهای دبیری تبریز و سن\\u200cایچ ساوه، امیر شجاعی بازیکن تیم اهورای بهبهان، اسحاق سورغالی بازیکن تیم ارژن شیراز و هادی احمدی، بازیکن تیم فرش\\u200cآرا چهار بازیکنی هستند که در ترکیب تیم ملی آذربایجان در رشته فوتسال به میدان رفته\\u200cاند. گل سرسبد ایرانی\\u200cهایی که برای جمهوری آذربایجان مسابقه می\\u200cدهند هم حامد حیدری است که همین یکی، دو ماه گذشته مدال طلای پارالمپیک در رشته پرتاب نیزه را از چنگ ورزشکار ایرانی درآورد و به حساب جمهوری آذربایجان لحاظ کرد. البته که به غیر از اینها ورزشکاران دیگری هم بوده و هستند که یا برای این کشور به میدان رفته یا این\\u200cروزها در آستانه بازی\\u200cکردن برای تیم\\u200cهای ملی جمهوری آذربایجان یا لیگ\\u200cهای مربوطه در این کشور هستند.\\nسامان طهماسبی، مسعود هاشم\\u200cزاده و صباح شریعتی، فرنگی\\u200cکاران ایرانی بوده\\u200cاند که با تغییر تابعیت پذیرفتند برای تیم ملی جمهوری آذربایجان مبارزه کنند. سینا بهرامی در تکواندو پایه\\u200cگذار سفر به جمهوری آذربایجان و مسابقه\\u200cدادن با پرچم این کشور در تکواندو بود ولی میلاد بیگی را شاید بتوان مهم\\u200cترین شکار جمهوری آذربایجان در بین ورزشکاران ایرانی دانست. او با پرچم جمهوری آذربایجان دو مدال نقره جهانی به دست آورد و سپس در افتخاری فراموش\\u200cنشدنی موفق شد آذربایجان را صاحب مدال برنز المپیک در سال ۲۰۱۶ کند. سهیلا سیاحی هم دیگر تکواندوکار ایرانی بود که سر از تیم ملی جمهوری آذربایجان درآورد؛ هرچند توفیقی مثل بقیه در این زمینه به دست نیاورد.\\nحالا با مرور همین فهرست کوتاه و انتقالاتی که در سال\\u200cهای اخیر رخ داده، مشخص است اگر قرار باشد الهام علی\\u200cاف همچنان به صحبت\\u200cهای بحث\\u200cبرانگیزش علیه ایران ادامه دهد، حال\\u200cو\\u200cروز این ورزشکاران ایرانی که در\\u200cحال\\u200cحاضر عضوی از تیم ملی جمهوری آذربایجان هستند یا در لیگ\\u200cهای این کشور بازی می\\u200cکنند، مبهم می\\u200cشود.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "paragraphs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnlJ9KWRTuaD",
        "outputId": "bb382369-5f09-4327-e92c-90534af5fbbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24307/24307 [00:29<00:00, 819.55it/s] \n"
          ]
        }
      ],
      "source": [
        "from hazm import Normalizer\n",
        "\n",
        "normalizer = Normalizer()\n",
        "# words_normalized = [[normalizer.normalize(word) for word in words] for paragraph in pbar(paragraphs)]\n",
        "paragraphs_normalized = [normalizer.normalize(paragraph) for paragraph in pbar(paragraphs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "2pIWkHIgSPvl",
        "outputId": "0668e429-006d-4923-a6d1-01dce5409713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'شاید کمتر\\u200cکسی تصور می\\u200cکرد روزی رابطه ایران با جمهوری آذربایجان از لحاظ دیپلماتیک شکرآب شود؛ اگرچه هنوز چنین موضوعی به\\u200cصورت قطعی رخ نداده ولی نشانه\\u200cهایی در میان است که به نظر می\\u200cرسد رفته\\u200cرفته چنین شود. شروعش فعلا از سوی رئیس\\u200cجمهور آذربایجان بوده است؛ الهام علی\\u200cاف، اخیرا در گفت\\u200cوگو با یک رسانه ترکیه\\u200cای درباره ادعای ورود ۶۰ کامیون ایرانی به منطقه قره\\u200cباغ در تابستان امسال گفته است که «این اولین باری نیست که کامیون\\u200cهای ایرانی به\\u200cصورت غیرقانونی به منطقه قره\\u200cباغ سفر می\\u200cکنند. این چیزی است که به\\u200cطور مداوم در جریان دوران اشغال [قره\\u200cباغ توسط ارمنستان] رخ می\\u200cداده است». او گفته است: «ما اطلاعاتی داشتیم اما قطعا مثل زمان حال، اطلاعاتمان واضح نبود. با توجه به این موضوع، ما از کانال\\u200cهای مختلف نارضایتی خود را از عبور غیرقانونی ابراز داشتیم اما این رویه ادامه داشت». علی\\u200cاف همچنین گفت در\\u200cصورتی\\u200cکه ورود کامیون\\u200cهای ایران به قره\\u200cباغ ادامه پیدا کند، باید مالیات پرداخت کنند. علی\\u200cاف همچنین درباره رزمایش\\u200c نظامی ایران در مرز جمهوری آذربایجان اظهارنظر کرد و گفت: «این یک رویداد بسیار تعجب\\u200cآور است. هر کشوری می\\u200cتواند هرگونه رزمایش نظامی را در قلمرو خود انجام دهد. این حق حاکمیتی آنها\\u200cست اما چرا حالا و چرا در مرز ما؟ چرا زمانی که ارامنه در جبرائیل، فضولی و زنگلان بودند، چنین رزمایش\\u200cهایی در کار نبود؟ چرا پس از آزادسازی این زمین\\u200cها پس از ۳۰ سال اشغال برگزار می\\u200cشود؟». این اظهارات با واکنش مقام\\u200cهای ایرانی روبه\\u200cرو شده است. سعید خطیب\\u200cزاده، سخنگوی وزارت امور خارجه در واکنش به اظهارات الهام علی\\u200cاف\\u200c گفته است: در\\u200cحالی\\u200cکه روابط خوب و محترمانه\\u200c\\u200cای میان دو کشور وجود دارد و مسیرهای معمول ارتباطات میان دو طرف در بالاترین سطح وجود دارد، بیان آن به این شیوه مایه تعجب است. او افزوده است: در این زمینه و موضوعات دیگر مرتبط با آن، در دیدار دو وزیر امور خارجه در حاشیه نشست اخیر مجمع عمومی سازمان ملل متحد در نیویورک، رایزنی\\u200cهای جدی و دقیقی صورت گرفت و توافق شد در یک بستر مناسب این گفت\\u200cوگو\\u200cها ادامه پیدا کند. او گفت: جمهوری اسلامی ایران همواره مخالفت خود را با هرگونه اشغال سرزمینی اعلام داشته و بر لزوم احترام به تمامیت ارضی کشورها و مرزهای شناخته\\u200cشده بین\\u200cالمللی تأکید کرده است. ضمن آنکه رعایت حسن همسایگی و همجواری از مهم\\u200cترین موضوعاتی است که انتظار می\\u200cرود از سوی همه همسایگان مورد توجه قرار گیرد. خطیب\\u200cزاده افزود: مانور انجام\\u200cشده از سوی کشورمان در مناطق مرزی شمال\\u200c غرب یک موضوع حاکمیتی است و برای آرامش و ثبات کل منطقه انجام می\\u200cشود. البته روشن است که جمهوری اسلامی ایران، حضور هرچند نمایشی رژیم صهیونیستی در نزدیکی مرزهای خود را تحمل نخواهد کرد و در این رابطه هر اقدامی را که برای امنیت ملی خود لازم بداند، انجام خواهد داد. \\nاگرچه ایران به اتهامات علی\\u200cاف پاسخ داده و اظهارات رئیس\\u200cجمهور آذربایجان را بی\\u200cاساس توصیف کرده ولی با فرمانی که الهام در پیش گرفته، ممکن است شرایط از وضع موجود کمی حادتر هم بشود. اگر چنین شود، آن\\u200cوقت روابط دو کشور در تمامی حوزه\\u200cها تحت تأثیر قرار می\\u200cگیرد و اینجاست که پای ورزشکاران بی\\u200cشماری که از ایران راهی جمهوری آذربایجان شده\\u200cاند هم به میان می\\u200cآید. قبل از وارد\\u200cشدن به جزئیات و اسامی این ورزشکاران، باید گفت \\u200cجمهوری آذربایجان در یک دهه گذشته مقصد بسیاری از ورزشکاران ایرانی بوده که عمدتا هم تابعیت این کشور را به دست آورده و زیر پرچم جمهوری آذربایجان مبارزه و مسابقه داده\\u200cاند. با\\u200cاین\\u200cحال، آنها تا\\u200cبه\\u200cحال منعی برای تردد بین دو کشور نداشته\\u200cاند. این موضوع در حالی است که عده\\u200cای دیگر از ورزشکاران ایرانی هم بدون اینکه تبعیت آذربایجان را بپذیرند، به لیگ\\u200cهای این کشور رفته\\u200cاند. پس، سؤال اصلی اینجاست که تکلیف این ورزشکاران چه می\\u200cشود و الهام علی\\u200cاف با ورزشکاران بی\\u200cشمار ایرانی در آذربایجان چه می\\u200cکند؟ آیا از این به بعد ورود و خروج ورزشکاران دو کشور محدود می\\u200cشود؟ یا شاید شبیه به اتفاقی که سال\\u200cها در امارات رخ داد، آیا حضور در لیگ\\u200cهای آذربایجان هم قرار است دستخوش تغییر و تحول قرار بگیرد؟ اینها مواردی است که ورزشکاران را نگران می\\u200cکند و هیچ\\u200cکدام علاقه\\u200cای به تیره\\u200cشدن روابط دیپلماتیک دو کشور ندارند. \\nفهرست ورزشکاران ایرانی که زیر پرچم جمهوری آذربایجان مسابقه می\\u200cدهند هم چندان کم نیست؛ علی قربانی و حجت حق\\u200cوردی دو فوتبالیست مشهور ایرانی هستند که برای تیم ملی فوتبال جمهوری آذربایجان مسابقه می\\u200cدهند. چهار فوتسالیست ایرانی هم پیش\\u200cتر در ترکیب تیم ملی فوتسال جمهوری آذربایجان دیده شده\\u200cاند: وحید شفیعی، بازیکن سابق تیم ملی ایران و تیم\\u200cهای دبیری تبریز و سن\\u200cایچ ساوه، امیر شجاعی بازیکن تیم اهورای بهبهان، اسحاق سورغالی بازیکن تیم ارژن شیراز و هادی احمدی، بازیکن تیم فرش\\u200cآرا چهار بازیکنی هستند که در ترکیب تیم ملی آذربایجان در رشته فوتسال به میدان رفته\\u200cاند. گل سرسبد ایرانی\\u200cهایی که برای جمهوری آذربایجان مسابقه می\\u200cدهند هم حامد حیدری است که همین یکی، دو ماه گذشته مدال طلای پارالمپیک در رشته پرتاب نیزه را از چنگ ورزشکار ایرانی درآورد و به حساب جمهوری آذربایجان لحاظ کرد. البته که به غیر از اینها ورزشکاران دیگری هم بوده و هستند که یا برای این کشور به میدان رفته یا این\\u200cروزها در آستانه بازی\\u200cکردن برای تیم\\u200cهای ملی جمهوری آذربایجان یا لیگ\\u200cهای مربوطه در این کشور هستند. \\nسامان طهماسبی، مسعود هاشم\\u200cزاده و صباح شریعتی، فرنگی\\u200cکاران ایرانی بوده\\u200cاند که با تغییر تابعیت پذیرفتند برای تیم ملی جمهوری آذربایجان مبارزه کنند. سینا بهرامی در تکواندو پایه\\u200cگذار سفر به جمهوری آذربایجان و مسابقه\\u200cدادن با پرچم این کشور در تکواندو بود ولی میلاد بیگی را شاید بتوان مهم\\u200cترین شکار جمهوری آذربایجان در بین ورزشکاران ایرانی دانست. او با پرچم جمهوری آذربایجان دو مدال نقره جهانی به دست آورد و سپس در افتخاری فراموش\\u200cنشدنی موفق شد آذربایجان را صاحب مدال برنز المپیک در سال ۲۰۱۶ کند. سهیلا سیاحی هم دیگر تکواندوکار ایرانی بود که سر از تیم ملی جمهوری آذربایجان درآورد؛ هرچند توفیقی مثل بقیه در این زمینه به دست نیاورد. \\nحالا با مرور همین فهرست کوتاه و انتقالاتی که در سال\\u200cهای اخیر رخ داده، مشخص است اگر قرار باشد الهام علی\\u200cاف همچنان به صحبت\\u200cهای بحث\\u200cبرانگیزش علیه ایران ادامه دهد، حال\\u200cو\\u200cروز این ورزشکاران ایرانی که در\\u200cحال\\u200cحاضر عضوی از تیم ملی جمهوری آذربایجان هستند یا در لیگ\\u200cهای این کشور بازی می\\u200cکنند، مبهم می\\u200cشود. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "paragraphs_normalized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fkuile9iSypQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586f94d5-86b6-4bfa-8668-26ca97736bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 24307/24307 [00:02<00:00, 8408.33it/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "470313"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from hazm import sent_tokenize\n",
        "from itertools import chain\n",
        "sentences = list(chain(*[sent_tokenize(paragraph) for paragraph in pbar(paragraphs_normalized)]))\n",
        "len(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "diO_eiBD7RT9",
        "outputId": "10e9d645-aa4c-458d-8129-048236c8d792"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'شاید کمتر\\u200cکسی تصور می\\u200cکرد روزی رابطه ایران با جمهوری آذربایجان از لحاظ دیپلماتیک شکرآب شود؛ اگرچه هنوز چنین موضوعی به\\u200cصورت قطعی رخ نداده ولی نشانه\\u200cهایی در میان است که به نظر می\\u200cرسد رفته\\u200cرفته چنین شود.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from hazm import word_tokenize\n",
        "# tokens = list(chain(*[word_tokenize(sentence) for sentence in pbar(sentences)]))\n",
        "# len(tokens)"
      ],
      "metadata": {
        "id": "cKovahIh7SZC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens[:5]"
      ],
      "metadata": {
        "id": "sCZb4tvt9O9M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hazm import word_tokenize\n",
        "sentence_tokens = [word_tokenize(sentence) for sentence in pbar(sentences)]\n",
        "print(len(sentence_tokens))\n",
        "print(sentence_tokens[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzjSwnPF97th",
        "outputId": "aa70c621-9899-41bc-a7a4-ef90c35cb3b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 470313/470313 [00:19<00:00, 24480.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470313\n",
            "شاید\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import nltk\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from itertools import product\n",
        "from os.path import exists\n",
        "\n",
        "\n",
        "class LanguageModel(object):\n",
        "    \"\"\"An n-gram language model trained on a given corpus.\n",
        "    \n",
        "    For a given n and given training corpus, constructs an n-gram language\n",
        "    model for the corpus by:\n",
        "    1. preprocessing the corpus (adding SOS/EOS/UNK tokens)\n",
        "    2. calculating (smoothed) probabilities for each n-gram\n",
        "    Also contains methods for calculating the perplexity of the model\n",
        "    against another corpus, and for generating sentences.\n",
        "    Args:\n",
        "        train_data (list of str): list of sentences comprising the training corpus.\n",
        "        n (int): the order of language model to build (i.e. 1 for unigram, 2 for bigram, etc.).\n",
        "        laplace (int): lambda multiplier to use for laplace smoothing (default 1 for add-1 smoothing).\n",
        "    \"\"\"\n",
        "\n",
        "    SOS = \"<s>\"\n",
        "    EOS = \"</s>\"\n",
        "    UNK = \"<UNK>\"\n",
        "    \n",
        "    def __init__(self, train_data, n, laplace=1, recalculate=True):\n",
        "        self.n = n\n",
        "        self.recalculate = recalculate\n",
        "        self.vocab = dict()\n",
        "        self.laplace = laplace\n",
        "        self.n_grams = [None]*(n+1)\n",
        "        self.n_vocabs = [None]*(n+1)\n",
        "        self.tokens = None\n",
        "        self.models = None\n",
        "\n",
        "        self.preprocess(train_data, n)\n",
        "        self._create_model()\n",
        "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
        "\n",
        "    def _smooth(self):\n",
        "        \"\"\"Apply Laplace smoothing to n-gram frequency distribution.\n",
        "        \n",
        "        Here, n_grams refers to the n-grams of the tokens in the training corpus,\n",
        "        while m_grams refers to the first (n-1) tokens of each n-gram.\n",
        "        Returns:\n",
        "            dict: Mapping of each n-gram (tuple of str) to its Laplace-smoothed \n",
        "            probability (float).\n",
        "        \"\"\"\n",
        "        pickle_name = f'models_{str(self.n)}.pickle'\n",
        "        if self.recalculate or not os.path.exists(pickle_name):\n",
        "            print('Recalculating model')\n",
        "            vocab_size = len(self.vocab)\n",
        "\n",
        "            for i in range(2, self.n+1):\n",
        "                n_grams = nltk.ngrams(self.tokens, i)\n",
        "                n_vocab = nltk.FreqDist(n_grams)\n",
        "                self.n_grams[i] = n_grams\n",
        "                self.n_vocabs[i] = n_vocab\n",
        "\n",
        "            models = [None]*(self.n+1)\n",
        "            def smoothed_count(n_gram, n_count, n):\n",
        "                m_gram = n_gram[:-1]\n",
        "                m_count = self.n_vocabs[i][m_gram]\n",
        "                return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "\n",
        "            num_tokens = len(self.tokens)\n",
        "            models[1] = { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "            for i in range(2, self.n+1):\n",
        "                model = {\n",
        "                    n_gram: smoothed_count(n_gram, count, i) for n_gram, count in self.n_vocabs[i].items()\n",
        "                }\n",
        "                models[i] = model\n",
        "            self.models = models\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(models, pickle_out)\n",
        "            pickle_out.close()\n",
        "        else:\n",
        "            print('Loading model')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.models = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "    def _create_model(self):\n",
        "        \"\"\"Create a probability distribution for the vocabulary of the training corpus.\n",
        "        \n",
        "        If building a unigram model, the probabilities are simple relative frequencies\n",
        "        of each token with the entire corpus.\n",
        "        Otherwise, the probabilities are Laplace-smoothed relative frequencies.\n",
        "        Returns:\n",
        "            A dict mapping each n-gram (tuple of str) to its probability (float).\n",
        "        \"\"\"\n",
        "        if self.n == 1:\n",
        "            num_tokens = len(self.tokens)\n",
        "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            return self._smooth()\n",
        "\n",
        "    def _convert_oov(self, ngram):\n",
        "        \"\"\"Convert, if necessary, a given n-gram to one which is known by the model.\n",
        "        Starting with the unmodified ngram, check each possible permutation of the n-gram\n",
        "        with each index of the n-gram containing either the original token or <UNK>. Stop\n",
        "        when the model contains an entry for that permutation.\n",
        "        This is achieved by creating a 'bitmask' for the n-gram tuple, and swapping out\n",
        "        each flagged token for <UNK>. Thus, in the worst case, this function checks 2^n\n",
        "        possible n-grams before returning.\n",
        "        Returns:\n",
        "            The n-gram with <UNK> tokens in certain positions such that the model\n",
        "            contains an entry for it.\n",
        "        \"\"\"\n",
        "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
        "\n",
        "        ngram = (ngram,) if type(ngram) is str else ngram\n",
        "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
        "            if possible_known in self.model:\n",
        "                return possible_known\n",
        "\n",
        "    def perplexity(self, test_data):\n",
        "        \"\"\"Calculate the perplexity of the model against a given test corpus.\n",
        "        \n",
        "        Args:\n",
        "            test_data (list of str): sentences comprising the training corpus.\n",
        "        Returns:\n",
        "            The perplexity of the model as a float.\n",
        "        \n",
        "        \"\"\"\n",
        "        test_tokens = self.preprocess(test_data, self.n)\n",
        "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
        "        N = len(test_tokens)\n",
        "\n",
        "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
        "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
        "        \n",
        "        for x,y in zip(known_ngrams, probabilities):\n",
        "            print(x,y)\n",
        "        \n",
        "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
        "\n",
        "    def _best_candidate(self, prev, without=[], random=False):\n",
        "        \n",
        "        blacklist  = [LanguageModel.UNK] + without\n",
        "\n",
        "        if len(prev) < self.n-1:\n",
        "            prev = [LanguageModel.SOS]*(self.n-1 - len(prev)) + prev\n",
        "        elif len(prev) > self.n-1:\n",
        "            prev = prev[-(self.n-1):]\n",
        "        candidates = []\n",
        "        n = self.n\n",
        "        while len(candidates) == 0 and n > 0:\n",
        "            # print('---------------- n: ', n, prev[-(n-1):])\n",
        "            candidates = list(((ngram[-1],prob) for ngram,prob in self.models[n].items() if ngram[:-1]==tuple(prev[-(n-1):])))\n",
        "            n -= 1\n",
        "\n",
        "        if n == 0:\n",
        "            return [(\"\",0)]\n",
        "            # raise Exception('Not available')\n",
        "\n",
        "        return sorted(candidates, key=lambda x: -x[1])\n",
        "        # if random:\n",
        "        #     probs = [y for x,y in candidates]\n",
        "        #     probs = probs/np.sum(probs)\n",
        "        #     words = [x for x,y in candidates]\n",
        "        #     idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "\n",
        "        #     while words[idx] in blacklist:\n",
        "        #         idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "            \n",
        "        #     return (words[idx], probs[idx])\n",
        "        # else:\n",
        "        #     return max(candidates, key=lambda x: x[1])\n",
        "         \n",
        "    def generate_sentence(self, min_len=12, max_len=24):\n",
        "        sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
        "        while sent[-1] != LanguageModel.EOS:\n",
        "            prev = [] if self.n == 1 else sent[-(self.n-1):]\n",
        "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "\n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(LanguageModel.EOS)\n",
        "\n",
        "        return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
        "    \n",
        "    \n",
        "\n",
        "    def add_sentence_tokens(self, sentences, n):\n",
        "        \"\"\"Wrap each sentence in SOS and EOS tokens.\n",
        "        For n >= 2, n-1 SOS tokens are added, otherwise only one is added.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to wrap.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            List of sentences with SOS and EOS tokens wrapped around them.\n",
        "        \"\"\"\n",
        "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
        "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
        "\n",
        "    def replace_singletons(self, tokens):\n",
        "        \"\"\"Replace tokens which appear only once in the corpus with <UNK>.\n",
        "\n",
        "        Args:\n",
        "            tokens (list of str): the tokens comprising the corpus.\n",
        "        Returns:\n",
        "            The same list of tokens with each singleton replaced by <UNK>.\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.vocab) == 0:\n",
        "            self.vocab = nltk.FreqDist(tokens)\n",
        "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
        "\n",
        "    def preprocess(self, sentences, n):\n",
        "        \"\"\"Add SOS/EOS/UNK tokens to given sentences and tokenize.\n",
        "        Args:\n",
        "            sentences (list of str): the sentences to preprocess.\n",
        "            n (int): order of the n-gram model which will use these sentences.\n",
        "        Returns:\n",
        "            The preprocessed sentences, tokenized by words.\n",
        "        \"\"\"\n",
        "        pickle_name = f'tokens_{str(self.n)}.pickle'\n",
        "\n",
        "        if self.recalculate or not os.path.exists(pickle_name):\n",
        "            print('Recalculating tokens')\n",
        "            sentences = self.add_sentence_tokens(sentences, n)\n",
        "            tokens = ' '.join(sentences).split()\n",
        "            self.tokens = self.replace_singletons(tokens)\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(tokens, pickle_out)\n",
        "            pickle_out.close()\n",
        "        else:\n",
        "            print('Loading tokens')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.tokens = pickle.load(pickle_in)\n",
        "\n",
        "        pickle_name = f'vocab_{str(self.n)}.pickle'\n",
        "        if self.recalculate or not exists(pickle_name):\n",
        "            print('Recalculating vocab')\n",
        "            self.vocab  = nltk.FreqDist(self.tokens)\n",
        "            pickle_out = open(pickle_name,\"wb\")\n",
        "            pickle.dump(self.vocab, pickle_out)\n",
        "            pickle_out.close()\n",
        "        else:\n",
        "            print('Loading vocab')\n",
        "            pickle_in = open(pickle_name,\"rb\")\n",
        "            self.vocab = pickle.load(pickle_in)"
      ],
      "metadata": {
        "id": "RRb0PrbfRUIm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "language_model = LanguageModel(sentences, 4, 1, recalculate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZlFPgeL-kd4",
        "outputId": "4584c78d-ede4-4cda-a491-cfd10dfb7364"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recalculating tokens\n",
            "Recalculating vocab\n",
            "Recalculating model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sent, prob= language_model.generate_sentence(min_len=4, max_len=12)\n",
        "\n",
        "# print(sent)\n",
        "# print(prob)"
      ],
      "metadata": {
        "id": "IyU1CvJE_WOK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prev = [\n",
        "#         'امروز',\n",
        "#         'فوتبال',\n",
        "#         'بازی',\n",
        "# ]\n",
        "prev = [\n",
        "        'او',\n",
        "        'علیرضا',\n",
        "]\n",
        "prev = [\n",
        "        'محمد'\n",
        "]\n",
        "# prev = [\n",
        "#         'من',\n",
        "#         'امروز'\n",
        "# ]\n",
        "# prev = [\n",
        "#         'سال‌ها',\n",
        "#         'با',\n",
        "# ]\n",
        "next = language_model._best_candidate(prev, random=False)\n",
        "next"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyMS2lDtCGi4",
        "outputId": "4a30036b-93ca-46dc-a037-580f005987cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('موسوی', 0.0006837380621539954),\n",
              " ('بنا', 0.00043009329716138425),\n",
              " ('<UNK>', 0.0004190652639008359),\n",
              " ('جمشیدی', 0.000385981164119191),\n",
              " ('وکیلی', 0.00036392509759809434),\n",
              " ('ترکاشوند', 0.0003418690310769977),\n",
              " ('دادکان', 0.0002426167317320629),\n",
              " ('بنا،', 0.0002315886984715146),\n",
              " ('یوسف\\u200cوند', 0.0002315886984715146),\n",
              " ('رویانیان', 0.00018747656542932134),\n",
              " ('مایلی\\u200cکهن', 0.00017644853216877303),\n",
              " ('مافی:', 0.0001543924656476764),\n",
              " ('حسین', 0.0001543924656476764),\n",
              " ('رویانیان،', 0.00014336443238712807),\n",
              " ('حسن', 0.00014336443238712807),\n",
              " ('دامغانی', 0.00014336443238712807),\n",
              " ('صلاح', 0.00013233639912657976),\n",
              " ('نوری', 0.00012130836586603145),\n",
              " ('حسن\\u200cزاده', 0.00012130836586603145),\n",
              " ('کسایی\\u200cپور', 0.00012130836586603145),\n",
              " ('انصاری', 0.00011028033260548313),\n",
              " ('دانشور', 0.00011028033260548313),\n",
              " ('موسوی،', 9.925229934493483e-05),\n",
              " ('رهبری', 9.925229934493483e-05),\n",
              " ('دادکان،', 9.925229934493483e-05),\n",
              " ('عباسی،', 9.925229934493483e-05),\n",
              " ('خاکپور', 8.822426608438651e-05),\n",
              " ('علی\\u200cآبادی،', 8.822426608438651e-05),\n",
              " ('قاضی', 8.822426608438651e-05),\n",
              " ('جمشیدی،', 8.822426608438651e-05),\n",
              " ('نادری', 7.71962328238382e-05),\n",
              " ('پولادگر،', 7.71962328238382e-05),\n",
              " ('پنجعلی،', 7.71962328238382e-05),\n",
              " ('بنا:', 7.71962328238382e-05),\n",
              " ('دادگان', 7.71962328238382e-05),\n",
              " ('رضا', 7.71962328238382e-05),\n",
              " ('احمدزاده،', 6.616819956328988e-05),\n",
              " ('علی\\u200cآبادی', 6.616819956328988e-05),\n",
              " ('خاکپور،', 6.616819956328988e-05),\n",
              " ('عباسی', 6.616819956328988e-05),\n",
              " ('رجبلو', 6.616819956328988e-05),\n",
              " ('ارزنده', 6.616819956328988e-05),\n",
              " ('پنجعلی', 5.514016630274157e-05),\n",
              " ('ایران\\u200cپوریان', 5.514016630274157e-05),\n",
              " ('منصوری', 5.514016630274157e-05),\n",
              " ('درخشان،', 5.514016630274157e-05),\n",
              " ('احمدزاده', 5.514016630274157e-05),\n",
              " ('طلایی،', 5.514016630274157e-05),\n",
              " ('صمیمی', 5.514016630274157e-05),\n",
              " ('مهدی', 5.514016630274157e-05),\n",
              " ('جواد', 5.514016630274157e-05),\n",
              " ('شریعتمداری،', 4.4112133042193257e-05),\n",
              " ('عباس\\u200cزاده', 4.4112133042193257e-05),\n",
              " ('پراش', 4.4112133042193257e-05),\n",
              " ('ترکاشوند،', 4.4112133042193257e-05),\n",
              " ('دلیریان،', 4.4112133042193257e-05),\n",
              " ('پروین', 4.4112133042193257e-05),\n",
              " ('دایی', 4.4112133042193257e-05),\n",
              " ('ناظم\\u200cالشریعه', 4.4112133042193257e-05),\n",
              " ('انصاری،', 4.4112133042193257e-05),\n",
              " ('قاضی،', 4.4112133042193257e-05),\n",
              " ('باقری\\u200cمعتمد،', 4.4112133042193257e-05),\n",
              " ('دانشور،', 4.4112133042193257e-05),\n",
              " ('درخشان', 4.4112133042193257e-05),\n",
              " ('کشاورز،', 4.4112133042193257e-05),\n",
              " ('ابراهیمی', 4.4112133042193257e-05),\n",
              " ('علی', 4.4112133042193257e-05),\n",
              " ('ترابی،', 4.4112133042193257e-05),\n",
              " ('طاهر', 4.4112133042193257e-05),\n",
              " ('کرمانشاهی', 4.4112133042193257e-05),\n",
              " ('سیاوشی', 4.4112133042193257e-05),\n",
              " ('یوسف\\u200cوند،', 4.4112133042193257e-05),\n",
              " ('نصیری', 3.308409978164494e-05),\n",
              " ('علیرضایی', 3.308409978164494e-05),\n",
              " ('دانشگر،', 3.308409978164494e-05),\n",
              " ('عباس\\u200cزاده،', 3.308409978164494e-05),\n",
              " ('دادگان،', 3.308409978164494e-05),\n",
              " ('نادری،', 3.308409978164494e-05),\n",
              " ('نوری،', 3.308409978164494e-05),\n",
              " ('حسن\\u200cنژاد،', 3.308409978164494e-05),\n",
              " ('نصرتی', 3.308409978164494e-05),\n",
              " ('نصیری،', 3.308409978164494e-05),\n",
              " ('شروین', 3.308409978164494e-05),\n",
              " ('بن', 3.308409978164494e-05),\n",
              " ('کاظمی', 3.308409978164494e-05),\n",
              " ('شریعتمداری', 3.308409978164494e-05),\n",
              " ('طلایی', 3.308409978164494e-05),\n",
              " ('وکیلی،', 3.308409978164494e-05),\n",
              " ('زارعی', 3.308409978164494e-05),\n",
              " ('طیبی', 3.308409978164494e-05),\n",
              " ('نهاوندیان', 3.308409978164494e-05),\n",
              " ('خرمگاه،', 3.308409978164494e-05),\n",
              " ('دایی،', 3.308409978164494e-05),\n",
              " ('صمیمی،', 3.308409978164494e-05),\n",
              " ('باقری\\u200cمعتمد', 3.308409978164494e-05),\n",
              " ('ناظم\\u200cالشریعه،', 3.308409978164494e-05),\n",
              " ('خالوندی', 3.308409978164494e-05),\n",
              " ('رشنونژاد', 3.308409978164494e-05),\n",
              " ('نزهتی،', 3.308409978164494e-05),\n",
              " ('نصرتی،', 3.308409978164494e-05),\n",
              " ('مافی،', 3.308409978164494e-05),\n",
              " ('ارزنده،', 3.308409978164494e-05),\n",
              " ('مایلی\\u200cکهن:', 3.308409978164494e-05),\n",
              " ('شمس', 3.308409978164494e-05),\n",
              " ('کیادربندسری', 3.308409978164494e-05),\n",
              " ('حمیدی:', 3.308409978164494e-05),\n",
              " ('نوربخش', 3.308409978164494e-05),\n",
              " ('صالحی', 3.308409978164494e-05),\n",
              " ('خمسه،', 3.308409978164494e-05),\n",
              " ('ابراهیم', 3.308409978164494e-05),\n",
              " ('قاسمی', 3.308409978164494e-05),\n",
              " ('عابدینی', 3.308409978164494e-05),\n",
              " ('فلاح', 3.308409978164494e-05),\n",
              " ('قاسمی،', 3.308409978164494e-05),\n",
              " ('دوست', 3.308409978164494e-05),\n",
              " ('یوسف', 3.308409978164494e-05),\n",
              " ('کسایی', 3.308409978164494e-05),\n",
              " ('عثمان', 2.2056066521096628e-05),\n",
              " ('شریفی', 2.2056066521096628e-05),\n",
              " ('اسفندیاری،', 2.2056066521096628e-05),\n",
              " ('بریمانلو', 2.2056066521096628e-05),\n",
              " ('رضایی', 2.2056066521096628e-05),\n",
              " ('رهبری،', 2.2056066521096628e-05),\n",
              " ('دهنوی', 2.2056066521096628e-05),\n",
              " ('محمدی\\u200cبریمانلو،', 2.2056066521096628e-05),\n",
              " ('خاتمی،', 2.2056066521096628e-05),\n",
              " ('مصلایی\\u200cپور', 2.2056066521096628e-05),\n",
              " ('قاسمی\\u200cنژاد،', 2.2056066521096628e-05),\n",
              " ('اکبری', 2.2056066521096628e-05),\n",
              " ('شریفی،', 2.2056066521096628e-05),\n",
              " ('پراش،', 2.2056066521096628e-05),\n",
              " ('شاهمرادی', 2.2056066521096628e-05),\n",
              " ('تابع،', 2.2056066521096628e-05),\n",
              " ('رحیمی', 2.2056066521096628e-05),\n",
              " ('درویش', 2.2056066521096628e-05),\n",
              " ('عباس\\u200cزاده؛', 2.2056066521096628e-05),\n",
              " ('نبی', 2.2056066521096628e-05),\n",
              " ('دریس', 2.2056066521096628e-05),\n",
              " ('دادگان:', 2.2056066521096628e-05),\n",
              " ('محبی', 2.2056066521096628e-05),\n",
              " ('پروین،', 2.2056066521096628e-05),\n",
              " ('اما', 2.2056066521096628e-05),\n",
              " ('در', 2.2056066521096628e-05),\n",
              " ('دایی؛', 2.2056066521096628e-05),\n",
              " ('بریمانلو،', 2.2056066521096628e-05),\n",
              " ('ناصری', 2.2056066521096628e-05),\n",
              " ('کریمی:', 2.2056066521096628e-05),\n",
              " ('خاتمی', 2.2056066521096628e-05),\n",
              " ('محسن', 2.2056066521096628e-05),\n",
              " ('حسن\\u200cنژاد', 2.2056066521096628e-05),\n",
              " ('تقوی،', 2.2056066521096628e-05),\n",
              " ('ناظری،', 2.2056066521096628e-05),\n",
              " ('الدعایه', 2.2056066521096628e-05),\n",
              " ('کریمی', 2.2056066521096628e-05),\n",
              " ('خانزاده،', 2.2056066521096628e-05),\n",
              " ('عبدالله', 2.2056066521096628e-05),\n",
              " ('فنایی', 2.2056066521096628e-05),\n",
              " ('فنایی،', 2.2056066521096628e-05),\n",
              " ('صادقی،', 2.2056066521096628e-05),\n",
              " ('کیادربندسری،', 2.2056066521096628e-05),\n",
              " ('الشیخ،', 2.2056066521096628e-05),\n",
              " ('غبیشاوی،', 2.2056066521096628e-05),\n",
              " ('هاشمی،', 2.2056066521096628e-05),\n",
              " ('حسینوند،', 2.2056066521096628e-05),\n",
              " ('عرفان،', 2.2056066521096628e-05),\n",
              " ('گنج\\u200cخانلو', 2.2056066521096628e-05),\n",
              " ('شربی\\u200cنیازی', 2.2056066521096628e-05),\n",
              " ('جلود', 2.2056066521096628e-05),\n",
              " ('شهاب\\u200cانداز', 2.2056066521096628e-05),\n",
              " ('جلود،', 2.2056066521096628e-05),\n",
              " ('حقانی،', 2.2056066521096628e-05),\n",
              " ('پولادگر', 2.2056066521096628e-05),\n",
              " ('آرام\\u200cطبع', 2.2056066521096628e-05),\n",
              " ('رشدی', 2.2056066521096628e-05),\n",
              " ('صالحی،', 2.2056066521096628e-05),\n",
              " ('گودرزی،', 2.2056066521096628e-05),\n",
              " ('موئدی', 2.2056066521096628e-05),\n",
              " ('پورحیدری', 2.2056066521096628e-05),\n",
              " ('فتحی\\u200cگنجی', 2.2056066521096628e-05),\n",
              " ('ناظری', 2.2056066521096628e-05),\n",
              " ('فرح،', 2.2056066521096628e-05),\n",
              " ('زادمهر', 2.2056066521096628e-05),\n",
              " ('بخشی،', 2.2056066521096628e-05),\n",
              " ('کاظمیان،', 2.2056066521096628e-05),\n",
              " ('ستاری،', 2.2056066521096628e-05),\n",
              " ('ابراهیمی،', 2.2056066521096628e-05),\n",
              " ('خضرایی', 2.2056066521096628e-05),\n",
              " ('کشاورز', 2.2056066521096628e-05),\n",
              " ('دانشگر', 2.2056066521096628e-05),\n",
              " ('طحان\\u200cپور', 2.2056066521096628e-05),\n",
              " ('نوازی', 2.2056066521096628e-05),\n",
              " ('ارشدی،', 2.2056066521096628e-05),\n",
              " ('بداوی', 2.2056066521096628e-05),\n",
              " ('ربیعی،', 2.2056066521096628e-05),\n",
              " ('مصدق،', 2.2056066521096628e-05),\n",
              " ('دلیریان', 2.2056066521096628e-05),\n",
              " ('رنجبر،', 2.2056066521096628e-05),\n",
              " ('شاهمیری،', 2.2056066521096628e-05),\n",
              " ('احمدپناه', 2.2056066521096628e-05),\n",
              " ('غلامی', 2.2056066521096628e-05),\n",
              " ('غلامی،', 2.2056066521096628e-05),\n",
              " ('رشنونژاد،', 2.2056066521096628e-05),\n",
              " ('محمدی', 2.2056066521096628e-05),\n",
              " ('تنابنده', 2.2056066521096628e-05),\n",
              " ('سلیمانی', 2.2056066521096628e-05),\n",
              " ('نظری،', 2.2056066521096628e-05),\n",
              " ('بچیروویچ،', 2.2056066521096628e-05),\n",
              " ('احمدزاده:', 2.2056066521096628e-05),\n",
              " ('فیروزی', 2.2056066521096628e-05),\n",
              " ('صادق', 2.2056066521096628e-05),\n",
              " ('سازنچیان', 2.2056066521096628e-05),\n",
              " ('شجاعی', 2.2056066521096628e-05),\n",
              " ('آبشک،', 2.2056066521096628e-05),\n",
              " ('فرامرزی', 2.2056066521096628e-05),\n",
              " ('عمر،', 2.2056066521096628e-05),\n",
              " ('فقیری', 2.2056066521096628e-05),\n",
              " ('ترابیان،', 2.2056066521096628e-05),\n",
              " ('عاری،', 2.2056066521096628e-05),\n",
              " ('جوانی', 2.2056066521096628e-05),\n",
              " ('یوسفی', 2.2056066521096628e-05),\n",
              " ('جمالی', 2.2056066521096628e-05),\n",
              " ('سررشته\\u200cداری،', 2.2056066521096628e-05),\n",
              " ('مایلی\\u200cکهن،', 2.2056066521096628e-05),\n",
              " ('که', 2.2056066521096628e-05),\n",
              " ('هم', 2.2056066521096628e-05),\n",
              " ('عاری', 2.2056066521096628e-05),\n",
              " ('دانیل', 2.2056066521096628e-05),\n",
              " ('خاکپور:', 2.2056066521096628e-05),\n",
              " ('بیرامی', 2.2056066521096628e-05),\n",
              " ('یوسفوند', 2.2056066521096628e-05),\n",
              " ('حضرت', 2.2056066521096628e-05),\n",
              " ('کاظم', 2.2056066521096628e-05),\n",
              " ('تقی', 2.2056066521096628e-05),\n",
              " ('علیپور:', 2.2056066521096628e-05),\n",
              " ('شیرازی', 2.2056066521096628e-05),\n",
              " ('شعبان', 2.2056066521096628e-05),\n",
              " ('صالحیان', 2.2056066521096628e-05),\n",
              " ('حسین\\u200c', 2.2056066521096628e-05),\n",
              " ('مشهدی', 2.2056066521096628e-05),\n",
              " ('فتحعلی،', 2.2056066521096628e-05),\n",
              " ('ضماند', 2.2056066521096628e-05),\n",
              " ('صادقی', 2.2056066521096628e-05),\n",
              " ('سیستانی', 2.2056066521096628e-05),\n",
              " ('جمشیدی:', 2.2056066521096628e-05),\n",
              " ('کسایی\\u200cپور،', 2.2056066521096628e-05),\n",
              " ('تر\\u200cکا\\u200cشو\\u200cند\\u200c', 2.2056066521096628e-05),\n",
              " ('عبدالرحمان', 2.2056066521096628e-05),\n",
              " ('کرمانشاهی،', 2.2056066521096628e-05),\n",
              " ('شاهسوند', 2.2056066521096628e-05),\n",
              " ('شهریان', 2.2056066521096628e-05),\n",
              " ('نیز', 2.2056066521096628e-05),\n",
              " ('حسن\\u200cزاده،', 2.2056066521096628e-05),\n",
              " ('صمد', 2.2056066521096628e-05),\n",
              " ('الوان', 2.2056066521096628e-05),\n",
              " ('صلاح،', 2.2056066521096628e-05),\n",
              " ('اسماعیل', 2.2056066521096628e-05),\n",
              " ('ابوحیدری', 2.2056066521096628e-05),\n",
              " ('سیفی', 2.2056066521096628e-05),\n",
              " ('گنج', 2.2056066521096628e-05),\n",
              " ('ملک', 2.2056066521096628e-05),\n",
              " ('کیادهی', 2.2056066521096628e-05),\n",
              " ('جعفر', 2.2056066521096628e-05)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YdCL9cpM5RD",
        "outputId": "726fb43c-b7f4-4580-e225-7d130cf983fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 900M\n",
            "4.0K drive\t      4.0K sample_data\t226M tokens_4.pickle\n",
            "672M models_4.pickle  4.0K test.txt\t2.3M vocab_4.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "C8-DteZnjiuB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ngram.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}