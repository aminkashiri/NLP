{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 571/571 [00:00<00:00, 562kB/s]\n",
      "Downloading: 100%|██████████| 1.25G/1.25G [18:34<00:00, 1.21MB/s] \n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 12.9kB/s]\n",
      "Downloading: 100%|██████████| 226k/226k [00:01<00:00, 189kB/s]  \n",
      "Downloading: 100%|██████████| 455k/455k [00:02<00:00, 228kB/s]  \n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-large-uncased\", tokenizer=\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4954774081707001,\n",
       "  'token': 4092,\n",
       "  'token_str': 'speaking',\n",
       "  'sequence': 'i am speaking english.'},\n",
       " {'score': 0.31246477365493774,\n",
       "  'token': 2025,\n",
       "  'token_str': 'not',\n",
       "  'sequence': 'i am not english.'},\n",
       " {'score': 0.08286348730325699,\n",
       "  'token': 1999,\n",
       "  'token_str': 'in',\n",
       "  'sequence': 'i am in english.'},\n",
       " {'score': 0.030466800555586815,\n",
       "  'token': 4083,\n",
       "  'token_str': 'learning',\n",
       "  'sequence': 'i am learning english.'},\n",
       " {'score': 0.0052549890242516994,\n",
       "  'token': 5702,\n",
       "  'token_str': 'studying',\n",
       "  'sequence': 'i am studying english.'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The capital of Iran is [MASK].\"\n",
    "text = \"Yesterday, I played [MASK] in the stadium\"\n",
    "text = \"Yesterday, I played [MASK] in the [MASK].\"\n",
    "text = \"I'm studying [MASK] learning in my computer class.\"\n",
    "text = \"I'm a very [MASK] player in football.\"\n",
    "text = \"He drived a [MASK].\"\n",
    "text = \"I love playing [MASK].\"\n",
    "text = \"I am [MASK] english.\"\n",
    "\n",
    "unmasker(text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34daa296ffe99e8a66e159d01b1dfeb9a87967b5cca691fda43c054f03617153"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
