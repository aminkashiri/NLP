{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Required Libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahur4/anaconda3/envs/data_env/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from transformers import pipeline, BertTokenizer, BertForMaskedLM, AlbertTokenizer, AlbertForMaskedLM, RobertaTokenizer,\n",
    "\n",
    "RobertaModel\n",
    "from transformers.pipelines.fill_mask import FillMaskPipeline\n",
    "import torch\n",
    "\n",
    "from spacy.tokens.token import Token\n",
    "from spacy.tokens.doc import Doc\n",
    "import editdistance\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: cpu\n",
      "en roberta Model Loaded ...\n"
     ]
    }
   ],
   "source": [
    "# torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch_device = 'cpu'\n",
    "print(f\"Torch Device: {torch_device}\")\n",
    "\n",
    "language = 'en'\n",
    "model_type = 'roberta'\n",
    "\n",
    "# EN\n",
    "# model_name = \"bert-large-uncased\" # Bert large\n",
    "# model_name = \"bert-base-uncased\" # Bert base\n",
    "model_name = \"roberta-large\"  # Roberta\n",
    "\n",
    "# FA\n",
    "# model_name = \"HooshvareLab/albert-fa-zwnj-base-v2\" # Albert\n",
    "# model_name = \"HooshvareLab/bert-fa-base-uncased\" # BERT V2\n",
    "# model_name = \"HooshvareLab/bert-fa-zwnj-base\" # BERT V3\n",
    "\n",
    "if model_type == 'bert':\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else BertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'albert':\n",
    "    tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "    model = AlbertForMaskedLM.from_pretrained(model_name).to(\n",
    "        torch_device) if language == 'en' else AlbertForMaskedLM.from_pretrained(model_name).to(torch_device)\n",
    "    MASK = \"[MASK]\"\n",
    "    unmasker = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "elif model_type == 'roberta':\n",
    "    MASK = \"<mask>\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "    unmasker = pipeline('fill-mask', model='roberta-large')\n",
    "\n",
    "else:\n",
    "    print(f\"{model_type} not found.\")\n",
    "\n",
    "vocab: set = set(tokenizer.get_vocab().keys())\n",
    "\n",
    "if model_type == 'roberta':\n",
    "    vocab = set(map(lambda s: s[1:], vocab))\n",
    "\n",
    "print(f\"{language} {model_type} Model Loaded ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Stanza\n",
    "\n",
    "spaCy's tokenization is non-destructive, so it always represents the original input text and never adds or deletes anything. This is kind of a core principle of the Doc object: you should always be able to reconstruct and reproduce the original input text.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import spacy\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if language == 'fa':\n",
    "    stanza.install_corenlp()\n",
    "    stanza.download('fa')\n",
    "    nlp = spacy_stanza.load_pipeline(\"fa\")\n",
    "\n",
    "elif language == 'en':\n",
    "    spacy.prefer_gpu()\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"{language} not supported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Lexico Typo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def lexico_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index, current_token in enumerate(doc):\n",
    "            current_token: Token\n",
    "            start_char_index: int = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            if current_token.text not in vocab:\n",
    "                if verbose:\n",
    "                    print(\"*\" * 50)\n",
    "                    print(f\"[{current_token.text}] is not in vocab\")\n",
    "\n",
    "                masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "                predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "                ### Select Token From Predicts\n",
    "                predicts = pd.DataFrame(predicts)\n",
    "\n",
    "                predicts['token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "                predicts['edit_distance'] = predicts['token_str'].apply(lambda tk: editdistance.eval(current_token.text, tk))\n",
    "\n",
    "                predicts['edit_distance_to_len_ratio'] = predicts['edit_distance'] / len(current_token.text)\n",
    "\n",
    "                selected_predicts = predicts[(predicts['edit_distance_to_len_ratio'] <= max_edit_distance_to_length_ratio) &\n",
    "                                             (predicts['edit_distance'] <= max_edit_distance) & (predicts['score'] >= min_score)]\n",
    "\n",
    "                try:\n",
    "                    selected_predict = selected_predicts['token_str'].iloc[0]\n",
    "                except:\n",
    "                    selected_predict = current_token.text\n",
    "                    if selected_predict not in vocab:\n",
    "                        vocab.add(selected_predict)\n",
    "\n",
    "                if selected_predict != current_token.text:\n",
    "                    some_token_corrected = True\n",
    "                    result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                    text = result_text\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"*\" * 50)\n",
    "                    print(f\"Token: {current_token.text}\")\n",
    "\n",
    "                    print(\"Predicts: \\n\")\n",
    "                    print(predicts[['token_str', 'score']])\n",
    "\n",
    "                    print(\"Filtered Predicts: \\n\")\n",
    "                    print(selected_predicts[['token_str', 'score']])\n",
    "                    print(f\"{current_token.text} -> {selected_predict}\")\n",
    "\n",
    "                    print(\"SOME TOKEN CORRECTED!!!\")\n",
    "\n",
    "                if some_token_corrected:\n",
    "                    break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Result text: \\n{text}\")\n",
    "\n",
    "    return text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Correct Contextual Typo\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def contextual_typo_correction(\n",
    "        text,\n",
    "        max_edit_distance_to_length_ratio=0.45,\n",
    "        max_edit_distance=2,\n",
    "        min_score=1e-7,\n",
    "        top_k=10,\n",
    "        verbose=False,\n",
    "):\n",
    "    while True:\n",
    "        some_token_corrected = False\n",
    "        doc = nlp(text)\n",
    "        for index in range(len(doc)):\n",
    "            current_token: Token = doc[index]\n",
    "\n",
    "            start_char_index = current_token.idx\n",
    "            end_char_index = start_char_index + len(current_token)\n",
    "\n",
    "            masked_text = doc.text[:start_char_index] + MASK + doc.text[end_char_index:]\n",
    "\n",
    "            predicts = unmasker(masked_text, top_k=top_k)\n",
    "\n",
    "            ### Select Token From Predicts\n",
    "            predicts = pd.DataFrame(predicts)\n",
    "\n",
    "            predicts['token_str'] = predicts['token_str'].apply(lambda tk: tk.replace(\" \", \"\"))\n",
    "            predicts['edit_distance'] = predicts['token_str'].apply(\n",
    "                lambda tk: editdistance.eval(current_token.text, tk))\n",
    "            predicts['edit_distance_to_len_ratio'] = predicts['edit_distance'] / len(current_token.text)\n",
    "\n",
    "            try:\n",
    "                if current_token.text in string.punctuation:\n",
    "                    selected_predict = predicts['token_str'].iloc[0]\n",
    "\n",
    "                elif current_token.text.isdigit():\n",
    "                    selected_predict = current_token.text\n",
    "\n",
    "                else:\n",
    "                    selected_predicts = predicts[\n",
    "                        (predicts['edit_distance_to_len_ratio'] <= max_edit_distance_to_length_ratio) &\n",
    "                        (predicts['edit_distance'] <= max_edit_distance) &\n",
    "                        (predicts['score'] >= min_score)]\n",
    "\n",
    "\n",
    "\n",
    "                    selected_predict = selected_predicts.sort_values('edit_distance_to_len_ratio')['token_str'].iloc[0]\n",
    "\n",
    "                    current_token_text_score = selected_predicts['score'][selected_predicts['token_str'] == current_token.text]\n",
    "\n",
    "                    selected_token_text_score = selected_predicts.sort_values('edit_distance_to_len_ratio')['score'].iloc[0]\n",
    "\n",
    "                    if current_token.text != selected_predict:\n",
    "\n",
    "                        if current_token.text in selected_predicts['token_str'].values:\n",
    "                            print(\"\\n\")\n",
    "                            print(f\"current_token_text_score: {current_token_text_score}, selected_token_text_score: {selected_token_text_score}\")\n",
    "                            print(\"\\n\")\n",
    "\n",
    "                            if selected_token_text_score / current_token_text_score > 50:\n",
    "                                selected_predict = selected_predicts.sort_values('edit_distance_to_len_ratio')['token_str'].iloc[0]\n",
    "\n",
    "                            else:\n",
    "                                selected_predict = current_token.text\n",
    "\n",
    "                        else:\n",
    "                            selected_predict = selected_predicts.sort_values('edit_distance_to_len_ratio')['token_str'].iloc[0]\n",
    "\n",
    "            except:\n",
    "                selected_predict = current_token.text\n",
    "\n",
    "            if selected_predict != current_token.text:\n",
    "                some_token_corrected = True\n",
    "                result_text = masked_text.replace(MASK, selected_predict, 1)\n",
    "                text = result_text\n",
    "\n",
    "            if verbose:\n",
    "                print(\"*\" * 50)\n",
    "                print(f\"Token: {current_token.text}\")\n",
    "\n",
    "                print(\"Predicts: \\n\")\n",
    "                print(predicts[['token_str', 'score']])\n",
    "\n",
    "                print(\"Filtered Predicts: \\n\")\n",
    "                print(selected_predicts[['token_str', 'score', 'edit_distance_to_len_ratio']])\n",
    "                print(f\"{current_token.text} -> {selected_predict}\")\n",
    "\n",
    "            if some_token_corrected:\n",
    "                break\n",
    "\n",
    "        if not some_token_corrected:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Result text: \\n{text}\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Correction Pipeline Class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "class SpellCorrector:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            max_edit_distance_to_length_ratio=0.45,\n",
    "            max_edit_distance=2,\n",
    "            min_score=1e-7,\n",
    "            verbose=False,\n",
    "            top_k=50\n",
    "    ):\n",
    "        self.max_edit_distance_to_length_ratio = max_edit_distance_to_length_ratio\n",
    "        self.max_edit_distance = max_edit_distance\n",
    "        self.min_score = min_score\n",
    "        self.verbose = verbose\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def _lexico_typo_correction(self, text):\n",
    "        return lexico_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                      self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def _contextual_typo_correction(self, text):\n",
    "        return contextual_typo_correction(text, self.max_edit_distance_to_length_ratio, self.max_edit_distance,\n",
    "                                          self.min_score, self.top_k, self.verbose, )\n",
    "\n",
    "    def correction_pipeline(self, text):\n",
    "        print(\"Lexico Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._lexico_typo_correction(text)\n",
    "\n",
    "        print(\"Contextual Correction ...\") if self.verbose else print()\n",
    "        corrected_text = self._contextual_typo_correction(corrected_text)\n",
    "        return corrected_text\n",
    "\n",
    "    def __call__(self, text, *args, **kwargs):\n",
    "        return self.correction_pipeline(text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test On Sample Texts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexico Correction ...\n",
      "**************************************************\n",
      "[decentrallized] is not in vocab\n",
      "**************************************************\n",
      "Token: decentrallized\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0    decentralized  0.479969\n",
      "1          virtual  0.058116\n",
      "2             free  0.045404\n",
      "3           secure  0.039285\n",
      "4    cryptographic  0.033346\n",
      "..             ...       ...\n",
      "245      dedicated  0.000106\n",
      "246      versatile  0.000105\n",
      "247  comprehensive  0.000104\n",
      "248         proven  0.000102\n",
      "249     relatively  0.000099\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0  decentralized  0.479969\n",
      "decentrallized -> decentralized\n",
      "SOME TOKEN CORRECTED!!!\n",
      "**************************************************\n",
      "[curency] is not in vocab\n",
      "**************************************************\n",
      "Token: curency\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0     currency  0.863189\n",
      "1        asset  0.069856\n",
      "2        token  0.023188\n",
      "3        money  0.016133\n",
      "4         coin  0.005230\n",
      "..         ...       ...\n",
      "245       lock  0.000001\n",
      "246     bounty  0.000001\n",
      "247      notes  0.000001\n",
      "248  portfolio  0.000001\n",
      "249     matter  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score\n",
      "0  currency  0.863189\n",
      "curency -> currency\n",
      "SOME TOKEN CORRECTED!!!\n",
      "**************************************************\n",
      "[transfered] is not in vocab\n",
      "**************************************************\n",
      "Token: transfered\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0       traded  0.421989\n",
      "1    exchanged  0.265843\n",
      "2         used  0.180609\n",
      "3    purchased  0.032875\n",
      "4        spent  0.029688\n",
      "..         ...       ...\n",
      "245      money  0.000009\n",
      "246     pegged  0.000009\n",
      "247     merged  0.000009\n",
      "248    Bitcoin  0.000009\n",
      "249   provided  0.000009\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "     token_str     score\n",
      "9  transferred  0.004273\n",
      "transfered -> transferred\n",
      "SOME TOKEN CORRECTED!!!\n",
      "Result text: \n",
      "Bitcoin is a decentralized digital currency that can be transferred on the peer-to-peer bitcoin network.\n",
      "Contextual Correction ...\n",
      "**************************************************\n",
      "Token: Bitcoin\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0     Bitcoin  9.474612e-01\n",
      "1     bitcoin  2.450448e-02\n",
      "2         BTC  9.873248e-03\n",
      "3        Coin  5.669167e-03\n",
      "4        Cash  2.599140e-03\n",
      "..        ...           ...\n",
      "245      Base  5.292040e-07\n",
      "246    Reward  5.291374e-07\n",
      "247       Don  5.270745e-07\n",
      "248      Rush  5.264556e-07\n",
      "249        TC  5.239312e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   Bitcoin  0.947461                    0.000000\n",
      "1   bitcoin  0.024504                    0.142857\n",
      "Bitcoin -> Bitcoin\n",
      "**************************************************\n",
      "Token: is\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            is  9.972281e-01\n",
      "1             ,  1.320823e-03\n",
      "2             :  4.260270e-04\n",
      "3             –  1.079769e-04\n",
      "4    represents  1.041605e-04\n",
      "..          ...           ...\n",
      "245          .,  9.790376e-08\n",
      "246   exchanges  9.631092e-08\n",
      "247       hosts  9.620958e-08\n",
      "248   announces  9.618645e-08\n",
      "249       notes  9.540116e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        is  0.997228                         0.0\n",
      "is -> is\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0              a  9.745944e-01\n",
      "1            the  2.420179e-02\n",
      "2             an  7.798372e-04\n",
      "3              a  4.328623e-05\n",
      "4           free  1.899538e-05\n",
      "..           ...           ...\n",
      "245  centralized  2.070605e-07\n",
      "246  approximate  2.057354e-07\n",
      "247       native  2.051367e-07\n",
      "248      modular  2.026609e-07\n",
      "249     famously  2.024083e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.974594                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: decentralized\n",
      "Predicts: \n",
      "\n",
      "          token_str     score\n",
      "0     decentralized  0.719312\n",
      "1            global  0.046566\n",
      "2           virtual  0.040719\n",
      "3     cryptographic  0.023904\n",
      "4              free  0.019579\n",
      "..              ...       ...\n",
      "245  transformative  0.000036\n",
      "246       respected  0.000036\n",
      "247           niche  0.000036\n",
      "248        complete  0.000035\n",
      "249      developing  0.000035\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "        token_str     score  edit_distance_to_len_ratio\n",
      "0   decentralized  0.719312                    0.000000\n",
      "18    centralized  0.001794                    0.153846\n",
      "decentralized -> decentralized\n",
      "**************************************************\n",
      "Token: digital\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0          digital  0.835784\n",
      "1          virtual  0.091498\n",
      "2       electronic  0.043780\n",
      "3           global  0.010840\n",
      "4           online  0.006829\n",
      "..             ...       ...\n",
      "245        prepaid  0.000001\n",
      "246  International  0.000001\n",
      "247          proof  0.000001\n",
      "248          metal  0.000001\n",
      "249      recurring  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   digital  0.835784                         0.0\n",
      "digital -> digital\n",
      "**************************************************\n",
      "Token: currency\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0      currency  8.802119e-01\n",
      "1         asset  5.401581e-02\n",
      "2         token  2.268820e-02\n",
      "3         money  1.644601e-02\n",
      "4          cash  5.252292e-03\n",
      "..          ...           ...\n",
      "245     classic  9.289276e-07\n",
      "246     savings  9.056972e-07\n",
      "247        drug  9.036611e-07\n",
      "248           ,  9.033130e-07\n",
      "249  commitment  8.902859e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  currency  0.880212                         0.0\n",
      "currency -> currency\n",
      "**************************************************\n",
      "Token: that\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        that  8.634651e-01\n",
      "1       which  1.239080e-01\n",
      "2         and  1.159341e-02\n",
      "3           ,  5.113298e-04\n",
      "4          it  9.192361e-05\n",
      "..        ...           ...\n",
      "245         T  9.396993e-08\n",
      "246        []  9.349438e-08\n",
      "247   program  9.325857e-08\n",
      "248         /  9.256142e-08\n",
      "249  although  9.195750e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      that  0.863465                         0.0\n",
      "that -> that\n",
      "**************************************************\n",
      "Token: can\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0            can  9.844274e-01\n",
      "1            may  1.379448e-02\n",
      "2         cannot  5.183446e-04\n",
      "3          could  4.546314e-04\n",
      "4           will  3.863680e-04\n",
      "..           ...           ...\n",
      "245  principally  2.287692e-08\n",
      "246  temporarily  2.269309e-08\n",
      "247       miners  2.266765e-08\n",
      "248      results  2.233326e-08\n",
      "249     deposits  2.230482e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       can  0.984427                         0.0\n",
      "can -> can\n",
      "**************************************************\n",
      "Token: be\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0              be  9.997566e-01\n",
      "1            been  2.392574e-05\n",
      "2              is  1.976504e-05\n",
      "3          freely  1.919000e-05\n",
      "4           being  1.905476e-05\n",
      "..            ...           ...\n",
      "245         float  6.214977e-08\n",
      "246      formally  6.153758e-08\n",
      "247          free  6.129252e-08\n",
      "248  effortlessly  6.044478e-08\n",
      "249      interact  6.023762e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        be  0.999757                         0.0\n",
      "be -> be\n",
      "**************************************************\n",
      "Token: transferred\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0       traded  0.421989\n",
      "1    exchanged  0.265843\n",
      "2         used  0.180609\n",
      "3    purchased  0.032875\n",
      "4        spent  0.029688\n",
      "..         ...       ...\n",
      "245      money  0.000009\n",
      "246     pegged  0.000009\n",
      "247     merged  0.000009\n",
      "248    Bitcoin  0.000009\n",
      "249   provided  0.000009\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "     token_str     score  edit_distance_to_len_ratio\n",
      "9  transferred  0.004273                         0.0\n",
      "transferred -> transferred\n",
      "**************************************************\n",
      "Token: on\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0            over  2.736392e-01\n",
      "1              on  2.561284e-01\n",
      "2           using  2.138205e-01\n",
      "3         through  1.369326e-01\n",
      "4             via  9.646251e-02\n",
      "..            ...           ...\n",
      "245          live  2.957811e-07\n",
      "246          wire  2.921779e-07\n",
      "247         fully  2.879522e-07\n",
      "248          back  2.863671e-07\n",
      "249  transferring  2.851887e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1        on  0.256128                         0.0\n",
      "on -> on\n",
      "**************************************************\n",
      "Token: the\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          the  9.903879e-01\n",
      "1            a  9.251021e-03\n",
      "2          its  1.090060e-04\n",
      "3          any  2.014395e-05\n",
      "4       global  1.571903e-05\n",
      "..         ...           ...\n",
      "245   powerful  8.320044e-08\n",
      "246  competing  8.297889e-08\n",
      "247       pure  8.294976e-08\n",
      "248   thriving  8.221168e-08\n",
      "249     larger  8.216747e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       the  0.990388                         0.0\n",
      "the -> the\n",
      "**************************************************\n",
      "Token: peer\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        peer  9.992085e-01\n",
      "1        Peer  7.173035e-04\n",
      "2        peer  5.023061e-05\n",
      "3       miner  2.933962e-06\n",
      "4      public  1.642442e-06\n",
      "..        ...           ...\n",
      "245      main  6.753480e-09\n",
      "246    viewer  6.632843e-09\n",
      "247    patron  6.553718e-09\n",
      "248     stock  6.552368e-09\n",
      "249   website  6.500782e-09\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      peer  0.999209                         0.0\n",
      "peer -> peer\n",
      "**************************************************\n",
      "Token: -\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           -  9.977123e-01\n",
      "1           .  9.833862e-04\n",
      "2          .-  3.810721e-04\n",
      "3        </s>  3.227240e-04\n",
      "4           –  2.222604e-04\n",
      "..        ...           ...\n",
      "245         0  4.335087e-08\n",
      "246         9  4.323724e-08\n",
      "247         8  4.322388e-08\n",
      "248         9  4.310714e-08\n",
      "249        ra  4.287018e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      peer  0.999209                         0.0\n",
      "- -> -\n",
      "**************************************************\n",
      "Token: to\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          to  9.997689e-01\n",
      "1           2  1.341515e-04\n",
      "2          to  5.462452e-05\n",
      "3         for  6.454928e-06\n",
      "4          on  6.261082e-06\n",
      "..        ...           ...\n",
      "245       key  6.519357e-09\n",
      "246    things  6.495080e-09\n",
      "247      take  6.470079e-09\n",
      "248     aware  6.389433e-09\n",
      "249     print  6.383781e-09\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        to  0.999769                         0.0\n",
      "to -> to\n",
      "**************************************************\n",
      "Token: -\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           -  9.855273e-01\n",
      "1           .  7.574474e-03\n",
      "2          .-  3.633745e-03\n",
      "3        </s>  1.273610e-03\n",
      "4           –  9.869518e-04\n",
      "..        ...           ...\n",
      "245        oz  1.116204e-07\n",
      "246        nd  1.115348e-07\n",
      "247         ,  1.110030e-07\n",
      "248        ic  1.109979e-07\n",
      "249         5  1.109551e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        to  0.999769                         0.0\n",
      "- -> -\n",
      "**************************************************\n",
      "Token: peer\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        peer  9.999890e-01\n",
      "1        peer  1.008245e-05\n",
      "2      source  1.595992e-07\n",
      "3         per  1.304958e-07\n",
      "4    consumer  6.455578e-08\n",
      "..        ...           ...\n",
      "245      loop  1.868936e-10\n",
      "246        an  1.861934e-10\n",
      "247        ay  1.856862e-10\n",
      "248   patient  1.849510e-10\n",
      "249      iler  1.838494e-10\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      peer  0.999989                         0.0\n",
      "peer -> peer\n",
      "**************************************************\n",
      "Token: bitcoin\n",
      "Predicts: \n",
      "\n",
      "          token_str     score\n",
      "0           Bitcoin  0.692211\n",
      "1           bitcoin  0.246911\n",
      "2        blockchain  0.019583\n",
      "3    cryptocurrency  0.009690\n",
      "4          Ethereum  0.003246\n",
      "..              ...       ...\n",
      "245           price  0.000003\n",
      "246       commodity  0.000003\n",
      "247        Protocol  0.000003\n",
      "248            swap  0.000003\n",
      "249       liquidity  0.000003\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   Bitcoin  0.692211                    0.142857\n",
      "1   bitcoin  0.246911                    0.000000\n",
      "bitcoin -> bitcoin\n",
      "**************************************************\n",
      "Token: network\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0        network  9.651316e-01\n",
      "1     blockchain  2.109600e-02\n",
      "2       exchange  3.308562e-03\n",
      "3       networks  2.293200e-03\n",
      "4       protocol  2.120612e-03\n",
      "..           ...           ...\n",
      "245    subreddit  1.823544e-07\n",
      "246       miners  1.806663e-07\n",
      "247           er  1.797568e-07\n",
      "248  communities  1.757241e-07\n",
      "249    character  1.754749e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   network  0.965132                    0.000000\n",
      "3  networks  0.002293                    0.142857\n",
      "network -> network\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0            .  9.940856e-01\n",
      "1            .  2.237871e-03\n",
      "2            ,  8.162371e-04\n",
      "3            :  8.087983e-04\n",
      "4         </s>  3.605928e-04\n",
      "..         ...           ...\n",
      "245  currently  3.343506e-07\n",
      "246      coins  3.327398e-07\n",
      "247          A  3.304893e-07\n",
      "248   provided  3.282867e-07\n",
      "249  apparatus  3.262990e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   network  0.965132                    0.000000\n",
      "3  networks  0.002293                    0.142857\n",
      ". -> .\n",
      "Result text: \n",
      "Bitcoin is a decentralized digital currency that can be transferred on the peer-to-peer bitcoin network.\n",
      "Lexico Correction ...\n",
      "**************************************************\n",
      "[veryfied] is not in vocab\n",
      "**************************************************\n",
      "Token: veryfied\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0         verified  0.761987\n",
      "1    authenticated  0.078949\n",
      "2        confirmed  0.038789\n",
      "3        validated  0.027425\n",
      "4          tracked  0.014500\n",
      "..             ...       ...\n",
      "245       obtained  0.000010\n",
      "246       filtered  0.000010\n",
      "247    categorized  0.000010\n",
      "248       reported  0.000010\n",
      "249       notified  0.000010\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score\n",
      "0  verified  0.761987\n",
      "veryfied -> verified\n",
      "SOME TOKEN CORRECTED!!!\n",
      "**************************************************\n",
      "[throgh] is not in vocab\n",
      "**************************************************\n",
      "Token: throgh\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0         using  9.318807e-01\n",
      "1       through  4.168373e-02\n",
      "2           via  1.363023e-02\n",
      "3          with  6.305173e-03\n",
      "4           and  2.212488e-03\n",
      "..          ...           ...\n",
      "245      simple  2.010052e-07\n",
      "246  generating  2.004440e-07\n",
      "247      thanks  1.995331e-07\n",
      "248      modern  1.988894e-07\n",
      "249   filtering  1.982116e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score\n",
      "1   through  0.041684\n",
      "throgh -> through\n",
      "SOME TOKEN CORRECTED!!!\n",
      "Result text: \n",
      "Bitcoin transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain.\n",
      "Contextual Correction ...\n",
      "**************************************************\n",
      "Token: Bitcoin\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0     Bitcoin  0.242349\n",
      "1         The  0.226701\n",
      "2       These  0.198254\n",
      "3         All  0.096847\n",
      "4      Online  0.042042\n",
      "..        ...       ...\n",
      "245     These  0.000028\n",
      "246      Open  0.000028\n",
      "247     Where  0.000028\n",
      "248     Broad  0.000027\n",
      "249      Uber  0.000027\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   Bitcoin  0.242349                         0.0\n",
      "Bitcoin -> Bitcoin\n",
      "**************************************************\n",
      "Token: transactions\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0    transactions  9.927609e-01\n",
      "1        payments  2.149067e-03\n",
      "2       addresses  7.523845e-04\n",
      "3          trades  6.122679e-04\n",
      "4       contracts  5.490952e-04\n",
      "..            ...           ...\n",
      "245     databases  1.704425e-07\n",
      "246     protocols  1.703600e-07\n",
      "247          sums  1.699854e-07\n",
      "248         tasks  1.694131e-07\n",
      "249      proceeds  1.681980e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "      token_str     score  edit_distance_to_len_ratio\n",
      "0  transactions  0.992761                         0.0\n",
      "transactions -> transactions\n",
      "**************************************************\n",
      "Token: are\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0             are  9.991875e-01\n",
      "1            were  4.806874e-04\n",
      "2             get  1.285399e-04\n",
      "3              is  6.400047e-05\n",
      "4              be  3.054559e-05\n",
      "..            ...           ...\n",
      "245          hail  3.030218e-08\n",
      "246          rate  3.012652e-08\n",
      "247  subsequently  3.006934e-08\n",
      "248          vary  3.001056e-08\n",
      "249          they  2.995737e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       are  0.999188                         0.0\n",
      "are -> are\n",
      "**************************************************\n",
      "Token: verified\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0         verified  0.782724\n",
      "1    authenticated  0.110257\n",
      "2        confirmed  0.023072\n",
      "3        validated  0.016327\n",
      "4          tracked  0.009878\n",
      "..             ...       ...\n",
      "245         proved  0.000006\n",
      "246     downloaded  0.000006\n",
      "247           paid  0.000006\n",
      "248       attended  0.000006\n",
      "249        indexed  0.000006\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  verified  0.782724                         0.0\n",
      "verified -> verified\n",
      "**************************************************\n",
      "Token: by\n",
      "Predicts: \n",
      "\n",
      "         token_str         score\n",
      "0               by  9.472043e-01\n",
      "1               at  1.293568e-02\n",
      "2           across  1.118798e-02\n",
      "3            among  9.732974e-03\n",
      "4               on  8.462414e-03\n",
      "..             ...           ...\n",
      "245    overlapping  1.737908e-07\n",
      "246        joining  1.724324e-07\n",
      "247  automatically  1.712799e-07\n",
      "248         system  1.712786e-07\n",
      "249     assembling  1.691605e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        by  0.947204                         0.0\n",
      "by -> by\n",
      "**************************************************\n",
      "Token: network\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0       network  0.305782\n",
      "1       trusted  0.100836\n",
      "2       bitcoin  0.081130\n",
      "3      computer  0.053917\n",
      "4       Bitcoin  0.042886\n",
      "..          ...       ...\n",
      "245    blocking  0.000095\n",
      "246   authority  0.000095\n",
      "247   automated  0.000094\n",
      "248  suspicious  0.000094\n",
      "249    merchant  0.000094\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   network  0.305782                         0.0\n",
      "network -> network\n",
      "**************************************************\n",
      "Token: nodes\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0           nodes  0.175929\n",
      "1    participants  0.170639\n",
      "2           peers  0.160030\n",
      "3       computers  0.115328\n",
      "4       consensus  0.065454\n",
      "..            ...       ...\n",
      "245     inference  0.000045\n",
      "246         forks  0.000044\n",
      "247          CPUs  0.000044\n",
      "248         means  0.000043\n",
      "249          hubs  0.000042\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0     nodes  0.175929                         0.0\n",
      "nodes -> nodes\n",
      "**************************************************\n",
      "Token: through\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0         using  9.318807e-01\n",
      "1       through  4.168373e-02\n",
      "2           via  1.363023e-02\n",
      "3          with  6.305173e-03\n",
      "4           and  2.212488e-03\n",
      "..          ...           ...\n",
      "245      simple  2.010052e-07\n",
      "246  generating  2.004440e-07\n",
      "247      thanks  1.995331e-07\n",
      "248      modern  1.988894e-07\n",
      "249   filtering  1.982116e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1   through  0.041684                         0.0\n",
      "through -> through\n",
      "**************************************************\n",
      "Token: cryptography\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0    cryptography  0.785307\n",
      "1        software  0.066333\n",
      "2       consensus  0.043646\n",
      "3       computers  0.017469\n",
      "4      encryption  0.017175\n",
      "..            ...       ...\n",
      "245   performance  0.000013\n",
      "246        robots  0.000013\n",
      "247        clocks  0.000013\n",
      "248       imaging  0.000013\n",
      "249      routines  0.000013\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "      token_str     score  edit_distance_to_len_ratio\n",
      "0  cryptography  0.785307                         0.0\n",
      "cryptography -> cryptography\n",
      "**************************************************\n",
      "Token: and\n",
      "Predicts: \n",
      "\n",
      "        token_str         score\n",
      "0             and  9.971835e-01\n",
      "1               ,  1.462845e-03\n",
      "2            then  9.623042e-04\n",
      "3              or  6.482154e-05\n",
      "4              as  6.179653e-05\n",
      "..            ...           ...\n",
      "245        agents  5.394960e-08\n",
      "246     therefore  5.387515e-08\n",
      "247             …  5.351261e-08\n",
      "248  fingerprints  5.293781e-08\n",
      "249         shows  5.260124e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       and  0.997184                         0.0\n",
      "and -> and\n",
      "**************************************************\n",
      "Token: recorded\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0        recorded  0.766447\n",
      "1          stored  0.078206\n",
      "2      documented  0.018542\n",
      "3          logged  0.016991\n",
      "4          record  0.012796\n",
      "..            ...       ...\n",
      "245    discovered  0.000015\n",
      "246       drafted  0.000015\n",
      "247  standardized  0.000015\n",
      "248        cached  0.000014\n",
      "249       entries  0.000014\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  recorded  0.766447                        0.00\n",
      "4    record  0.012796                        0.25\n",
      "recorded -> recorded\n",
      "**************************************************\n",
      "Token: in\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            in  5.467218e-01\n",
      "1            on  4.392631e-01\n",
      "2          into  5.060242e-03\n",
      "3          onto  3.349008e-03\n",
      "4            as  1.733126e-03\n",
      "..          ...           ...\n",
      "245  developing  4.587976e-08\n",
      "246   composing  4.571623e-08\n",
      "247   occupying  4.553748e-08\n",
      "248    separate  4.541778e-08\n",
      "249      static  4.519224e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        in  0.546722                         0.0\n",
      "in -> in\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "         token_str         score\n",
      "0                a  9.988035e-01\n",
      "1              the  9.432365e-04\n",
      "2               an  1.157420e-04\n",
      "3              one  3.476477e-05\n",
      "4            their  2.699542e-05\n",
      "..             ...           ...\n",
      "245     segregated  1.831650e-08\n",
      "246       handmade  1.826898e-08\n",
      "247         secret  1.816197e-08\n",
      "248       implicit  1.807061e-08\n",
      "249  international  1.782326e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0         a  0.998803                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: public\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0      publicly  0.471153\n",
      "1        public  0.110036\n",
      "2        global  0.088993\n",
      "3       central  0.078837\n",
      "4        secure  0.067249\n",
      "..          ...       ...\n",
      "245      random  0.000030\n",
      "246      timely  0.000030\n",
      "247      sealed  0.000030\n",
      "248    silently  0.000030\n",
      "249  frequently  0.000030\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  publicly  0.471153                    0.333333\n",
      "1    public  0.110036                    0.000000\n",
      "public -> public\n",
      "**************************************************\n",
      "Token: distributed\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0     distributed  0.361170\n",
      "1         digital  0.202603\n",
      "2     transaction  0.093666\n",
      "3          online  0.072060\n",
      "4      electronic  0.059844\n",
      "..            ...       ...\n",
      "245         power  0.000017\n",
      "246      metadata  0.000017\n",
      "247  subscription  0.000017\n",
      "248    analytical  0.000016\n",
      "249     relations  0.000016\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "     token_str    score  edit_distance_to_len_ratio\n",
      "0  distributed  0.36117                         0.0\n",
      "distributed -> distributed\n",
      "**************************************************\n",
      "Token: ledger\n",
      "Predicts: \n",
      "\n",
      "          token_str         score\n",
      "0            ledger  9.179381e-01\n",
      "1          database  6.650332e-02\n",
      "2            record  8.887555e-03\n",
      "3              file  1.957214e-03\n",
      "4          document  7.443751e-04\n",
      "..              ...           ...\n",
      "245  implementation  3.676747e-07\n",
      "246       hierarchy  3.604064e-07\n",
      "247        language  3.548960e-07\n",
      "248          agency  3.492712e-07\n",
      "249    transparency  3.432482e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0    ledger  0.917938                         0.0\n",
      "ledger -> ledger\n",
      "**************************************************\n",
      "Token: called\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0       called  9.682971e-01\n",
      "1            ,  1.402353e-02\n",
      "2       dubbed  4.261822e-03\n",
      "3           or  2.996073e-03\n",
      "4           on  2.220538e-03\n",
      "..         ...           ...\n",
      "245  recording  1.526044e-07\n",
      "246         ),  1.522190e-07\n",
      "247         so  1.511433e-07\n",
      "248  computing  1.510736e-07\n",
      "249      above  1.494098e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0    called  0.968297                         0.0\n",
      "called -> called\n",
      "**************************************************\n",
      "Token: a\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          the  7.888343e-01\n",
      "1            a  2.091032e-01\n",
      "2          its  1.017121e-03\n",
      "3      bitcoin  3.276638e-04\n",
      "4      Bitcoin  3.126327e-04\n",
      "..         ...           ...\n",
      "245    Fortune  8.224607e-08\n",
      "246         th  8.219902e-08\n",
      "247  nicknamed  8.196857e-08\n",
      "248      lunar  8.137599e-08\n",
      "249    Jenkins  8.132572e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1         a  0.209103                         0.0\n",
      "a -> a\n",
      "**************************************************\n",
      "Token: blockchain\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0    blockchain  9.783273e-01\n",
      "1    Blockchain  1.334462e-02\n",
      "2         chain  1.333591e-03\n",
      "3       bitcoin  1.160829e-03\n",
      "4        ledger  1.078341e-03\n",
      "..          ...           ...\n",
      "245  foundation  2.274593e-07\n",
      "246    manifest  2.266953e-07\n",
      "247  filesystem  2.261322e-07\n",
      "248         Tau  2.229271e-07\n",
      "249          Po  2.127299e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "0  blockchain  0.978327                         0.0\n",
      "1  Blockchain  0.013345                         0.1\n",
      "blockchain -> blockchain\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           .  9.943855e-01\n",
      "1           :  3.813885e-03\n",
      "2           .  1.040663e-03\n",
      "3           ,  1.769343e-04\n",
      "4          .\"  7.554258e-05\n",
      "..        ...           ...\n",
      "245        it  7.094474e-08\n",
      "246        *:  7.087549e-08\n",
      "247    ......  7.070671e-08\n",
      "248     proxy  7.064632e-08\n",
      "249       now  7.002305e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "0  blockchain  0.978327                         0.0\n",
      "1  Blockchain  0.013345                         0.1\n",
      ". -> .\n",
      "Result text: \n",
      "Bitcoin transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain.\n",
      "Lexico Correction ...\n",
      "**************************************************\n",
      "[criptocurrency] is not in vocab\n",
      "**************************************************\n",
      "Token: criptocurrency\n",
      "Predicts: \n",
      "\n",
      "          token_str     score\n",
      "0    cryptocurrency  0.338522\n",
      "1          currency  0.133724\n",
      "2           program  0.089376\n",
      "3            system  0.072976\n",
      "4          internet  0.057725\n",
      "..              ...       ...\n",
      "245           event  0.000023\n",
      "246            Cube  0.000023\n",
      "247           Pearl  0.000023\n",
      "248             bot  0.000023\n",
      "249           drive  0.000023\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0  cryptocurrency  0.338522\n",
      "criptocurrency -> cryptocurrency\n",
      "SOME TOKEN CORRECTED!!!\n",
      "**************************************************\n",
      "[Nakamoto] is not in vocab\n",
      "**************************************************\n",
      "Token: Nakamoto\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0         Nak  0.345265\n",
      "1         Inc  0.115021\n",
      "2         Bay  0.048765\n",
      "3        Cash  0.043410\n",
      "4     Satoshi  0.035006\n",
      "..        ...       ...\n",
      "245     group  0.000246\n",
      "246         3  0.000244\n",
      "247   Private  0.000244\n",
      "248    Gordon  0.000243\n",
      "249       123  0.000242\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score]\n",
      "Index: []\n",
      "Nakamoto -> Nakamoto\n",
      "SOME TOKEN CORRECTED!!!\n",
      "Result text: \n",
      "The cryptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto.\n",
      "Contextual Correction ...\n",
      "**************************************************\n",
      "Token: The\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0           The  0.886194\n",
      "1       Bitcoin  0.045884\n",
      "2          This  0.041068\n",
      "3             A  0.014026\n",
      "4       Digital  0.002151\n",
      "..          ...       ...\n",
      "245  blockchain  0.000004\n",
      "246       Prime  0.000004\n",
      "247      source  0.000004\n",
      "248           s  0.000004\n",
      "249           –  0.000004\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       The  0.886194                    0.000000\n",
      "6       the  0.001025                    0.333333\n",
      "The -> The\n",
      "**************************************************\n",
      "Token: cryptocurrency\n",
      "Predicts: \n",
      "\n",
      "          token_str     score\n",
      "0    cryptocurrency  0.338522\n",
      "1          currency  0.133724\n",
      "2           program  0.089376\n",
      "3            system  0.072976\n",
      "4          internet  0.057725\n",
      "..              ...       ...\n",
      "245           event  0.000023\n",
      "246            Cube  0.000023\n",
      "247           Pearl  0.000023\n",
      "248             bot  0.000023\n",
      "249           drive  0.000023\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "        token_str     score  edit_distance_to_len_ratio\n",
      "0  cryptocurrency  0.338522                         0.0\n",
      "cryptocurrency -> cryptocurrency\n",
      "**************************************************\n",
      "Token: was\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0         was  9.980275e-01\n",
      "1        were  5.474555e-04\n",
      "2       first  3.031443e-04\n",
      "3          is  2.838364e-04\n",
      "4           ,  1.905405e-04\n",
      "..        ...           ...\n",
      "245    Darwin  2.704654e-07\n",
      "246    Oracle  2.694233e-07\n",
      "247     ether  2.676144e-07\n",
      "248    Cipher  2.673888e-07\n",
      "249   economy  2.673827e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       was  0.998028                         0.0\n",
      "was -> was\n",
      "**************************************************\n",
      "Token: invented\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0      created  0.579677\n",
      "1     invented  0.153664\n",
      "2    developed  0.060673\n",
      "3      started  0.030445\n",
      "4    announced  0.028178\n",
      "..         ...       ...\n",
      "245     solved  0.000003\n",
      "246    blocked  0.000003\n",
      "247   isolated  0.000003\n",
      "248    alleged  0.000003\n",
      "249   achieved  0.000003\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1  invented  0.153664                         0.0\n",
      "invented -> invented\n",
      "**************************************************\n",
      "Token: in\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            in  9.861141e-01\n",
      "1        around  1.093645e-02\n",
      "2         circa  4.564296e-04\n",
      "3        during  2.964678e-04\n",
      "4            on  1.773629e-04\n",
      "..          ...           ...\n",
      "245      aboard  7.923409e-08\n",
      "246  Foundation  7.903787e-08\n",
      "247          fo  7.838511e-08\n",
      "248        Apex  7.784071e-08\n",
      "249       Model  7.633018e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        in  0.986114                         0.0\n",
      "in -> in\n",
      "**************************************************\n",
      "Token: 2008\n",
      "Predicts: \n",
      "\n",
      "         token_str         score\n",
      "0             2009  5.851328e-01\n",
      "1             2008  1.557039e-01\n",
      "2             2010  1.361985e-01\n",
      "3             2014  3.677357e-02\n",
      "4             2011  2.934284e-02\n",
      "..             ...           ...\n",
      "245        bitcoin  4.983886e-07\n",
      "246        servers  4.901016e-07\n",
      "247       internet  4.865436e-07\n",
      "248  decentralized  4.852989e-07\n",
      "249        program  4.850315e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        in  0.986114                         0.0\n",
      "2008 -> 2008\n",
      "**************************************************\n",
      "Token: by\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            by  9.995822e-01\n",
      "1          with  1.428652e-04\n",
      "2             ,  2.943795e-05\n",
      "3           and  2.248715e-05\n",
      "4            by  2.229974e-05\n",
      "..          ...           ...\n",
      "245     leaving  3.346943e-08\n",
      "246           w  3.336732e-08\n",
      "247          al  3.329586e-08\n",
      "248  apparently  3.323800e-08\n",
      "249      likely  3.309907e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        by  0.999582                         0.0\n",
      "by -> by\n",
      "**************************************************\n",
      "Token: an\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          an  9.947709e-01\n",
      "1        some  1.925157e-03\n",
      "2           a  1.871643e-03\n",
      "3         the  7.806694e-04\n",
      "4     another  3.488494e-04\n",
      "..        ...           ...\n",
      "245        ag  3.894733e-08\n",
      "246  external  3.871506e-08\n",
      "247        he  3.868480e-08\n",
      "248  slightly  3.808083e-08\n",
      "249     ether  3.796407e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        an  0.994771                         0.0\n",
      "an -> an\n",
      "**************************************************\n",
      "Token: unknown\n",
      "Predicts: \n",
      "\n",
      "         token_str         score\n",
      "0        anonymous  7.665348e-01\n",
      "1          unknown  1.849775e-01\n",
      "2     unidentified  4.081203e-02\n",
      "3          unnamed  6.267949e-03\n",
      "4      unspecified  4.154555e-04\n",
      "..             ...           ...\n",
      "245       eclectic  2.930033e-08\n",
      "246    adventurous  2.923591e-08\n",
      "247      alternate  2.913070e-08\n",
      "248     impossible  2.845307e-08\n",
      "249  International  2.822723e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1   unknown  0.184977                         0.0\n",
      "unknown -> unknown\n",
      "**************************************************\n",
      "Token: person\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0        person  7.424020e-01\n",
      "1    individual  2.512595e-01\n",
      "2           man  2.341637e-03\n",
      "3        people  6.735467e-04\n",
      "4        author  5.028282e-04\n",
      "..          ...           ...\n",
      "245        trio  3.293964e-07\n",
      "246    director  3.282011e-07\n",
      "247        poet  3.231177e-07\n",
      "248        guru  3.218715e-07\n",
      "249        type  3.176826e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0    person  0.742402                         0.0\n",
      "person -> person\n",
      "**************************************************\n",
      "Token: or\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0            or  9.990051e-01\n",
      "1             a  2.282871e-04\n",
      "2            of  2.251666e-04\n",
      "3             /  1.765992e-04\n",
      "4           and  8.259248e-05\n",
      "..          ...           ...\n",
      "245     onymous  2.797709e-08\n",
      "246  individual  2.786164e-08\n",
      "247           …  2.772466e-08\n",
      "248        said  2.748625e-08\n",
      "249          /\"  2.739549e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        or  0.999005                         0.0\n",
      "or -> or\n",
      "**************************************************\n",
      "Token: group\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0         group  9.638312e-01\n",
      "1          team  2.277896e-02\n",
      "2        groups  7.297665e-03\n",
      "3           set  2.230277e-03\n",
      "4    collection  5.305239e-04\n",
      "..          ...           ...\n",
      "245        herd  1.548021e-07\n",
      "246       fleet  1.528726e-07\n",
      "247       union  1.527915e-07\n",
      "248  associates  1.520548e-07\n",
      "249     someone  1.472760e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0     group  0.963831                         0.0\n",
      "2    groups  0.007298                         0.2\n",
      "group -> group\n",
      "**************************************************\n",
      "Token: of\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0          of  9.991453e-01\n",
      "1          or  7.947808e-04\n",
      "2           a  7.395938e-06\n",
      "3          of  5.861302e-06\n",
      "4     thereof  3.973118e-06\n",
      "..        ...           ...\n",
      "245      next  8.634980e-09\n",
      "246         v  8.545423e-09\n",
      "247        au  8.520197e-09\n",
      "248     above  8.493846e-09\n",
      "249       led  8.467577e-09\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        of  0.999145                         0.0\n",
      "of -> of\n",
      "**************************************************\n",
      "Token: people\n",
      "Predicts: \n",
      "\n",
      "          token_str         score\n",
      "0            people  8.572866e-01\n",
      "1           persons  9.743161e-02\n",
      "2       individuals  2.914356e-02\n",
      "3           hackers  6.710021e-03\n",
      "4       programmers  1.739139e-03\n",
      "..              ...           ...\n",
      "245  whistleblowers  6.953152e-07\n",
      "246        partners  6.948114e-07\n",
      "247     contestants  6.901489e-07\n",
      "248     astronomers  6.877862e-07\n",
      "249        Japanese  6.787368e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0    people  0.857287                         0.0\n",
      "people -> people\n",
      "**************************************************\n",
      "Token: using\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0       using  0.734402\n",
      "1       under  0.099746\n",
      "2        with  0.088111\n",
      "3          by  0.021191\n",
      "4       given  0.013282\n",
      "..        ...       ...\n",
      "245         –  0.000004\n",
      "246    coding  0.000004\n",
      "247      near  0.000004\n",
      "248  handling  0.000004\n",
      "249  changing  0.000004\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0     using  0.734402                         0.0\n",
      "using -> using\n",
      "**************************************************\n",
      "Token: the\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0          the  9.953011e-01\n",
      "1         code  1.750801e-03\n",
      "2          pen  4.215312e-04\n",
      "3            a  2.791172e-04\n",
      "4          cod  1.933625e-04\n",
      "..         ...           ...\n",
      "245     origin  7.889391e-07\n",
      "246     Domain  7.826681e-07\n",
      "247    partial  7.754554e-07\n",
      "248      trust  7.701196e-07\n",
      "249  affiliate  7.593697e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       the  0.995301                         0.0\n",
      "the -> the\n",
      "**************************************************\n",
      "Token: name\n",
      "Predicts: \n",
      "\n",
      "      token_str         score\n",
      "0     pseudonym  7.579424e-01\n",
      "1          name  1.632731e-01\n",
      "2         alias  3.539579e-02\n",
      "3      initials  1.162892e-02\n",
      "4      username  9.696626e-03\n",
      "..          ...           ...\n",
      "245    accounts  6.974140e-07\n",
      "246      theory  6.847235e-07\n",
      "247      marker  6.808141e-07\n",
      "248  foundation  6.796024e-07\n",
      "249     control  6.792706e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1      name  0.163273                         0.0\n",
      "name -> name\n",
      "**************************************************\n",
      "Token: Satoshi\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0     Satoshi  9.996921e-01\n",
      "1     Project  6.790974e-05\n",
      "2        John  5.305163e-05\n",
      "3          of  2.296716e-05\n",
      "4      Andrew  2.196212e-05\n",
      "..        ...           ...\n",
      "245  Academic  1.993220e-08\n",
      "246     Thank  1.948355e-08\n",
      "247        's  1.943819e-08\n",
      "248     Faith  1.893163e-08\n",
      "249  Geoffrey  1.892037e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0   Satoshi  0.999692                         0.0\n",
      "Satoshi -> Satoshi\n",
      "**************************************************\n",
      "Token: Nakamoto\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0         Nak  0.345265\n",
      "1         Inc  0.115021\n",
      "2         Bay  0.048765\n",
      "3        Cash  0.043410\n",
      "4     Satoshi  0.035006\n",
      "..        ...       ...\n",
      "245     group  0.000246\n",
      "246         3  0.000244\n",
      "247   Private  0.000244\n",
      "248    Gordon  0.000243\n",
      "249       123  0.000242\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "Nakamoto -> Nakamoto\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0              .  9.908209e-01\n",
      "1              :  3.380057e-03\n",
      "2              .  2.577147e-03\n",
      "3              ,  7.994844e-04\n",
      "4            ().  6.404854e-04\n",
      "..           ...           ...\n",
      "245           cc  1.817387e-07\n",
      "246  anonymously  1.800000e-07\n",
      "247           .–  1.795563e-07\n",
      "248           if  1.781651e-07\n",
      "249           IV  1.778079e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      ". -> .\n",
      "Result text: \n",
      "The cryptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto.\n",
      "Lexico Correction ...\n",
      "**************************************************\n",
      "[curency] is not in vocab\n",
      "**************************************************\n",
      "Token: curency\n",
      "Predicts: \n",
      "\n",
      "     token_str     score\n",
      "0       system  0.059482\n",
      "1      browser  0.051536\n",
      "2      program  0.051311\n",
      "3       engine  0.048230\n",
      "4     platform  0.046004\n",
      "..         ...       ...\n",
      "245       Leap  0.000300\n",
      "246        MVP  0.000299\n",
      "247     source  0.000298\n",
      "248  telephone  0.000296\n",
      "249     filter  0.000295\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score]\n",
      "Index: []\n",
      "curency -> curency\n",
      "SOME TOKEN CORRECTED!!!\n",
      "**************************************************\n",
      "[implemntation] is not in vocab\n",
      "**************************************************\n",
      "Token: implemntation\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          code  0.338177\n",
      "1          core  0.083800\n",
      "2      firmware  0.079147\n",
      "3      software  0.074270\n",
      "4        design  0.041706\n",
      "..          ...       ...\n",
      "245    encoding  0.000085\n",
      "246     mapping  0.000083\n",
      "247  filesystem  0.000083\n",
      "248  protection  0.000082\n",
      "249     feature  0.000082\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "        token_str     score\n",
      "5  implementation  0.034375\n",
      "implemntation -> implementation\n",
      "SOME TOKEN CORRECTED!!!\n",
      "Result text: \n",
      "The curency began use in 2009 when its implementation was released as open-source software.\n",
      "Contextual Correction ...\n",
      "**************************************************\n",
      "Token: The\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0           P  0.109524\n",
      "1           C  0.050013\n",
      "2         The  0.047485\n",
      "3           L  0.038839\n",
      "4           S  0.038128\n",
      "..        ...       ...\n",
      "245  Advanced  0.000360\n",
      "246       Pin  0.000357\n",
      "247       Sun  0.000353\n",
      "248     Hyper  0.000351\n",
      "249        IC  0.000350\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "    token_str     score  edit_distance_to_len_ratio\n",
      "2         The  0.047485                    0.000000\n",
      "108        Th  0.001024                    0.333333\n",
      "The -> The\n",
      "**************************************************\n",
      "Token: curency\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0       protocol  0.134696\n",
      "1         system  0.093115\n",
      "2       standard  0.072198\n",
      "3      algorithm  0.047491\n",
      "4      framework  0.043086\n",
      "..           ...       ...\n",
      "245  environment  0.000191\n",
      "246          DRM  0.000190\n",
      "247     internet  0.000189\n",
      "248         Java  0.000188\n",
      "249    structure  0.000185\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [token_str, score, edit_distance_to_len_ratio]\n",
      "Index: []\n",
      "curency -> curency\n",
      "**************************************************\n",
      "Token: began\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0     entered  0.591312\n",
      "1         saw  0.070498\n",
      "2       began  0.068588\n",
      "3      gained  0.052425\n",
      "4       found  0.040235\n",
      "..        ...       ...\n",
      "245   further  0.000029\n",
      "246  licensed  0.000029\n",
      "247   slipped  0.000029\n",
      "248    closed  0.000029\n",
      "249  admitted  0.000028\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "2     began  0.068588                         0.0\n",
      "began -> began\n",
      "**************************************************\n",
      "Token: use\n",
      "Predicts: \n",
      "\n",
      "        token_str     score\n",
      "0       spreading  0.125111\n",
      "1         growing  0.116020\n",
      "2     circulating  0.106992\n",
      "3            life  0.058206\n",
      "4        evolving  0.039702\n",
      "..            ...       ...\n",
      "245     effective  0.000242\n",
      "246  distributing  0.000239\n",
      "247    decreasing  0.000239\n",
      "248      dropping  0.000239\n",
      "249        taking  0.000236\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "   token_str     score  edit_distance_to_len_ratio\n",
      "45       use  0.002404                         0.0\n",
      "use -> use\n",
      "**************************************************\n",
      "Token: in\n",
      "Predicts: \n",
      "\n",
      "       token_str         score\n",
      "0             in  9.901626e-01\n",
      "1         around  3.602251e-03\n",
      "2           from  5.492209e-04\n",
      "3          after  4.143081e-04\n",
      "4         during  3.962384e-04\n",
      "..           ...           ...\n",
      "245         2014  1.995870e-07\n",
      "246     publicly  1.995063e-07\n",
      "247         2007  1.990168e-07\n",
      "248  voluntarily  1.985239e-07\n",
      "249            C  1.975735e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        in  0.990163                         0.0\n",
      "in -> in\n",
      "**************************************************\n",
      "Token: 2009\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0           1999  0.053608\n",
      "1           1997  0.050606\n",
      "2           1998  0.050424\n",
      "3           1996  0.046198\n",
      "4           1995  0.044808\n",
      "..           ...       ...\n",
      "245       Turkey  0.000005\n",
      "246        Kenya  0.000005\n",
      "247       Hawaii  0.000005\n",
      "248          and  0.000005\n",
      "249  development  0.000005\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        in  0.990163                         0.0\n",
      "2009 -> 2009\n",
      "**************************************************\n",
      "Token: when\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        when  5.498735e-01\n",
      "1         and  2.467060e-01\n",
      "2       after  1.856461e-01\n",
      "3          as  7.507562e-03\n",
      "4           ;  2.519481e-03\n",
      "..        ...           ...\n",
      "245       has  1.930533e-07\n",
      "246      2013  1.925841e-07\n",
      "247         ―  1.924262e-07\n",
      "248         Â  1.918340e-07\n",
      "249    became  1.914553e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      when  0.549873                         0.0\n",
      "when -> when\n",
      "**************************************************\n",
      "Token: its\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0         the  0.565721\n",
      "1         its  0.349334\n",
      "2          an  0.074102\n",
      "3       their  0.002101\n",
      "4         one  0.001451\n",
      "..        ...       ...\n",
      "245    static  0.000002\n",
      "246       Ada  0.000002\n",
      "247  research  0.000002\n",
      "248    plugin  0.000002\n",
      "249  earliest  0.000002\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "1       its  0.349334                         0.0\n",
      "its -> its\n",
      "**************************************************\n",
      "Token: implementation\n",
      "Predicts: \n",
      "\n",
      "      token_str     score\n",
      "0          code  0.338177\n",
      "1          core  0.083800\n",
      "2      firmware  0.079147\n",
      "3      software  0.074270\n",
      "4        design  0.041706\n",
      "..          ...       ...\n",
      "245    encoding  0.000085\n",
      "246     mapping  0.000083\n",
      "247  filesystem  0.000083\n",
      "248  protection  0.000082\n",
      "249     feature  0.000082\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "        token_str     score  edit_distance_to_len_ratio\n",
      "5  implementation  0.034375                         0.0\n",
      "implementation -> implementation\n",
      "**************************************************\n",
      "Token: was\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0         was  9.989811e-01\n",
      "1        were  3.261089e-04\n",
      "2      became  2.157933e-04\n",
      "3       first  6.487549e-05\n",
      "4          is  5.907634e-05\n",
      "..        ...           ...\n",
      "245      beta  8.226083e-08\n",
      "246        if  8.193076e-08\n",
      "247      work  8.189420e-08\n",
      "248        CD  8.101392e-08\n",
      "249       tab  8.015505e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0       was  0.998981                         0.0\n",
      "was -> was\n",
      "**************************************************\n",
      "Token: released\n",
      "Predicts: \n",
      "\n",
      "       token_str     score\n",
      "0       released  0.901764\n",
      "1      published  0.050052\n",
      "2    distributed  0.009473\n",
      "3      available  0.007904\n",
      "4       launched  0.003138\n",
      "..           ...       ...\n",
      "245     upgraded  0.000004\n",
      "246     captured  0.000003\n",
      "247    exchanged  0.000003\n",
      "248       turned  0.000003\n",
      "249         sent  0.000003\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  released  0.901764                         0.0\n",
      "released -> released\n",
      "**************************************************\n",
      "Token: as\n",
      "Predicts: \n",
      "\n",
      "     token_str         score\n",
      "0           as  9.973778e-01\n",
      "1           in  1.380664e-03\n",
      "2         into  4.184015e-04\n",
      "3          for  1.626341e-04\n",
      "4         with  8.318142e-05\n",
      "..         ...           ...\n",
      "245    General  3.973627e-08\n",
      "246        ged  3.962682e-08\n",
      "247  Microsoft  3.956052e-08\n",
      "248   courtesy  3.924577e-08\n",
      "249   featured  3.922362e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0        as  0.997378                         0.0\n",
      "as -> as\n",
      "**************************************************\n",
      "Token: open\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0        open  9.972971e-01\n",
      "1      closed  1.041102e-03\n",
      "2        free  7.454910e-04\n",
      "3        Open  4.618311e-04\n",
      "4      public  4.586164e-05\n",
      "..        ...           ...\n",
      "245     stock  1.558179e-07\n",
      "246   visible  1.536218e-07\n",
      "247      anti  1.531344e-07\n",
      "248  unlocked  1.524594e-07\n",
      "249     Intel  1.507936e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      open  0.997297                         0.0\n",
      "open -> open\n",
      "**************************************************\n",
      "Token: -\n",
      "Predicts: \n",
      "\n",
      "    token_str         score\n",
      "0           -  9.990255e-01\n",
      "1           ‑  4.256372e-04\n",
      "2           –  2.110758e-04\n",
      "3           ‐  1.944684e-04\n",
      "4           -  2.271008e-05\n",
      "..        ...           ...\n",
      "245       DEC  4.926142e-08\n",
      "246        -\"  4.905664e-08\n",
      "247         >  4.873843e-08\n",
      "248  software  4.838128e-08\n",
      "249         >  4.833166e-08\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0      open  0.997297                         0.0\n",
      "- -> -\n",
      "**************************************************\n",
      "Token: source\n",
      "Predicts: \n",
      "\n",
      "    token_str     score\n",
      "0      source  0.991947\n",
      "1      access  0.002967\n",
      "2    licensed  0.000747\n",
      "3    standard  0.000580\n",
      "4    platform  0.000529\n",
      "..        ...       ...\n",
      "245     model  0.000001\n",
      "246      body  0.000001\n",
      "247  provided  0.000001\n",
      "248      arts  0.000001\n",
      "249       eye  0.000001\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0    source  0.991947                         0.0\n",
      "source -> source\n",
      "**************************************************\n",
      "Token: software\n",
      "Predicts: \n",
      "\n",
      "         token_str     score\n",
      "0         software  0.810986\n",
      "1             code  0.177307\n",
      "2    documentation  0.000985\n",
      "3       technology  0.000742\n",
      "4             work  0.000506\n",
      "..             ...       ...\n",
      "245           gold  0.000004\n",
      "246          since  0.000004\n",
      "247            CGI  0.000004\n",
      "248  automatically  0.000004\n",
      "249     underneath  0.000004\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  software  0.810986                         0.0\n",
      "software -> software\n",
      "**************************************************\n",
      "Token: .\n",
      "Predicts: \n",
      "\n",
      "         token_str         score\n",
      "0                .  9.840055e-01\n",
      "1                :  1.153943e-02\n",
      "2                .  1.187058e-03\n",
      "3                ,  6.951570e-04\n",
      "4               .\"  2.601102e-04\n",
      "..             ...           ...\n",
      "245              !  3.523658e-07\n",
      "246  advertisement  3.508408e-07\n",
      "247            viz  3.501897e-07\n",
      "248         vendor  3.494930e-07\n",
      "249              ‎  3.443648e-07\n",
      "\n",
      "[250 rows x 2 columns]\n",
      "Filtered Predicts: \n",
      "\n",
      "  token_str     score  edit_distance_to_len_ratio\n",
      "0  software  0.810986                         0.0\n",
      ". -> .\n",
      "Result text: \n",
      "The curency began use in 2009 when its implementation was released as open-source software.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Bitcoin is a decentralized digital currency that can be transferred on the peer-to-peer bitcoin network. Bitcoin transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. The cryptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto. The curency began use in 2009 when its implementation was released as open-source software.'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EDIT_DISTANCE_TO_LEN_RATIO = 0.4\n",
    "MAX_EDIT_DISTANCE = 2\n",
    "MIN_SCORE = 0.001\n",
    "TOP_K = 250\n",
    "VERBOSE = True\n",
    "\n",
    "if language == 'en':\n",
    "    # input_text = \"The capitan of Iran is tehran.\"\n",
    "    # input_text = \"i am speeking english very wall.\"\n",
    "    # input_text = \"He was stadying english for the finall exam.\"\n",
    "    # text = \"I'm studying [MASK] learning in my computer class.\"\n",
    "    # text = \"I'm a very [MASK] player in football.\"\n",
    "    # input_text = \"He drove a cat.\"\n",
    "    # text = \"do you want to watch tv.\"\n",
    "    # text = \"I love playing [MASK].\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The quantity thoery of money also assume that the quantity of money in an economy has a large influense on its level of economic activity. So, a change in the money supply results in either a change in the price levels or a change in the sopply of gods and services, or both. In addition, the theory assumes that changes in the money supply are the primary reason for changes in spending.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Does it privent Iran from getting nuclear weapens. Many exports say that if all parties adhered to their pledges, the deal almost certainly could have achieved that goal for longer than a dekade!\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        The Federal Reserve monitor risks to the financal system and works to help ensure the system supports a haelthy economy for U.S. households, communities, and busineses.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        Bitcoin is a decentrallized digital curency that can be transfered on the peer-to-peer bitcoin network. Bitcoin transactions are veryfied by network nodes throgh cryptography and recorded in a public distributed ledger called a blockchain. The criptocurrency was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto. The curency began use in 2009 when its implemntation was released as open-source software.\n",
    "    \"\"\"\n",
    "\n",
    "    if model_type != 'roberta':\n",
    "        input_text = input_text.lower()\n",
    "\n",
    "if language == 'fa':\n",
    "    input_text = \"امروز در استادیوم آزادی تیم ملی ایران و روسیه مسایقه می‌دهند.\"\n",
    "    input_text = \"پس از سال‌ها تلاش رازی موفق به کسف الکل شد. این دانشمند تیرانی باعث افتخار در تاریخ کور است.\"\n",
    "    input_text = \"هفته آینده احتمالا توافق بسته‌ای امضا می‌شود.\"\n",
    "    input_text = \"اهل کدام کشور هستی.\"\n",
    "    input_text = \"سن شما چقدر است.\"\n",
    "    input_text = \"وقتی قیمت گوست قرمز یا صفید در کشورهای دیگر بیشتر شده است، ممکن است در جیران هم گرا شود.\"\n",
    "    input_text = \"در هفته گذشته قیمت تلا تغییر چندانی نداشت، و در همان محدوده 1850 دلاری کار خود را به پایان رساند. \"\n",
    "    input_text = \"هدف از زندگانی چیست!\"\n",
    "    input_text = \"همه رأس ساعت 3 در جلسه حاضر باشند.\"\n",
    "\n",
    "    input_text = \"بر اساس مسوبه سران قوا، معاملات فردایی طلا همانند معاملات فردایی ارض، ممنوع و غیرقانونی شناخته شد و فعالان این بازار به جرم اخلال اقتصادی، تحت پیگرد قرار خواهند گرفت. در نتیجه تانک مرکزی در بازار فردایی مداخله نخواهد کرد\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        با نزدیک شدن قیمت دار غیر رسمی به سفف خود در روز قبل، تحلیلگران در بازار برای هفته بعد هشدار میدادند که باید احطیاط کرد و اقدامات امنیتی در بازار افزایش خواهد یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "    با تولانی شدن جنگ روسیه و اوکراین و سهم قابل توجهی که این دو کشور در تأمین کندم جهان داشتند، بازار کندم با نوسانات زیادی مواجه شد و قیمت محصولاتی که مواد اولیه‌شان کندم بود، در همه جای جهان افزایش یافت.\n",
    "    \"\"\"\n",
    "\n",
    "    input_text = \"\"\"\n",
    "        علت واقعی تعویق در مزاکرات وین چیست.\n",
    "    \"\"\"\n",
    "\n",
    "input_text = input_text.strip()\n",
    "\n",
    "spell_corrector = SpellCorrector(MAX_EDIT_DISTANCE_TO_LEN_RATIO, MAX_EDIT_DISTANCE, MIN_SCORE, VERBOSE, TOP_K)\n",
    "\n",
    "doc = nlp(input_text)\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "# displacy.render(doc, style=\"dep\")\n",
    "\n",
    "result = \" \".join([spell_corrector(sentence.text) for sentence in doc.sents])\n",
    "result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"theory\" in vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34daa296ffe99e8a66e159d01b1dfeb9a87967b5cca691fda43c054f03617153"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}