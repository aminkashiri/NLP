{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-12 15:26:31,983 WARNING] Directory /home/ahura/stanza_corenlp already exists. Please install CoreNLP to a new directory.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import spacy_stanza\n",
    "\n",
    "stanza.install_corenlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: 142kB [00:00, 82.2MB/s]                    \n",
      "[2022-04-12 15:26:33,070 INFO] Downloading default packages for language: fa (Persian)...\n",
      "[2022-04-12 15:26:35,642 INFO] File exists: /home/ahura/stanza_resources/fa/default.zip.\n",
      "[2022-04-12 15:26:39,851 INFO] Finished downloading models and saved to /home/ahura/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-12 15:26:39,999 INFO] Loading these models for language: fa (Persian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | perdt   |\n",
      "| mwt       | perdt   |\n",
      "| pos       | perdt   |\n",
      "| lemma     | perdt   |\n",
      "| depparse  | perdt   |\n",
      "=======================\n",
      "\n",
      "[2022-04-12 15:26:40,000 INFO] Use device: gpu\n",
      "[2022-04-12 15:26:40,001 INFO] Loading: tokenize\n",
      "[2022-04-12 15:26:40,012 INFO] Loading: mwt\n",
      "[2022-04-12 15:26:40,021 INFO] Loading: pos\n",
      "[2022-04-12 15:26:40,218 INFO] Loading: lemma\n",
      "[2022-04-12 15:26:40,281 INFO] Loading: depparse\n",
      "[2022-04-12 15:26:40,668 INFO] Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp = spacy_stanza.load_pipeline(\"fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup DadmaTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fa_tokenizer exists in /home/ahura/.pernlp/fa_tokenizer.pt\n",
      "Model fa_mwt exists in /home/ahura/.pernlp/fa_mwt.pt\n",
      "Model fa_lemmatizer exists in /home/ahura/.pernlp/fa_lemmatizer.pt\n",
      "Model parsbert exists in /home/ahura/.pernlp/parsbert.tar.gz\n",
      "Model dependencyparser exists in /home/ahura/.pernlp/dependencyparser.pt\n",
      "2022-04-12 15:26:44,234 loading file /home/ahura/anaconda3/envs/DataEnvPIP/lib/python3.8/site-packages/dadmatools/saved_models/dependencyparser/dependencyparser.pt\n",
      "Model parsbert exists in /home/ahura/.pernlp/parsbert.tar.gz\n",
      "Model postagger exists in /home/ahura/.pernlp/postagger.pt\n",
      "2022-04-12 15:27:00,671 loading file /home/ahura/anaconda3/envs/DataEnvPIP/lib/python3.8/site-packages/dadmatools/saved_models/postagger/postagger.pt\n",
      "Model fa_constituency exists in /home/ahura/.pernlp/fa_constituency.pt\n",
      "Model ner exists in /home/ahura/.pernlp/ner.tar.gz\n",
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component            Assigns       Requires   Scores   Retokenizes\n",
      "-   ------------------   -----------   --------   ------   -----------\n",
      "0   tokenizer                                              True       \n",
      "                                                                      \n",
      "1   lemmatize            token.lemma                       False      \n",
      "                                                                      \n",
      "2   dependancyparser     token.dep                         False      \n",
      "                                                                      \n",
      "3   postagger            token.pos                         False      \n",
      "                                                                      \n",
      "4   chunking                                               False      \n",
      "                                                                      \n",
      "5   constituencyparser                                     False      \n",
      "                                                                      \n",
      "6   ners                                                   False      \n",
      "\n",
      "\u001b[38;5;2m✔ No problems found.\u001b[0m\n",
      "{'summary': {'tokenizer': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': True}, 'lemmatize': {'assigns': ['token.lemma'], 'requires': [], 'scores': [], 'retokenizes': False}, 'dependancyparser': {'assigns': ['token.dep'], 'requires': [], 'scores': [], 'retokenizes': False}, 'postagger': {'assigns': ['token.pos'], 'requires': [], 'scores': [], 'retokenizes': False}, 'chunking': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}, 'constituencyparser': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}, 'ners': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}}, 'problems': {'tokenizer': [], 'lemmatize': [], 'dependancyparser': [], 'postagger': [], 'chunking': [], 'constituencyparser': [], 'ners': []}, 'attrs': {'token.dep': {'assigns': ['dependancyparser'], 'requires': []}, 'token.pos': {'assigns': ['postagger'], 'requires': []}, 'token.lemma': {'assigns': ['lemmatize'], 'requires': []}}}\n"
     ]
    }
   ],
   "source": [
    "import dadmatools.pipeline.language as language\n",
    "\n",
    "# here lemmatizer and pos tagger will be loaded\n",
    "# as tokenizer is the default tool, it will be loaded as well even without calling\n",
    "pips = 'ner, pos, dep, cons, chunk, lem, tok' \n",
    "dadma_nlp = language.Pipeline(pips)\n",
    "\n",
    "# you can see the pipeline with this code\n",
    "print(dadma_nlp.analyze_pipes(pretty=True))\n",
    "\n",
    "# doc is an SpaCy object\n",
    "# doc = dadma_nlp('از قصهٔ کودکیشان که می‌گفت، گاهی حرص می‌خورد!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dadma Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dadmatools.models.normalizer import Normalizer\n",
    "\n",
    "normalizer = Normalizer(\n",
    "    full_cleaning=False,\n",
    "    unify_chars=True,\n",
    "    refine_punc_spacing=True,\n",
    "    remove_extra_space=True,\n",
    "    remove_puncs=False,\n",
    "    remove_html=False,\n",
    "    remove_stop_word=False,\n",
    "    replace_email_with=\"<EMAIL>\",\n",
    "    replace_number_with=None,\n",
    "    replace_url_with=\"<URL\",\n",
    "    replace_mobile_number_with=\"<MOBILE_NUMBER>\",\n",
    "    replace_emoji_with=\"<EMOJI>\",\n",
    "    replace_home_number_with=\"<HOME_NUMBER>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    # 'روز چهارشنبه یک دفعه برای خودشون افشا زدن.'\n",
    "    # \"ارزش سهام شرکت نفت کاهش یافت\",\n",
    "    # \"سهام وغذیر و خزر کاهش یافت.\",\n",
    "    # \"قرارداد با آمریکا باعث افت قیمت سهم وغدیر شد\",\n",
    "    # \"ریزش بازار به دلیل حمله‌ی روسیه است.\",\n",
    "    # \"فک کنم یه اصلاح قیمتی و کمی ریزش داشته باشیم.\",\n",
    "    # \"یک نکته‌ی تکنیکالی هم در صورت دستکاری نشدن اضافه کنم، کندلی که روز سه شنبه‌ی گذشته ثبت کرد کامل است\",\n",
    "    \n",
    "    # \"روز چهارشنبه یه دفعه برای خودشون افشا زدن\",\n",
    "    # \"رشد قیمت‌ها باعث ایجاد صف خرید در سهم پرشیا شد\",\n",
    "    # \"شاخص به ۲ میلیون می‌رسه\",\n",
    "    # \"آمریکا باعث ریزش بازار شد\",\n",
    "    # \"آمریکا موجب ریزش بازار شد\",\n",
    "    # \"آمریکا دلیل ریزش بازار شد\",\n",
    "    # \"کاهش قیمت سهم عجیب بود\",\n",
    "    # \"قیمت زیاد شد\",\n",
    "    # \"قیمت زیاد است\",\n",
    "    # \"به کتابخانه رفتم.\",\n",
    "    # \"به کتابخانه رفت.\",\n",
    "    # \"پول در جیب من است.\",\n",
    "    # \"سهم قیمتش پایین است\",\n",
    "    \"حضور تو موجب خوشحالی من در هوای بارانی است\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy import displacy\n",
    "\n",
    "# for index, text in enumerate(texts):\n",
    "#     doc = stanza_nlp(text)\n",
    "#     print(f'sentence {index + 1}: ...')\n",
    "#     for token in doc:\n",
    "#         print(f'word: {token.text:12}, pos: {token.pos_:10}, tag: {token.tag_:10}, dep: {token.dep_:15}')\n",
    "#         print(\"\\n\")\n",
    "        \n",
    "#     displacy.render(list(doc.sents), style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-04-12 15:57:59,210 INFO] [Ensembling dict with seq2seq lemmatizer...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حضور NOUN nsubj 3\n",
      "تو PRON nmod 1\n",
      "موجب ADJ root 0\n",
      "خوشحالی NOUN obl:arg 3\n",
      "من PRON nmod 4\n",
      "در ADP case 7\n",
      "هوای NOUN nmod 4\n",
      "بارانی ADJ amod 7\n",
      "است AUX cop 3\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fa\" id=\"00f36b2acaca4426ad054ce62b5e5278-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"rtl\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: rtl\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1575\">حضور</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">تو</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1225\">موجب</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">خوشحالی</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"875\">من</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"875\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"700\">در</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"700\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"525\">هوای</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"525\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">بارانی</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"175\">است</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"175\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-0\" stroke-width=\"2px\" d=\"M1555,352.0 C1555,177.0 1235.0,177.0 1235.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1555,354.0 L1547,342.0 1563,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-1\" stroke-width=\"2px\" d=\"M1555,352.0 C1555,264.5 1415.0,264.5 1415.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1415.0,354.0 L1423.0,342.0 1407.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-2\" stroke-width=\"2px\" d=\"M1205,352.0 C1205,2.0 175.0,2.0 175.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">root</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1205,354.0 L1197,342.0 1213,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-3\" stroke-width=\"2px\" d=\"M1205,352.0 C1205,264.5 1065.0,264.5 1065.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">obl:arg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1065.0,354.0 L1073.0,342.0 1057.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-4\" stroke-width=\"2px\" d=\"M1030,352.0 C1030,264.5 890.0,264.5 890.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M890.0,354.0 L898.0,342.0 882.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-5\" stroke-width=\"2px\" d=\"M680,352.0 C680,264.5 540.0,264.5 540.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M680,354.0 L672,342.0 688,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-6\" stroke-width=\"2px\" d=\"M1030,352.0 C1030,89.5 530.0,89.5 530.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M530.0,354.0 L538.0,342.0 522.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-7\" stroke-width=\"2px\" d=\"M505,352.0 C505,264.5 365.0,264.5 365.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M365.0,354.0 L373.0,342.0 357.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-00f36b2acaca4426ad054ce62b5e5278-0-8\" stroke-width=\"2px\" d=\"M1205,352.0 C1205,2.0 175.0,2.0 175.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-00f36b2acaca4426ad054ce62b5e5278-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"right\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M175.0,354.0 L183.0,342.0 167.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "for index, text in enumerate(texts):\n",
    "    text = normalizer.normalize(text)\n",
    "    try:\n",
    "        \n",
    "        doc = dadma_nlp(text)\n",
    "        \n",
    "        # print(f'sentence {index + 1}: ...')\n",
    "        # for token in doc:\n",
    "        #     print(f'word: {token.text:12}, pos: {token.pos_:10}, tag: {token.tag_:10}, dep: {token.dep_:15}')\n",
    "        #     print(\"\\n\")\n",
    "        \n",
    "        sentences = doc._.sentences\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence_text = sentence.text\n",
    "            for token in sentence:\n",
    "                token_text = token.text\n",
    "                lemma = token.lemma_ ## this has value only if lem is called\n",
    "                pos_tag = token.pos_ ## this has value only if pos is called\n",
    "                dep = token.dep_ ## this has value only if dep is called\n",
    "                dep_arc = token._.dep_arc ## this has value only if dep is called\n",
    "                print(token_text, pos_tag, dep, dep_arc)\n",
    "                if token.pos_ == \"AUX\":\n",
    "                    token.pos_ = \"VERB\"\n",
    "                \n",
    "        sent_constituency = doc._.constituency ## this has value only if cons is called\n",
    "        sent_chunks = doc._.chunks ## this has value only if cons is called\n",
    "        # ners = doc._.ners ## this has value only if ner is called\n",
    "        # print(sent_constituency)\n",
    "        # print(sent_chunks)\n",
    "        \n",
    "        print(\"\\n\\n\\n\")\n",
    "        \n",
    "        displacy.render(doc, style=\"dep\")\n",
    "        \n",
    "    except Exception:\n",
    "        \n",
    "        print(f\"ERRR {text}\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pattern Matching](https://spacy.io/usage/spacy-101#architecture-matchers)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94bffb7bb37b548aa5e0061bb472f4819fbdd606d7ef446f7f021a1efc0be190"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('DataEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
